{"segementation": [{"cmdutils.c": [{"function body": "void init_opts(void)\n{\n\n    if(CONFIG_SWSCALE)\n        sws_opts = sws_getContext(16, 16, 0, 16, 16, 0, SWS_BICUBIC,\n                              NULL, NULL, NULL);\n\n    if(CONFIG_SWRESAMPLE)\n        swr_opts = swr_alloc();\n}"}, {"function body": "void uninit_opts(void)\n{\n#if CONFIG_SWSCALE\n    sws_freeContext(sws_opts);\n    sws_opts = NULL;\n#endif\n\n    if(CONFIG_SWRESAMPLE)\n        swr_free(&swr_opts);\n\n    av_dict_free(&format_opts);\n    av_dict_free(&codec_opts);\n}"}, {"function body": "void log_callback_help(void *ptr, int level, const char *fmt, va_list vl)\n{\n    vfprintf(stdout, fmt, vl);\n}"}, {"function body": "static void log_callback_report(void *ptr, int level, const char *fmt, va_list vl)\n{\n    va_list vl2;\n    char line[1024];\n    static int print_prefix = 1;\n\n    va_copy(vl2, vl);\n    av_log_default_callback(ptr, level, fmt, vl);\n    av_log_format_line(ptr, level, fmt, vl2, line, sizeof(line), &print_prefix);\n    va_end(vl2);\n    fputs(line, report_file);\n    fflush(report_file);\n}"}, {"function body": "double parse_number_or_die(const char *context, const char *numstr, int type,\n                           double min, double max)\n{\n    char *tail;\n    const char *error;\n    double d = av_strtod(numstr, &tail);\n    if (*tail)\n        error = \"Expected number for %s but found: %s\\n\";\n    else if (d < min || d > max)\n        error = \"The value for %s was %s which is not within %f - %f\\n\";\n    else if (type == OPT_INT64 && (int64_t)d != d)\n        error = \"Expected int64 for %s but found %s\\n\";\n    else if (type == OPT_INT && (int)d != d)\n        error = \"Expected int for %s but found %s\\n\";\n    else\n        return d;\n    av_log(NULL, AV_LOG_FATAL, error, context, numstr, min, max);\n    exit_program(1);\n    return 0;\n}"}, {"function body": "int64_t parse_time_or_die(const char *context, const char *timestr,\n                          int is_duration)\n{\n    int64_t us;\n    if (av_parse_time(&us, timestr, is_duration) < 0) {\n        av_log(NULL, AV_LOG_FATAL, \"Invalid %s specification for %s: %s\\n\",\n               is_duration ? \"duration\" : \"date\", context, timestr);\n        exit_program(1);\n    }\n    return us;\n}"}, {"function body": "void show_help_options(const OptionDef *options, const char *msg, int req_flags,\n                       int rej_flags, int alt_flags)\n{\n    const OptionDef *po;\n    int first;\n\n    first = 1;\n    for (po = options; po->name != NULL; po++) {\n        char buf[64];\n\n        if (((po->flags & req_flags) != req_flags) ||\n            (alt_flags && !(po->flags & alt_flags)) ||\n            (po->flags & rej_flags))\n            continue;\n\n        if (first) {\n            printf(\"%s\\n\", msg);\n            first = 0;\n        }\n        av_strlcpy(buf, po->name, sizeof(buf));\n        if (po->argname) {\n            av_strlcat(buf, \" \", sizeof(buf));\n            av_strlcat(buf, po->argname, sizeof(buf));\n        }\n        printf(\"-%-17s  %s\\n\", buf, po->help);\n    }\n    printf(\"\\n\");\n}"}, {"function body": "void show_help_children(const AVClass *class, int flags)\n{\n    const AVClass *child = NULL;\n    if (class->option) {\n        av_opt_show2(&class, NULL, flags, 0);\n        printf(\"\\n\");\n    }\n\n    while (child = av_opt_child_class_next(class, child))\n        show_help_children(child, flags);\n}"}, {"function body": "static const OptionDef *find_option(const OptionDef *po, const char *name)\n{\n    const char *p = strchr(name, ':');\n    int len = p ? p - name : strlen(name);\n\n    while (po->name != NULL) {\n        if (!strncmp(name, po->name, len) && strlen(po->name) == len)\n            break;\n        po++;\n    }\n    return po;\n}"}, {"function body": "static void prepare_app_arguments(int *argc_ptr, char ***argv_ptr)\n{\n    char *argstr_flat;\n    wchar_t **argv_w;\n    int i, buffsize = 0, offset = 0;\n\n    if (win32_argv_utf8) {\n        *argc_ptr = win32_argc;\n        *argv_ptr = win32_argv_utf8;\n        return;\n    }\n\n    win32_argc = 0;\n    argv_w = CommandLineToArgvW(GetCommandLineW(), &win32_argc);\n    if (win32_argc <= 0 || !argv_w)\n        return;\n\n    /* determine the UTF-8 buffer size (including NULL-termination symbols) */\n    for (i = 0; i < win32_argc; i++)\n        buffsize += WideCharToMultiByte(CP_UTF8, 0, argv_w[i], -1,\n                                        NULL, 0, NULL, NULL);\n\n    win32_argv_utf8 = av_mallocz(sizeof(char *) * (win32_argc + 1) + buffsize);\n    argstr_flat     = (char *)win32_argv_utf8 + sizeof(char *) * (win32_argc + 1);\n    if (win32_argv_utf8 == NULL) {\n        LocalFree(argv_w);\n        return;\n    }\n\n    for (i = 0; i < win32_argc; i++) {\n        win32_argv_utf8[i] = &argstr_flat[offset];\n        offset += WideCharToMultiByte(CP_UTF8, 0, argv_w[i], -1,\n                                      &argstr_flat[offset],\n                                      buffsize - offset, NULL, NULL);\n    }\n    win32_argv_utf8[i] = NULL;\n    LocalFree(argv_w);\n\n    *argc_ptr = win32_argc;\n    *argv_ptr = win32_argv_utf8;\n}"}, {"function body": "static inline void prepare_app_arguments(int *argc_ptr, char ***argv_ptr)\n{\n    /* nothing to do */\n}"}, {"function body": "int parse_option(void *optctx, const char *opt, const char *arg,\n                 const OptionDef *options)\n{\n    const OptionDef *po;\n    int bool_val = 1;\n    int *dstcount;\n    void *dst;\n\n    po = find_option(options, opt);\n    if (!po->name && opt[0] == 'n' && opt[1] == 'o') {\n        /* handle 'no' bool option */\n        po = find_option(options, opt + 2);\n        if ((po->name && (po->flags & OPT_BOOL)))\n            bool_val = 0;\n    }\n    if (!po->name)\n        po = find_option(options, \"default\");\n    if (!po->name) {\n        av_log(NULL, AV_LOG_ERROR, \"Unrecognized option '%s'\\n\", opt);\n        return AVERROR(EINVAL);\n    }\n    if (po->flags & HAS_ARG && !arg) {\n        av_log(NULL, AV_LOG_ERROR, \"Missing argument for option '%s'\\n\", opt);\n        return AVERROR(EINVAL);\n    }\n\n    /* new-style options contain an offset into optctx, old-style address of\n     * a global var*/\n    dst = po->flags & (OPT_OFFSET | OPT_SPEC) ? (uint8_t *)optctx + po->u.off\n                                              : po->u.dst_ptr;\n\n    if (po->flags & OPT_SPEC) {\n        SpecifierOpt **so = dst;\n        char *p = strchr(opt, ':');\n\n        dstcount = (int *)(so + 1);\n        *so = grow_array(*so, sizeof(**so), dstcount, *dstcount + 1);\n        (*so)[*dstcount - 1].specifier = av_strdup(p ? p + 1 : \"\");\n        dst = &(*so)[*dstcount - 1].u;\n    }\n\n    if (po->flags & OPT_STRING) {\n        char *str;\n        str = av_strdup(arg);\n//         av_freep(dst);\n        *(char **)dst = str;\n    } else if (po->flags & OPT_BOOL) {\n        *(int *)dst = bool_val;\n    } else if (po->flags & OPT_INT) {\n        *(int *)dst = parse_number_or_die(opt, arg, OPT_INT64, INT_MIN, INT_MAX);\n    } else if (po->flags & OPT_INT64) {\n        *(int64_t *)dst = parse_number_or_die(opt, arg, OPT_INT64, INT64_MIN, INT64_MAX);\n    } else if (po->flags & OPT_TIME) {\n        *(int64_t *)dst = parse_time_or_die(opt, arg, 1);\n    } else if (po->flags & OPT_FLOAT) {\n        *(float *)dst = parse_number_or_die(opt, arg, OPT_FLOAT, -INFINITY, INFINITY);\n    } else if (po->flags & OPT_DOUBLE) {\n        *(double *)dst = parse_number_or_die(opt, arg, OPT_DOUBLE, -INFINITY, INFINITY);\n    } else if (po->u.func_arg) {\n        int ret = po->u.func_arg(optctx, opt, arg);\n        if (ret < 0) {\n            av_log(NULL, AV_LOG_ERROR,\n                   \"Failed to set value '%s' for option '%s'\\n\", arg, opt);\n            return ret;\n        }\n    }\n    if (po->flags & OPT_EXIT)\n        exit_program(0);\n    return !!(po->flags & HAS_ARG);\n}"}, {"function body": "void parse_options(void *optctx, int argc, char **argv, const OptionDef *options,\n                   void (*parse_arg_function)(void *, const char*))\n{\n    const char *opt;\n    int optindex, handleoptions = 1, ret;\n\n    /* perform system-dependent conversions for arguments list */\n    prepare_app_arguments(&argc, &argv);\n\n    /* parse options */\n    optindex = 1;\n    while (optindex < argc) {\n        opt = argv[optindex++];\n\n        if (handleoptions && opt[0] == '-' && opt[1] != '\\0') {\n            if (opt[1] == '-' && opt[2] == '\\0') {\n                handleoptions = 0;\n                continue;\n            }\n            opt++;\n\n            if ((ret = parse_option(optctx, opt, argv[optindex], options)) < 0)\n                exit_program(1);\n            optindex += ret;\n        } else {\n            if (parse_arg_function)\n                parse_arg_function(optctx, opt);\n        }\n    }\n}"}, {"function body": "int locate_option(int argc, char **argv, const OptionDef *options,\n                  const char *optname)\n{\n    const OptionDef *po;\n    int i;\n\n    for (i = 1; i < argc; i++) {\n        const char *cur_opt = argv[i];\n\n        if (*cur_opt++ != '-')\n            continue;\n\n        po = find_option(options, cur_opt);\n        if (!po->name && cur_opt[0] == 'n' && cur_opt[1] == 'o')\n            po = find_option(options, cur_opt + 2);\n\n        if ((!po->name && !strcmp(cur_opt, optname)) ||\n             (po->name && !strcmp(optname, po->name)))\n            return i;\n\n        if (!po || po->flags & HAS_ARG)\n            i++;\n    }\n    return 0;\n}"}, {"function body": "static void dump_argument(const char *a)\n{\n    const unsigned char *p;\n\n    for (p = a; *p; p++)\n        if (!((*p >= '+' && *p <= ':') || (*p >= '@' && *p <= 'Z') ||\n              *p == '_' || (*p >= 'a' && *p <= 'z')))\n            break;\n    if (!*p) {\n        fputs(a, report_file);\n        return;\n    }\n    fputc('\"', report_file);\n    for (p = a; *p; p++) {\n        if (*p == '\\\\' || *p == '\"' || *p == '$' || *p == '`')\n            fprintf(report_file, \"\\\\%c\", *p);\n        else if (*p < ' ' || *p > '~')\n            fprintf(report_file, \"\\\\x%02x\", *p);\n        else\n            fputc(*p, report_file);\n    }\n    fputc('\"', report_file);\n}"}, {"function body": "void parse_loglevel(int argc, char **argv, const OptionDef *options)\n{\n    int idx = locate_option(argc, argv, options, \"loglevel\");\n    if (!idx)\n        idx = locate_option(argc, argv, options, \"v\");\n    if (idx && argv[idx + 1])\n        opt_loglevel(NULL, \"loglevel\", argv[idx + 1]);\n    idx = locate_option(argc, argv, options, \"report\");\n    if (idx || getenv(\"FFREPORT\")) {\n        opt_report(\"report\");\n        if (report_file) {\n            int i;\n            fprintf(report_file, \"Command line:\\n\");\n            for (i = 0; i < argc; i++) {\n                dump_argument(argv[i]);\n                fputc(i < argc - 1 ? ' ' : '\\n', report_file);\n            }\n            fflush(report_file);\n        }\n    }\n}"}, {"function body": "int opt_default(void *optctx, const char *opt, const char *arg)\n{\n    const AVOption *o;\n    char opt_stripped[128];\n    const char *p;\n    const AVClass *cc = avcodec_get_class(), *fc = avformat_get_class(), *sc, *swr_class;\n\n    if (!(p = strchr(opt, ':')))\n        p = opt + strlen(opt);\n    av_strlcpy(opt_stripped, opt, FFMIN(sizeof(opt_stripped), p - opt + 1));\n\n    if ((o = av_opt_find(&cc, opt_stripped, NULL, 0,\n                         AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ)) ||\n        ((opt[0] == 'v' || opt[0] == 'a' || opt[0] == 's') &&\n         (o = av_opt_find(&cc, opt + 1, NULL, 0, AV_OPT_SEARCH_FAKE_OBJ))))\n        av_dict_set(&codec_opts, opt, arg, FLAGS);\n    else if ((o = av_opt_find(&fc, opt, NULL, 0,\n                              AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ)))\n        av_dict_set(&format_opts, opt, arg, FLAGS);\n#if CONFIG_SWSCALE\n    sc = sws_get_class();\n    if (!o && (o = av_opt_find(&sc, opt, NULL, 0,\n                         AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ))) {\n        // XXX we only support sws_flags, not arbitrary sws options\n        int ret = av_opt_set(sws_opts, opt, arg, 0);\n        if (ret < 0) {\n            av_log(NULL, AV_LOG_ERROR, \"Error setting option %s.\\n\", opt);\n            return ret;\n        }\n    }\n#endif\n#if CONFIG_SWRESAMPLE\n    swr_class = swr_get_class();\n    if (!o && (o = av_opt_find(&swr_class, opt, NULL, 0,\n                               AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ))) {\n        int ret = av_opt_set(swr_opts, opt, arg, 0);\n        if (ret < 0) {\n            av_log(NULL, AV_LOG_ERROR, \"Error setting option %s.\\n\", opt);\n            return ret;\n        }\n    }\n#endif\n\n    if (o)\n        return 0;\n    av_log(NULL, AV_LOG_ERROR, \"Unrecognized option '%s'\\n\", opt);\n    return AVERROR_OPTION_NOT_FOUND;\n}"}, {"function body": "int opt_loglevel(void *optctx, const char *opt, const char *arg)\n{\n    const struct { const char *name; int level; } log_levels[] = {\n        { \"quiet\"  , AV_LOG_QUIET   },\n        { \"panic\"  , AV_LOG_PANIC   },\n        { \"fatal\"  , AV_LOG_FATAL   },\n        { \"error\"  , AV_LOG_ERROR   },\n        { \"warning\", AV_LOG_WARNING },\n        { \"info\"   , AV_LOG_INFO    },\n        { \"verbose\", AV_LOG_VERBOSE },\n        { \"debug\"  , AV_LOG_DEBUG   },\n    };\n    char *tail;\n    int level;\n    int i;\n\n    for (i = 0; i < FF_ARRAY_ELEMS(log_levels); i++) {\n        if (!strcmp(log_levels[i].name, arg)) {\n            av_log_set_level(log_levels[i].level);\n            return 0;\n        }\n    }\n\n    level = strtol(arg, &tail, 10);\n    if (*tail) {\n        av_log(NULL, AV_LOG_FATAL, \"Invalid loglevel \\\"%s\\\". \"\n               \"Possible levels are numbers or:\\n\", arg);\n        for (i = 0; i < FF_ARRAY_ELEMS(log_levels); i++)\n            av_log(NULL, AV_LOG_FATAL, \"\\\"%s\\\"\\n\", log_levels[i].name);\n        exit_program(1);\n    }\n    av_log_set_level(level);\n    return 0;\n}"}, {"function body": "int opt_report(const char *opt)\n{\n    char filename[64];\n    time_t now;\n    struct tm *tm;\n\n    if (report_file) /* already opened */\n        return 0;\n    time(&now);\n    tm = localtime(&now);\n    snprintf(filename, sizeof(filename), \"%s-%04d%02d%02d-%02d%02d%02d.log\",\n             program_name,\n             tm->tm_year + 1900, tm->tm_mon + 1, tm->tm_mday,\n             tm->tm_hour, tm->tm_min, tm->tm_sec);\n    report_file = fopen(filename, \"w\");\n    if (!report_file) {\n        av_log(NULL, AV_LOG_ERROR, \"Failed to open report \\\"%s\\\": %s\\n\",\n               filename, strerror(errno));\n        return AVERROR(errno);\n    }\n    av_log_set_callback(log_callback_report);\n    av_log(NULL, AV_LOG_INFO,\n           \"%s started on %04d-%02d-%02d at %02d:%02d:%02d\\n\"\n           \"Report written to \\\"%s\\\"\\n\",\n           program_name,\n           tm->tm_year + 1900, tm->tm_mon + 1, tm->tm_mday,\n           tm->tm_hour, tm->tm_min, tm->tm_sec,\n           filename);\n    av_log_set_level(FFMAX(av_log_get_level(), AV_LOG_VERBOSE));\n    return 0;\n}"}, {"function body": "int opt_max_alloc(void *optctx, const char *opt, const char *arg)\n{\n    char *tail;\n    size_t max;\n\n    max = strtol(arg, &tail, 10);\n    if (*tail) {\n        av_log(NULL, AV_LOG_FATAL, \"Invalid max_alloc \\\"%s\\\".\\n\", arg);\n        exit_program(1);\n    }\n    av_max_alloc(max);\n    return 0;\n}"}, {"function body": "int opt_cpuflags(void *optctx, const char *opt, const char *arg)\n{\n    int ret;\n    unsigned flags = av_get_cpu_flags();\n\n    if ((ret = av_parse_cpu_caps(&flags, arg)) < 0)\n        return ret;\n\n    av_force_cpu_flags(flags);\n    return 0;\n}"}, {"function body": "int opt_codec_debug(void *optctx, const char *opt, const char *arg)\n{\n    av_log_set_level(AV_LOG_DEBUG);\n    return opt_default(NULL, opt, arg);\n}"}, {"function body": "int opt_timelimit(void *optctx, const char *opt, const char *arg)\n{\n#if HAVE_SETRLIMIT\n    int lim = parse_number_or_die(opt, arg, OPT_INT64, 0, INT_MAX);\n    struct rlimit rl = { lim, lim + 1 };\n    if (setrlimit(RLIMIT_CPU, &rl))\n        perror(\"setrlimit\");\n#else\n    av_log(NULL, AV_LOG_WARNING, \"-%s not implemented on this OS\\n\", opt);\n#endif\n    return 0;\n}"}, {"function body": "void print_error(const char *filename, int err)\n{\n    char errbuf[128];\n    const char *errbuf_ptr = errbuf;\n\n    if (av_strerror(err, errbuf, sizeof(errbuf)) < 0)\n        errbuf_ptr = strerror(AVUNERROR(err));\n    av_log(NULL, AV_LOG_ERROR, \"%s: %s\\n\", filename, errbuf_ptr);\n}"}, {"function body": "static void print_all_libs_info(int flags, int level)\n{\n    PRINT_LIB_INFO(avutil,   AVUTIL,   flags, level);\n    PRINT_LIB_INFO(avcodec,  AVCODEC,  flags, level);\n    PRINT_LIB_INFO(avformat, AVFORMAT, flags, level);\n    PRINT_LIB_INFO(avdevice, AVDEVICE, flags, level);\n    PRINT_LIB_INFO(avfilter, AVFILTER, flags, level);\n//    PRINT_LIB_INFO(avresample, AVRESAMPLE, flags, level);\n    PRINT_LIB_INFO(swscale,  SWSCALE,  flags, level);\n    PRINT_LIB_INFO(swresample,SWRESAMPLE,  flags, level);\n#if CONFIG_POSTPROC\n    PRINT_LIB_INFO(postproc, POSTPROC, flags, level);\n#endif\n}"}, {"function body": "static void print_program_info(int flags, int level)\n{\n    const char *indent = flags & INDENT? \"  \" : \"\";\n\n    av_log(NULL, level, \"%s version \" FFMPEG_VERSION, program_name);\n    if (flags & SHOW_COPYRIGHT)\n        av_log(NULL, level, \" Copyright (c) %d-%d the FFmpeg developers\",\n               program_birth_year, this_year);\n    av_log(NULL, level, \"\\n\");\n    av_log(NULL, level, \"%sbuilt on %s %s with %s\\n\",\n           indent, __DATE__, __TIME__, CC_IDENT);\n\n    av_log(NULL, level, \"%sconfiguration: \" FFMPEG_CONFIGURATION \"\\n\", indent);\n}"}, {"function body": "void show_banner(int argc, char **argv, const OptionDef *options)\n{\n    int idx = locate_option(argc, argv, options, \"version\");\n    if (idx)\n        return;\n\n    print_program_info (INDENT|SHOW_COPYRIGHT, AV_LOG_INFO);\n    print_all_libs_info(INDENT|SHOW_CONFIG,  AV_LOG_INFO);\n    print_all_libs_info(INDENT|SHOW_VERSION, AV_LOG_INFO);\n}"}, {"function body": "int show_version(void *optctx, const char *opt, const char *arg)\n{\n    av_log_set_callback(log_callback_help);\n    print_program_info (0           , AV_LOG_INFO);\n    print_all_libs_info(SHOW_VERSION, AV_LOG_INFO);\n\n    return 0;\n}"}, {"function body": "int show_license(void *optctx, const char *opt, const char *arg)\n{\n    printf(\n#if CONFIG_NONFREE\n    \"This version of %s has nonfree parts compiled in.\\n\"\n    \"Therefore it is not legally redistributable.\\n\",\n    program_name\n#elif CONFIG_GPLV3\n    \"%s is free software; you can redistribute it and/or modify\\n\"\n    \"it under the terms of the GNU General Public License as published by\\n\"\n    \"the Free Software Foundation; either version 3 of the License, or\\n\"\n    \"(at your option) any later version.\\n\"\n    \"\\n\"\n    \"%s is distributed in the hope that it will be useful,\\n\"\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n\"\n    \"GNU General Public License for more details.\\n\"\n    \"\\n\"\n    \"You should have received a copy of the GNU General Public License\\n\"\n    \"along with %s.  If not, see <http://www.gnu.org/licenses/>.\\n\",\n    program_name, program_name, program_name\n#elif CONFIG_GPL\n    \"%s is free software; you can redistribute it and/or modify\\n\"\n    \"it under the terms of the GNU General Public License as published by\\n\"\n    \"the Free Software Foundation; either version 2 of the License, or\\n\"\n    \"(at your option) any later version.\\n\"\n    \"\\n\"\n    \"%s is distributed in the hope that it will be useful,\\n\"\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n\"\n    \"GNU General Public License for more details.\\n\"\n    \"\\n\"\n    \"You should have received a copy of the GNU General Public License\\n\"\n    \"along with %s; if not, write to the Free Software\\n\"\n    \"Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\\n\",\n    program_name, program_name, program_name\n#elif CONFIG_LGPLV3\n    \"%s is free software; you can redistribute it and/or modify\\n\"\n    \"it under the terms of the GNU Lesser General Public License as published by\\n\"\n    \"the Free Software Foundation; either version 3 of the License, or\\n\"\n    \"(at your option) any later version.\\n\"\n    \"\\n\"\n    \"%s is distributed in the hope that it will be useful,\\n\"\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n\"\n    \"GNU Lesser General Public License for more details.\\n\"\n    \"\\n\"\n    \"You should have received a copy of the GNU Lesser General Public License\\n\"\n    \"along with %s.  If not, see <http://www.gnu.org/licenses/>.\\n\",\n    program_name, program_name, program_name\n#else\n    \"%s is free software; you can redistribute it and/or\\n\"\n    \"modify it under the terms of the GNU Lesser General Public\\n\"\n    \"License as published by the Free Software Foundation; either\\n\"\n    \"version 2.1 of the License, or (at your option) any later version.\\n\"\n    \"\\n\"\n    \"%s is distributed in the hope that it will be useful,\\n\"\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\\n\"\n    \"Lesser General Public License for more details.\\n\"\n    \"\\n\"\n    \"You should have received a copy of the GNU Lesser General Public\\n\"\n    \"License along with %s; if not, write to the Free Software\\n\"\n    \"Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\\n\",\n    program_name, program_name, program_name\n#endif\n    );\n\n    return 0;\n}"}, {"function body": "int show_formats(void *optctx, const char *opt, const char *arg)\n{\n    AVInputFormat *ifmt  = NULL;\n    AVOutputFormat *ofmt = NULL;\n    const char *last_name;\n\n    printf(\"File formats:\\n\"\n           \" D. = Demuxing supported\\n\"\n           \" .E = Muxing supported\\n\"\n           \" --\\n\");\n    last_name = \"000\";\n    for (;;) {\n        int decode = 0;\n        int encode = 0;\n        const char *name      = NULL;\n        const char *long_name = NULL;\n\n        while ((ofmt = av_oformat_next(ofmt))) {\n            if ((name == NULL || strcmp(ofmt->name, name) < 0) &&\n                strcmp(ofmt->name, last_name) > 0) {\n                name      = ofmt->name;\n                long_name = ofmt->long_name;\n                encode    = 1;\n            }\n        }\n        while ((ifmt = av_iformat_next(ifmt))) {\n            if ((name == NULL || strcmp(ifmt->name, name) < 0) &&\n                strcmp(ifmt->name, last_name) > 0) {\n                name      = ifmt->name;\n                long_name = ifmt->long_name;\n                encode    = 0;\n            }\n            if (name && strcmp(ifmt->name, name) == 0)\n                decode = 1;\n        }\n        if (name == NULL)\n            break;\n        last_name = name;\n\n        printf(\" %s%s %-15s %s\\n\",\n               decode ? \"D\" : \" \",\n               encode ? \"E\" : \" \",\n               name,\n            long_name ? long_name:\" \");\n    }\n    return 0;\n}"}, {"function body": "static void print_codec(const AVCodec *c)\n{\n    int encoder = av_codec_is_encoder(c);\n\n    printf(\"%s %s [%s]:\\n\", encoder ? \"Encoder\" : \"Decoder\", c->name,\n           c->long_name ? c->long_name : \"\");\n\n    if (c->type == AVMEDIA_TYPE_VIDEO) {\n        printf(\"    Threading capabilities: \");\n        switch (c->capabilities & (CODEC_CAP_FRAME_THREADS |\n                                   CODEC_CAP_SLICE_THREADS)) {\n        case CODEC_CAP_FRAME_THREADS |\n             CODEC_CAP_SLICE_THREADS: printf(\"frame and slice\"); break;\n        case CODEC_CAP_FRAME_THREADS: printf(\"frame\");           break;\n        case CODEC_CAP_SLICE_THREADS: printf(\"slice\");           break;\n        default:                      printf(\"no\");              break;\n        }\n        printf(\"\\n\");\n    }\n\n    if (c->supported_framerates) {\n        const AVRational *fps = c->supported_framerates;\n\n        printf(\"    Supported framerates:\");\n        while (fps->num) {\n            printf(\" %d/%d\", fps->num, fps->den);\n            fps++;\n        }\n        printf(\"\\n\");\n    }\n    PRINT_CODEC_SUPPORTED(c, pix_fmts, enum PixelFormat, \"pixel formats\",\n                          PIX_FMT_NONE, GET_PIX_FMT_NAME);\n    PRINT_CODEC_SUPPORTED(c, supported_samplerates, int, \"sample rates\", 0,\n                          GET_SAMPLE_RATE_NAME);\n    PRINT_CODEC_SUPPORTED(c, sample_fmts, enum AVSampleFormat, \"sample formats\",\n                          AV_SAMPLE_FMT_NONE, GET_SAMPLE_FMT_NAME);\n    PRINT_CODEC_SUPPORTED(c, channel_layouts, uint64_t, \"channel layouts\",\n                          0, GET_CH_LAYOUT_DESC);\n\n    if (c->priv_class) {\n        show_help_children(c->priv_class,\n                           AV_OPT_FLAG_ENCODING_PARAM |\n                           AV_OPT_FLAG_DECODING_PARAM);\n    }\n}"}, {"function body": "static char get_media_type_char(enum AVMediaType type)\n{\n    switch (type) {\n        case AVMEDIA_TYPE_VIDEO:    return 'V';\n        case AVMEDIA_TYPE_AUDIO:    return 'A';\n        case AVMEDIA_TYPE_DATA:     return 'D';\n        case AVMEDIA_TYPE_SUBTITLE: return 'S';\n        case AVMEDIA_TYPE_ATTACHMENT:return 'T';\n        default:                    return '?';\n    }\n}"}, {"function body": "static const AVCodec *next_codec_for_id(enum AVCodecID id, const AVCodec *prev,\n                                        int encoder)\n{\n    while ((prev = av_codec_next(prev))) {\n        if (prev->id == id &&\n            (encoder ? av_codec_is_encoder(prev) : av_codec_is_decoder(prev)))\n            return prev;\n    }\n    return NULL;\n}"}, {"function body": "static int compare_codec_desc(const void *a, const void *b)\n{\n    const AVCodecDescriptor * const *da = a;\n    const AVCodecDescriptor * const *db = b;\n\n    return (*da)->type != (*db)->type ? (*da)->type - (*db)->type :\n           strcmp((*da)->name, (*db)->name);\n}"}, {"function body": "static unsigned get_codecs_sorted(const AVCodecDescriptor ***rcodecs)\n{\n    const AVCodecDescriptor *desc = NULL;\n    const AVCodecDescriptor **codecs;\n    unsigned nb_codecs = 0, i = 0;\n\n    while ((desc = avcodec_descriptor_next(desc)))\n        nb_codecs++;\n    if (!(codecs = av_calloc(nb_codecs, sizeof(*codecs)))) {\n        av_log(0, AV_LOG_ERROR, \"Out of memory\\n\");\n        exit_program(1);\n    }\n    desc = NULL;\n    while ((desc = avcodec_descriptor_next(desc)))\n        codecs[i++] = desc;\n    av_assert0(i == nb_codecs);\n    qsort(codecs, nb_codecs, sizeof(*codecs), compare_codec_desc);\n    *rcodecs = codecs;\n    return nb_codecs;\n}"}, {"function body": "static void print_codecs_for_id(enum AVCodecID id, int encoder)\n{\n    const AVCodec *codec = NULL;\n\n    printf(\" (%s: \", encoder ? \"encoders\" : \"decoders\");\n\n    while ((codec = next_codec_for_id(id, codec, encoder)))\n        printf(\"%s \", codec->name);\n\n    printf(\")\");\n}"}, {"function body": "int show_codecs(void *optctx, const char *opt, const char *arg)\n{\n    const AVCodecDescriptor **codecs;\n    unsigned i, nb_codecs = get_codecs_sorted(&codecs);\n\n    printf(\"Codecs:\\n\"\n           \" D..... = Decoding supported\\n\"\n           \" .E.... = Encoding supported\\n\"\n           \" ..V... = Video codec\\n\"\n           \" ..A... = Audio codec\\n\"\n           \" ..S... = Subtitle codec\\n\"\n           \" ...I.. = Intra frame-only codec\\n\"\n           \" ....L. = Lossy compression\\n\"\n           \" .....S = Lossless compression\\n\"\n           \" -------\\n\");\n    for (i = 0; i < nb_codecs; i++) {\n        const AVCodecDescriptor *desc = codecs[i];\n        const AVCodec *codec = NULL;\n\n        printf(\" \");\n        printf(avcodec_find_decoder(desc->id) ? \"D\" : \".\");\n        printf(avcodec_find_encoder(desc->id) ? \"E\" : \".\");\n\n        printf(\"%c\", get_media_type_char(desc->type));\n        printf((desc->props & AV_CODEC_PROP_INTRA_ONLY) ? \"I\" : \".\");\n        printf((desc->props & AV_CODEC_PROP_LOSSY)      ? \"L\" : \".\");\n        printf((desc->props & AV_CODEC_PROP_LOSSLESS)   ? \"S\" : \".\");\n\n        printf(\" %-20s %s\", desc->name, desc->long_name ? desc->long_name : \"\");\n\n        /* print decoders/encoders when there's more than one or their\n         * names are different from codec name */\n        while ((codec = next_codec_for_id(desc->id, codec, 0))) {\n            if (strcmp(codec->name, desc->name)) {\n                print_codecs_for_id(desc->id, 0);\n                break;\n            }\n        }\n        codec = NULL;\n        while ((codec = next_codec_for_id(desc->id, codec, 1))) {\n            if (strcmp(codec->name, desc->name)) {\n                print_codecs_for_id(desc->id, 1);\n                break;\n            }\n        }\n\n        printf(\"\\n\");\n    }\n    av_free(codecs);\n    return 0;\n}"}, {"function body": "static void print_codecs(int encoder)\n{\n    const AVCodecDescriptor **codecs;\n    unsigned i, nb_codecs = get_codecs_sorted(&codecs);\n\n    printf(\"%s:\\n\"\n           \" V..... = Video\\n\"\n           \" A..... = Audio\\n\"\n           \" S..... = Subtitle\\n\"\n           \" .F.... = Frame-level multithreading\\n\"\n           \" ..S... = Slice-level multithreading\\n\"\n           \" ...X.. = Codec is experimental\\n\"\n           \" ....B. = Supports draw_horiz_band\\n\"\n           \" .....D = Supports direct rendering method 1\\n\"\n           \" ------\\n\",\n           encoder ? \"Encoders\" : \"Decoders\");\n    for (i = 0; i < nb_codecs; i++) {\n        const AVCodecDescriptor *desc = codecs[i];\n        const AVCodec *codec = NULL;\n\n        while ((codec = next_codec_for_id(desc->id, codec, encoder))) {\n            printf(\" %c\", get_media_type_char(desc->type));\n            printf((codec->capabilities & CODEC_CAP_FRAME_THREADS) ? \"F\" : \".\");\n            printf((codec->capabilities & CODEC_CAP_SLICE_THREADS) ? \"S\" : \".\");\n            printf((codec->capabilities & CODEC_CAP_EXPERIMENTAL)  ? \"X\" : \".\");\n            printf((codec->capabilities & CODEC_CAP_DRAW_HORIZ_BAND)?\"B\" : \".\");\n            printf((codec->capabilities & CODEC_CAP_DR1)           ? \"D\" : \".\");\n\n            printf(\" %-20s %s\", codec->name, codec->long_name ? codec->long_name : \"\");\n            if (strcmp(codec->name, desc->name))\n                printf(\" (codec %s)\", desc->name);\n\n            printf(\"\\n\");\n        }\n    }\n    av_free(codecs);\n}"}, {"function body": "int show_decoders(void *optctx, const char *opt, const char *arg)\n{\n    print_codecs(0);\n    return 0;\n}"}, {"function body": "int show_encoders(void *optctx, const char *opt, const char *arg)\n{\n    print_codecs(1);\n    return 0;\n}"}, {"function body": "int show_bsfs(void *optctx, const char *opt, const char *arg)\n{\n    AVBitStreamFilter *bsf = NULL;\n\n    printf(\"Bitstream filters:\\n\");\n    while ((bsf = av_bitstream_filter_next(bsf)))\n        printf(\"%s\\n\", bsf->name);\n    printf(\"\\n\");\n    return 0;\n}"}, {"function body": "int show_protocols(void *optctx, const char *opt, const char *arg)\n{\n    void *opaque = NULL;\n    const char *name;\n\n    printf(\"Supported file protocols:\\n\"\n           \"Input:\\n\");\n    while ((name = avio_enum_protocols(&opaque, 0)))\n        printf(\"%s\\n\", name);\n    printf(\"Output:\\n\");\n    while ((name = avio_enum_protocols(&opaque, 1)))\n        printf(\"%s\\n\", name);\n    return 0;\n}"}, {"function body": "int show_filters(void *optctx, const char *opt, const char *arg)\n{\n    AVFilter av_unused(**filter) = NULL;\n    char descr[64], *descr_cur;\n    int i, j;\n    const AVFilterPad *pad;\n\n    printf(\"Filters:\\n\");\n#if CONFIG_AVFILTER\n    while ((filter = av_filter_next(filter)) && *filter) {\n        descr_cur = descr;\n        for (i = 0; i < 2; i++) {\n            if (i) {\n                *(descr_cur++) = '-';\n                *(descr_cur++) = '>';\n            }\n            pad = i ? (*filter)->outputs : (*filter)->inputs;\n            for (j = 0; pad && pad[j].name; j++) {\n                if (descr_cur >= descr + sizeof(descr) - 4)\n                    break;\n                *(descr_cur++) = get_media_type_char(pad[j].type);\n            }\n            if (!j)\n                *(descr_cur++) = '|';\n        }\n        *descr_cur = 0;\n        printf(\"%-16s %-10s %s\\n\", (*filter)->name, descr, (*filter)->description);\n    }\n#endif\n    return 0;\n}"}, {"function body": "int show_pix_fmts(void *optctx, const char *opt, const char *arg)\n{\n    enum PixelFormat pix_fmt;\n\n    printf(\"Pixel formats:\\n\"\n           \"I.... = Supported Input  format for conversion\\n\"\n           \".O... = Supported Output format for conversion\\n\"\n           \"..H.. = Hardware accelerated format\\n\"\n           \"...P. = Paletted format\\n\"\n           \"....B = Bitstream format\\n\"\n           \"FLAGS NAME            NB_COMPONENTS BITS_PER_PIXEL\\n\"\n           \"-----\\n\");\n\n#if !CONFIG_SWSCALE\n#   define sws_isSupportedInput(x)  0\n#   define sws_isSupportedOutput(x) 0\n#endif\n\n    for (pix_fmt = 0; pix_fmt < PIX_FMT_NB; pix_fmt++) {\n        const AVPixFmtDescriptor *pix_desc = &av_pix_fmt_descriptors[pix_fmt];\n        if(!pix_desc->name)\n            continue;\n        printf(\"%c%c%c%c%c %-16s       %d            %2d\\n\",\n               sws_isSupportedInput (pix_fmt)      ? 'I' : '.',\n               sws_isSupportedOutput(pix_fmt)      ? 'O' : '.',\n               pix_desc->flags & PIX_FMT_HWACCEL   ? 'H' : '.',\n               pix_desc->flags & PIX_FMT_PAL       ? 'P' : '.',\n               pix_desc->flags & PIX_FMT_BITSTREAM ? 'B' : '.',\n               pix_desc->name,\n               pix_desc->nb_components,\n               av_get_bits_per_pixel(pix_desc));\n    }\n    return 0;\n}"}, {"function body": "int show_layouts(void *optctx, const char *opt, const char *arg)\n{\n    int i = 0;\n    uint64_t layout, j;\n    const char *name, *descr;\n\n    printf(\"Individual channels:\\n\"\n           \"NAME        DESCRIPTION\\n\");\n    for (i = 0; i < 63; i++) {\n        name = av_get_channel_name((uint64_t)1 << i);\n        if (!name)\n            continue;\n        descr = av_get_channel_description((uint64_t)1 << i);\n        printf(\"%-12s%s\\n\", name, descr);\n    }\n    printf(\"\\nStandard channel layouts:\\n\"\n           \"NAME        DECOMPOSITION\\n\");\n    for (i = 0; !av_get_standard_channel_layout(i, &layout, &name); i++) {\n        if (name) {\n            printf(\"%-12s\", name);\n            for (j = 1; j; j <<= 1)\n                if ((layout & j))\n                    printf(\"%s%s\", (layout & (j - 1)) ? \"+\" : \"\", av_get_channel_name(j));\n            printf(\"\\n\");\n        }\n    }\n    return 0;\n}"}, {"function body": "int show_sample_fmts(void *optctx, const char *opt, const char *arg)\n{\n    int i;\n    char fmt_str[128];\n    for (i = -1; i < AV_SAMPLE_FMT_NB; i++)\n        printf(\"%s\\n\", av_get_sample_fmt_string(fmt_str, sizeof(fmt_str), i));\n    return 0;\n}"}, {"function body": "static void show_help_codec(const char *name, int encoder)\n{\n    const AVCodecDescriptor *desc;\n    const AVCodec *codec;\n\n    if (!name) {\n        av_log(NULL, AV_LOG_ERROR, \"No codec name specified.\\n\");\n        return;\n    }\n\n    codec = encoder ? avcodec_find_encoder_by_name(name) :\n                      avcodec_find_decoder_by_name(name);\n\n    if (codec)\n        print_codec(codec);\n    else if ((desc = avcodec_descriptor_get_by_name(name))) {\n        int printed = 0;\n\n        while ((codec = next_codec_for_id(desc->id, codec, encoder))) {\n            printed = 1;\n            print_codec(codec);\n        }\n\n        if (!printed) {\n            av_log(NULL, AV_LOG_ERROR, \"Codec '%s' is known to FFmpeg, \"\n                   \"but no %s for it are available. FFmpeg might need to be \"\n                   \"recompiled with additional external libraries.\\n\",\n                   name, encoder ? \"encoders\" : \"decoders\");\n        }\n    } else {\n        av_log(NULL, AV_LOG_ERROR, \"Codec '%s' is not recognized by FFmpeg.\\n\",\n               name);\n    }\n}"}, {"function body": "static void show_help_demuxer(const char *name)\n{\n    const AVInputFormat *fmt = av_find_input_format(name);\n\n    if (!fmt) {\n        av_log(NULL, AV_LOG_ERROR, \"Unknown format '%s'.\\n\", name);\n        return;\n    }\n\n    printf(\"Demuxer %s [%s]:\\n\", fmt->name, fmt->long_name);\n\n    if (fmt->extensions)\n        printf(\"    Common extensions: %s.\\n\", fmt->extensions);\n\n    if (fmt->priv_class)\n        show_help_children(fmt->priv_class, AV_OPT_FLAG_DECODING_PARAM);\n}"}, {"function body": "static void show_help_muxer(const char *name)\n{\n    const AVCodecDescriptor *desc;\n    const AVOutputFormat *fmt = av_guess_format(name, NULL, NULL);\n\n    if (!fmt) {\n        av_log(NULL, AV_LOG_ERROR, \"Unknown format '%s'.\\n\", name);\n        return;\n    }\n\n    printf(\"Muxer %s [%s]:\\n\", fmt->name, fmt->long_name);\n\n    if (fmt->extensions)\n        printf(\"    Common extensions: %s.\\n\", fmt->extensions);\n    if (fmt->mime_type)\n        printf(\"    Mime type: %s.\\n\", fmt->mime_type);\n    if (fmt->video_codec != AV_CODEC_ID_NONE &&\n        (desc = avcodec_descriptor_get(fmt->video_codec))) {\n        printf(\"    Default video codec: %s.\\n\", desc->name);\n    }\n    if (fmt->audio_codec != AV_CODEC_ID_NONE &&\n        (desc = avcodec_descriptor_get(fmt->audio_codec))) {\n        printf(\"    Default audio codec: %s.\\n\", desc->name);\n    }\n    if (fmt->subtitle_codec != AV_CODEC_ID_NONE &&\n        (desc = avcodec_descriptor_get(fmt->subtitle_codec))) {\n        printf(\"    Default subtitle codec: %s.\\n\", desc->name);\n    }\n\n    if (fmt->priv_class)\n        show_help_children(fmt->priv_class, AV_OPT_FLAG_ENCODING_PARAM);\n}"}, {"function body": "int show_help(void *optctx, const char *opt, const char *arg)\n{\n    char *topic, *par;\n    av_log_set_callback(log_callback_help);\n\n    topic = av_strdup(arg ? arg : \"\");\n    par = strchr(topic, '=');\n    if (par)\n        *par++ = 0;\n\n    if (!*topic) {\n        show_help_default(topic, par);\n    } else if (!strcmp(topic, \"decoder\")) {\n        show_help_codec(par, 0);\n    } else if (!strcmp(topic, \"encoder\")) {\n        show_help_codec(par, 1);\n    } else if (!strcmp(topic, \"demuxer\")) {\n        show_help_demuxer(par);\n    } else if (!strcmp(topic, \"muxer\")) {\n        show_help_muxer(par);\n    } else {\n        show_help_default(topic, par);\n    }\n\n    av_freep(&topic);\n    return 0;\n}"}, {"function body": "int read_yesno(void)\n{\n    int c = getchar();\n    int yesno = (toupper(c) == 'Y');\n\n    while (c != '\\n' && c != EOF)\n        c = getchar();\n\n    return yesno;\n}"}, {"function body": "int cmdutils_read_file(const char *filename, char **bufptr, size_t *size)\n{\n    int ret;\n    FILE *f = fopen(filename, \"rb\");\n\n    if (!f) {\n        av_log(NULL, AV_LOG_ERROR, \"Cannot read file '%s': %s\\n\", filename,\n               strerror(errno));\n        return AVERROR(errno);\n    }\n    fseek(f, 0, SEEK_END);\n    *size = ftell(f);\n    fseek(f, 0, SEEK_SET);\n    *bufptr = av_malloc(*size + 1);\n    if (!*bufptr) {\n        av_log(NULL, AV_LOG_ERROR, \"Could not allocate file buffer\\n\");\n        fclose(f);\n        return AVERROR(ENOMEM);\n    }\n    ret = fread(*bufptr, 1, *size, f);\n    if (ret < *size) {\n        av_free(*bufptr);\n        if (ferror(f)) {\n            av_log(NULL, AV_LOG_ERROR, \"Error while reading file '%s': %s\\n\",\n                   filename, strerror(errno));\n            ret = AVERROR(errno);\n        } else\n            ret = AVERROR_EOF;\n    } else {\n        ret = 0;\n        (*bufptr)[*size++] = '\\0';\n    }\n\n    fclose(f);\n    return ret;\n}"}, {"function body": "FILE *get_preset_file(char *filename, size_t filename_size,\n                      const char *preset_name, int is_path,\n                      const char *codec_name)\n{\n    FILE *f = NULL;\n    int i;\n    const char *base[3] = { getenv(\"FFMPEG_DATADIR\"),\n                            getenv(\"HOME\"),\n                            FFMPEG_DATADIR, };\n\n    if (is_path) {\n        av_strlcpy(filename, preset_name, filename_size);\n        f = fopen(filename, \"r\");\n    } else {\n#ifdef _WIN32\n        char datadir[MAX_PATH], *ls;\n        base[2] = NULL;\n\n        if (GetModuleFileNameA(GetModuleHandleA(NULL), datadir, sizeof(datadir) - 1))\n        {\n            for (ls = datadir; ls < datadir + strlen(datadir); ls++)\n                if (*ls == '\\\\') *ls = '/';\n\n            if (ls = strrchr(datadir, '/'))\n            {\n                *ls = 0;\n                strncat(datadir, \"/ffpresets\",  sizeof(datadir) - 1 - strlen(datadir));\n                base[2] = datadir;\n            }\n        }\n#endif\n        for (i = 0; i < 3 && !f; i++) {\n            if (!base[i])\n                continue;\n            snprintf(filename, filename_size, \"%s%s/%s.ffpreset\", base[i],\n                     i != 1 ? \"\" : \"/.ffmpeg\", preset_name);\n            f = fopen(filename, \"r\");\n            if (!f && codec_name) {\n                snprintf(filename, filename_size,\n                         \"%s%s/%s-%s.ffpreset\",\n                         base[i], i != 1 ? \"\" : \"/.ffmpeg\", codec_name,\n                         preset_name);\n                f = fopen(filename, \"r\");\n            }\n        }\n    }\n\n    return f;\n}"}, {"function body": "int check_stream_specifier(AVFormatContext *s, AVStream *st, const char *spec)\n{\n    int ret = avformat_match_stream_specifier(s, st, spec);\n    if (ret < 0)\n        av_log(s, AV_LOG_ERROR, \"Invalid stream specifier: %s.\\n\", spec);\n    return ret;\n}"}, {"function body": "AVDictionary *filter_codec_opts(AVDictionary *opts, enum AVCodecID codec_id,\n                                AVFormatContext *s, AVStream *st, AVCodec *codec)\n{\n    AVDictionary    *ret = NULL;\n    AVDictionaryEntry *t = NULL;\n    int            flags = s->oformat ? AV_OPT_FLAG_ENCODING_PARAM\n                                      : AV_OPT_FLAG_DECODING_PARAM;\n    char          prefix = 0;\n    const AVClass    *cc = avcodec_get_class();\n\n    if (!codec)\n        codec            = s->oformat ? avcodec_find_encoder(codec_id)\n                                      : avcodec_find_decoder(codec_id);\n    if (!codec)\n        return NULL;\n\n    switch (codec->type) {\n    case AVMEDIA_TYPE_VIDEO:\n        prefix  = 'v';\n        flags  |= AV_OPT_FLAG_VIDEO_PARAM;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        prefix  = 'a';\n        flags  |= AV_OPT_FLAG_AUDIO_PARAM;\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        prefix  = 's';\n        flags  |= AV_OPT_FLAG_SUBTITLE_PARAM;\n        break;\n    }\n\n    while (t = av_dict_get(opts, \"\", t, AV_DICT_IGNORE_SUFFIX)) {\n        char *p = strchr(t->key, ':');\n\n        /* check stream specification in opt name */\n        if (p)\n            switch (check_stream_specifier(s, st, p + 1)) {\n            case  1: *p = 0; break;\n            case  0:         continue;\n            default:         return NULL;\n            }\n\n        if (av_opt_find(&cc, t->key, NULL, flags, AV_OPT_SEARCH_FAKE_OBJ) ||\n            (codec && codec->priv_class &&\n             av_opt_find(&codec->priv_class, t->key, NULL, flags,\n                         AV_OPT_SEARCH_FAKE_OBJ)))\n            av_dict_set(&ret, t->key, t->value, 0);\n        else if (t->key[0] == prefix &&\n                 av_opt_find(&cc, t->key + 1, NULL, flags,\n                             AV_OPT_SEARCH_FAKE_OBJ))\n            av_dict_set(&ret, t->key + 1, t->value, 0);\n\n        if (p)\n            *p = ':';\n    }\n    return ret;\n}"}, {"function body": "AVDictionary **setup_find_stream_info_opts(AVFormatContext *s,\n                                           AVDictionary *codec_opts)\n{\n    int i;\n    AVDictionary **opts;\n\n    if (!s->nb_streams)\n        return NULL;\n    opts = av_mallocz(s->nb_streams * sizeof(*opts));\n    if (!opts) {\n        av_log(NULL, AV_LOG_ERROR,\n               \"Could not alloc memory for stream options.\\n\");\n        return NULL;\n    }\n    for (i = 0; i < s->nb_streams; i++)\n        opts[i] = filter_codec_opts(codec_opts, s->streams[i]->codec->codec_id,\n                                    s, s->streams[i], NULL);\n    return opts;\n}"}, {"function body": "void *grow_array(void *array, int elem_size, int *size, int new_size)\n{\n    if (new_size >= INT_MAX / elem_size) {\n        av_log(NULL, AV_LOG_ERROR, \"Array too big.\\n\");\n        exit_program(1);\n    }\n    if (*size < new_size) {\n        uint8_t *tmp = av_realloc(array, new_size*elem_size);\n        if (!tmp) {\n            av_log(NULL, AV_LOG_ERROR, \"Could not alloc buffer.\\n\");\n            exit_program(1);\n        }\n        memset(tmp + *size*elem_size, 0, (new_size-*size) * elem_size);\n        *size = new_size;\n        return tmp;\n    }\n    return array;\n}"}, {"function body": "static int alloc_buffer(FrameBuffer **pool, AVCodecContext *s, FrameBuffer **pbuf)\n{\n    FrameBuffer  *buf = av_mallocz(sizeof(*buf));\n    int i, ret;\n    const int pixel_size = av_pix_fmt_descriptors[s->pix_fmt].comp[0].step_minus1+1;\n    int h_chroma_shift, v_chroma_shift;\n    int edge = 32; // XXX should be avcodec_get_edge_width(), but that fails on svq1\n    int w = s->width, h = s->height;\n\n    if (!buf)\n        return AVERROR(ENOMEM);\n\n    avcodec_align_dimensions(s, &w, &h);\n\n    if (!(s->flags & CODEC_FLAG_EMU_EDGE)) {\n        w += 2*edge;\n        h += 2*edge;\n    }\n\n    if ((ret = av_image_alloc(buf->base, buf->linesize, w, h,\n                              s->pix_fmt, 32)) < 0) {\n        av_freep(&buf);\n        av_log(s, AV_LOG_ERROR, \"alloc_buffer: av_image_alloc() failed\\n\");\n        return ret;\n    }\n    /* XXX this shouldn't be needed, but some tests break without this line\n     * those decoders are buggy and need to be fixed.\n     * the following tests fail:\n     * cdgraphics, ansi, aasc, fraps-v1, qtrle-1bit\n     */\n    memset(buf->base[0], 128, ret);\n\n    avcodec_get_chroma_sub_sample(s->pix_fmt, &h_chroma_shift, &v_chroma_shift);\n    for (i = 0; i < FF_ARRAY_ELEMS(buf->data); i++) {\n        const int h_shift = i==0 ? 0 : h_chroma_shift;\n        const int v_shift = i==0 ? 0 : v_chroma_shift;\n        if ((s->flags & CODEC_FLAG_EMU_EDGE) || !buf->linesize[i] || !buf->base[i])\n            buf->data[i] = buf->base[i];\n        else\n            buf->data[i] = buf->base[i] +\n                           FFALIGN((buf->linesize[i]*edge >> v_shift) +\n                                   (pixel_size*edge >> h_shift), 32);\n    }\n    buf->w       = s->width;\n    buf->h       = s->height;\n    buf->pix_fmt = s->pix_fmt;\n    buf->pool    = pool;\n\n    *pbuf = buf;\n    return 0;\n}"}, {"function body": "int codec_get_buffer(AVCodecContext *s, AVFrame *frame)\n{\n    FrameBuffer **pool = s->opaque;\n    FrameBuffer *buf;\n    int ret, i;\n\n    if(av_image_check_size(s->width, s->height, 0, s) || s->pix_fmt<0) {\n        av_log(s, AV_LOG_ERROR, \"codec_get_buffer: image parameters invalid\\n\");\n        return -1;\n    }\n\n    if (!*pool && (ret = alloc_buffer(pool, s, pool)) < 0)\n        return ret;\n\n    buf              = *pool;\n    *pool            = buf->next;\n    buf->next        = NULL;\n    if (buf->w != s->width || buf->h != s->height || buf->pix_fmt != s->pix_fmt) {\n        av_freep(&buf->base[0]);\n        av_free(buf);\n        if ((ret = alloc_buffer(pool, s, &buf)) < 0)\n            return ret;\n    }\n    av_assert0(!buf->refcount);\n    buf->refcount++;\n\n    frame->opaque        = buf;\n    frame->type          = FF_BUFFER_TYPE_USER;\n    frame->extended_data = frame->data;\n    frame->pkt_pts       = s->pkt ? s->pkt->pts : AV_NOPTS_VALUE;\n    frame->width         = buf->w;\n    frame->height        = buf->h;\n    frame->format        = buf->pix_fmt;\n    frame->sample_aspect_ratio = s->sample_aspect_ratio;\n\n    for (i = 0; i < FF_ARRAY_ELEMS(buf->data); i++) {\n        frame->base[i]     = buf->base[i];  // XXX h264.c uses base though it shouldn't\n        frame->data[i]     = buf->data[i];\n        frame->linesize[i] = buf->linesize[i];\n    }\n\n    return 0;\n}"}, {"function body": "static void unref_buffer(FrameBuffer *buf)\n{\n    FrameBuffer **pool = buf->pool;\n\n    av_assert0(buf->refcount > 0);\n    buf->refcount--;\n    if (!buf->refcount) {\n        FrameBuffer *tmp;\n        for(tmp= *pool; tmp; tmp= tmp->next)\n            av_assert1(tmp != buf);\n\n        buf->next = *pool;\n        *pool = buf;\n    }\n}"}, {"function body": "void codec_release_buffer(AVCodecContext *s, AVFrame *frame)\n{\n    FrameBuffer *buf = frame->opaque;\n    int i;\n\n    if(frame->type!=FF_BUFFER_TYPE_USER) {\n        avcodec_default_release_buffer(s, frame);\n        return;\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(frame->data); i++)\n        frame->data[i] = NULL;\n\n    unref_buffer(buf);\n}"}, {"function body": "void filter_release_buffer(AVFilterBuffer *fb)\n{\n    FrameBuffer *buf = fb->priv;\n    av_free(fb);\n    unref_buffer(buf);\n}"}, {"function body": "void free_buffer_pool(FrameBuffer **pool)\n{\n    FrameBuffer *buf = *pool;\n    while (buf) {\n        *pool = buf->next;\n        av_freep(&buf->base[0]);\n        av_free(buf);\n        buf = *pool;\n    }\n}"}]}, {"ffmpeg.c": [{"function body": "static void sub2video_copy_rect(uint8_t *dst, int dst_linesize, int w, int h,\n                                AVSubtitleRect *r)\n{\n    uint32_t *pal, *dst2;\n    uint8_t *src, *src2;\n    int x, y;\n\n    if (r->type != SUBTITLE_BITMAP) {\n        av_log(NULL, AV_LOG_WARNING, \"sub2video: non-bitmap subtitle\\n\");\n        return;\n    }\n    if (r->x < 0 || r->x + r->w > w || r->y < 0 || r->y + r->h > h) {\n        av_log(NULL, AV_LOG_WARNING, \"sub2video: rectangle overflowing\\n\");\n        return;\n    }\n\n    dst += r->y * dst_linesize + r->x * 4;\n    src = r->pict.data[0];\n    pal = (uint32_t *)r->pict.data[1];\n    for (y = 0; y < r->h; y++) {\n        dst2 = (uint32_t *)dst;\n        src2 = src;\n        for (x = 0; x < r->w; x++)\n            *(dst2++) = pal[*(src2++)];\n        dst += dst_linesize;\n        src += r->pict.linesize[0];\n    }\n}"}, {"function body": "static void sub2video_push_ref(InputStream *ist, int64_t pts)\n{\n    AVFilterBufferRef *ref = ist->sub2video.ref;\n    int i;\n\n    ist->sub2video.last_pts = ref->pts = pts;\n    for (i = 0; i < ist->nb_filters; i++)\n        av_buffersrc_add_ref(ist->filters[i]->filter,\n                             avfilter_ref_buffer(ref, ~0),\n                             AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT |\n                             AV_BUFFERSRC_FLAG_NO_COPY |\n                             AV_BUFFERSRC_FLAG_PUSH);\n}"}, {"function body": "static void sub2video_update(InputStream *ist, AVSubtitle *sub)\n{\n    int w = ist->sub2video.w, h = ist->sub2video.h;\n    AVFilterBufferRef *ref = ist->sub2video.ref;\n    int8_t *dst;\n    int     dst_linesize;\n    int i;\n    int64_t pts = av_rescale_q(sub->pts, AV_TIME_BASE_Q, ist->st->time_base);\n\n    if (!ref)\n        return;\n    dst          = ref->data    [0];\n    dst_linesize = ref->linesize[0];\n    memset(dst, 0, h * dst_linesize);\n    for (i = 0; i < sub->num_rects; i++)\n        sub2video_copy_rect(dst, dst_linesize, w, h, sub->rects[i]);\n    sub2video_push_ref(ist, pts);\n}"}, {"function body": "static void sub2video_heartbeat(InputStream *ist, int64_t pts)\n{\n    InputFile *infile = input_files[ist->file_index];\n    int i, j, nb_reqs;\n    int64_t pts2;\n\n    /* When a frame is read from a file, examine all sub2video streams in\n       the same file and send the sub2video frame again. Otherwise, decoded\n       video frames could be accumulating in the filter graph while a filter\n       (possibly overlay) is desperately waiting for a subtitle frame. */\n    for (i = 0; i < infile->nb_streams; i++) {\n        InputStream *ist2 = input_streams[infile->ist_index + i];\n        if (!ist2->sub2video.ref)\n            continue;\n        /* subtitles seem to be usually muxed ahead of other streams;\n           if not, substracting a larger time here is necessary */\n        pts2 = av_rescale_q(pts, ist->st->time_base, ist2->st->time_base) - 1;\n        /* do not send the heartbeat frame if the subtitle is already ahead */\n        if (pts2 <= ist2->sub2video.last_pts)\n            continue;\n        for (j = 0, nb_reqs = 0; j < ist2->nb_filters; j++)\n            nb_reqs += av_buffersrc_get_nb_failed_requests(ist2->filters[j]->filter);\n        if (nb_reqs)\n            sub2video_push_ref(ist2, pts2);\n    }\n}"}, {"function body": "static void sub2video_flush(InputStream *ist)\n{\n    int i;\n\n    for (i = 0; i < ist->nb_filters; i++)\n        av_buffersrc_add_ref(ist->filters[i]->filter, NULL, 0);\n}"}, {"function body": "void term_exit(void)\n{\n    av_log(NULL, AV_LOG_QUIET, \"%s\", \"\");\n#if HAVE_TERMIOS_H\n    if(restore_tty)\n        tcsetattr (0, TCSANOW, &oldtty);\n#endif\n}"}, {"function body": "static void\nsigterm_handler(int sig)\n{\n    received_sigterm = sig;\n    received_nb_signals++;\n    term_exit();\n    if(received_nb_signals > 3)\n        exit(123);\n}"}, {"function body": "void term_init(void)\n{\n#if HAVE_TERMIOS_H\n    if(!run_as_daemon){\n        struct termios tty;\n        int istty = 1;\n#if HAVE_ISATTY\n        istty = isatty(0) && isatty(2);\n#endif\n        if (istty && tcgetattr (0, &tty) == 0) {\n            oldtty = tty;\n            restore_tty = 1;\n            atexit(term_exit);\n\n            tty.c_iflag &= ~(IGNBRK|BRKINT|PARMRK|ISTRIP\n                             |INLCR|IGNCR|ICRNL|IXON);\n            tty.c_oflag |= OPOST;\n            tty.c_lflag &= ~(ECHO|ECHONL|ICANON|IEXTEN);\n            tty.c_cflag &= ~(CSIZE|PARENB);\n            tty.c_cflag |= CS8;\n            tty.c_cc[VMIN] = 1;\n            tty.c_cc[VTIME] = 0;\n\n            tcsetattr (0, TCSANOW, &tty);\n        }\n        signal(SIGQUIT, sigterm_handler); /* Quit (POSIX).  */\n    }\n#endif\n    avformat_network_deinit();\n\n    signal(SIGINT , sigterm_handler); /* Interrupt (ANSI).    */\n    signal(SIGTERM, sigterm_handler); /* Termination (ANSI).  */\n#ifdef SIGXCPU\n    signal(SIGXCPU, sigterm_handler);\n#endif\n}"}, {"function body": "static int read_key(void)\n{\n    unsigned char ch;\n#if HAVE_TERMIOS_H\n    int n = 1;\n    struct timeval tv;\n    fd_set rfds;\n\n    FD_ZERO(&rfds);\n    FD_SET(0, &rfds);\n    tv.tv_sec = 0;\n    tv.tv_usec = 0;\n    n = select(1, &rfds, NULL, NULL, &tv);\n    if (n > 0) {\n        n = read(0, &ch, 1);\n        if (n == 1)\n            return ch;\n\n        return n;\n    }\n#elif HAVE_KBHIT\n#    if HAVE_PEEKNAMEDPIPE\n    static int is_pipe;\n    static HANDLE input_handle;\n    DWORD dw, nchars;\n    if(!input_handle){\n        input_handle = GetStdHandle(STD_INPUT_HANDLE);\n        is_pipe = !GetConsoleMode(input_handle, &dw);\n    }\n\n    if (stdin->_cnt > 0) {\n        read(0, &ch, 1);\n        return ch;\n    }\n    if (is_pipe) {\n        /* When running under a GUI, you will end here. */\n        if (!PeekNamedPipe(input_handle, NULL, 0, NULL, &nchars, NULL))\n            return -1;\n        //Read it\n        if(nchars != 0) {\n            read(0, &ch, 1);\n            return ch;\n        }else{\n            return -1;\n        }\n    }\n#    endif\n    if(kbhit())\n        return(getch());\n#endif\n    return -1;\n}"}, {"function body": "static int decode_interrupt_cb(void *ctx)\n{\n    return received_nb_signals > 1;\n}"}, {"function body": "av_noreturn exit_program(int ret)\n{\n    int i, j;\n\n    for (i = 0; i < nb_filtergraphs; i++) {\n        avfilter_graph_free(&filtergraphs[i]->graph);\n        for (j = 0; j < filtergraphs[i]->nb_inputs; j++) {\n            av_freep(&filtergraphs[i]->inputs[j]->name);\n            av_freep(&filtergraphs[i]->inputs[j]);\n        }\n        av_freep(&filtergraphs[i]->inputs);\n        for (j = 0; j < filtergraphs[i]->nb_outputs; j++) {\n            av_freep(&filtergraphs[i]->outputs[j]->name);\n            av_freep(&filtergraphs[i]->outputs[j]);\n        }\n        av_freep(&filtergraphs[i]->outputs);\n        av_freep(&filtergraphs[i]);\n    }\n    av_freep(&filtergraphs);\n\n    av_freep(&subtitle_out);\n\n    /* close files */\n    for (i = 0; i < nb_output_files; i++) {\n        AVFormatContext *s = output_files[i]->ctx;\n        if (!(s->oformat->flags & AVFMT_NOFILE) && s->pb)\n            avio_close(s->pb);\n        avformat_free_context(s);\n        av_dict_free(&output_files[i]->opts);\n        av_freep(&output_files[i]);\n    }\n    for (i = 0; i < nb_output_streams; i++) {\n        AVBitStreamFilterContext *bsfc = output_streams[i]->bitstream_filters;\n        while (bsfc) {\n            AVBitStreamFilterContext *next = bsfc->next;\n            av_bitstream_filter_close(bsfc);\n            bsfc = next;\n        }\n        output_streams[i]->bitstream_filters = NULL;\n        avcodec_free_frame(&output_streams[i]->filtered_frame);\n\n        av_freep(&output_streams[i]->forced_keyframes);\n        av_freep(&output_streams[i]->avfilter);\n        av_freep(&output_streams[i]->logfile_prefix);\n        av_freep(&output_streams[i]);\n    }\n    for (i = 0; i < nb_input_files; i++) {\n        avformat_close_input(&input_files[i]->ctx);\n        av_freep(&input_files[i]);\n    }\n    for (i = 0; i < nb_input_streams; i++) {\n        avcodec_free_frame(&input_streams[i]->decoded_frame);\n        av_dict_free(&input_streams[i]->opts);\n        free_buffer_pool(&input_streams[i]->buffer_pool);\n        avfilter_unref_bufferp(&input_streams[i]->sub2video.ref);\n        av_freep(&input_streams[i]->filters);\n        av_freep(&input_streams[i]);\n    }\n\n    if (vstats_file)\n        fclose(vstats_file);\n    av_free(vstats_filename);\n\n    av_freep(&input_streams);\n    av_freep(&input_files);\n    av_freep(&output_streams);\n    av_freep(&output_files);\n\n    uninit_opts();\n\n    avfilter_uninit();\n    avformat_network_deinit();\n\n    if (received_sigterm) {\n        av_log(NULL, AV_LOG_INFO, \"Received signal %d: terminating.\\n\",\n               (int) received_sigterm);\n        exit (255);\n    }\n\n    exit(ret);\n}"}, {"function body": "void assert_avoptions(AVDictionary *m)\n{\n    AVDictionaryEntry *t;\n    if ((t = av_dict_get(m, \"\", NULL, AV_DICT_IGNORE_SUFFIX))) {\n        av_log(NULL, AV_LOG_FATAL, \"Option %s not found.\\n\", t->key);\n        exit_program(1);\n    }\n}"}, {"function body": "static void assert_codec_experimental(AVCodecContext *c, int encoder)\n{\n    const char *codec_string = encoder ? \"encoder\" : \"decoder\";\n    AVCodec *codec;\n    if (c->codec->capabilities & CODEC_CAP_EXPERIMENTAL &&\n        c->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        av_log(NULL, AV_LOG_FATAL, \"%s '%s' is experimental and might produce bad \"\n                \"results.\\nAdd '-strict experimental' if you want to use it.\\n\",\n                codec_string, c->codec->name);\n        codec = encoder ? avcodec_find_encoder(c->codec->id) : avcodec_find_decoder(c->codec->id);\n        if (!(codec->capabilities & CODEC_CAP_EXPERIMENTAL))\n            av_log(NULL, AV_LOG_FATAL, \"Or use the non experimental %s '%s'.\\n\",\n                   codec_string, codec->name);\n        exit_program(1);\n    }\n}"}, {"function body": "static void update_benchmark(const char *fmt, ...)\n{\n    if (do_benchmark_all) {\n        int64_t t = getutime();\n        va_list va;\n        char buf[1024];\n\n        if (fmt) {\n            va_start(va, fmt);\n            vsnprintf(buf, sizeof(buf), fmt, va);\n            va_end(va);\n            printf(\"bench: %8\"PRIu64\" %s \\n\", t - current_time, buf);\n        }\n        current_time = t;\n    }\n}"}, {"function body": "static void write_frame(AVFormatContext *s, AVPacket *pkt, OutputStream *ost)\n{\n    AVBitStreamFilterContext *bsfc = ost->bitstream_filters;\n    AVCodecContext          *avctx = ost->st->codec;\n    int ret;\n\n    if ((avctx->codec_type == AVMEDIA_TYPE_VIDEO && video_sync_method == VSYNC_DROP) ||\n        (avctx->codec_type == AVMEDIA_TYPE_AUDIO && audio_sync_method < 0))\n        pkt->pts = pkt->dts = AV_NOPTS_VALUE;\n\n    if ((avctx->codec_type == AVMEDIA_TYPE_AUDIO || avctx->codec_type == AVMEDIA_TYPE_VIDEO) && pkt->dts != AV_NOPTS_VALUE) {\n        int64_t max = ost->st->cur_dts + !(s->oformat->flags & AVFMT_TS_NONSTRICT);\n        if (ost->st->cur_dts && ost->st->cur_dts != AV_NOPTS_VALUE &&  max > pkt->dts) {\n            av_log(s, max - pkt->dts > 2 || avctx->codec_type == AVMEDIA_TYPE_VIDEO ? AV_LOG_WARNING : AV_LOG_DEBUG,\n                   \"st:%d PTS: %\"PRId64\" DTS: %\"PRId64\" < %\"PRId64\" invalid, clipping\\n\", pkt->stream_index, pkt->pts, pkt->dts, max);\n            if(pkt->pts >= pkt->dts)\n                pkt->pts = FFMAX(pkt->pts, max);\n            pkt->dts = max;\n        }\n    }\n\n    /*\n     * Audio encoders may split the packets --  #frames in != #packets out.\n     * But there is no reordering, so we can limit the number of output packets\n     * by simply dropping them here.\n     * Counting encoded video frames needs to be done separately because of\n     * reordering, see do_video_out()\n     */\n    if (!(avctx->codec_type == AVMEDIA_TYPE_VIDEO && avctx->codec)) {\n        if (ost->frame_number >= ost->max_frames) {\n            av_free_packet(pkt);\n            return;\n        }\n        ost->frame_number++;\n    }\n\n    while (bsfc) {\n        AVPacket new_pkt = *pkt;\n        int a = av_bitstream_filter_filter(bsfc, avctx, NULL,\n                                           &new_pkt.data, &new_pkt.size,\n                                           pkt->data, pkt->size,\n                                           pkt->flags & AV_PKT_FLAG_KEY);\n        if(a == 0 && new_pkt.data != pkt->data && new_pkt.destruct) {\n            uint8_t *t = av_malloc(new_pkt.size + FF_INPUT_BUFFER_PADDING_SIZE); //the new should be a subset of the old so cannot overflow\n            if(t) {\n                memcpy(t, new_pkt.data, new_pkt.size);\n                memset(t + new_pkt.size, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n                new_pkt.data = t;\n                a = 1;\n            } else\n                a = AVERROR(ENOMEM);\n        }\n        if (a > 0) {\n            av_free_packet(pkt);\n            new_pkt.destruct = av_destruct_packet;\n        } else if (a < 0) {\n            av_log(NULL, AV_LOG_ERROR, \"Failed to open bitstream filter %s for stream %d with codec %s\",\n                   bsfc->filter->name, pkt->stream_index,\n                   avctx->codec ? avctx->codec->name : \"copy\");\n            print_error(\"\", a);\n            if (exit_on_error)\n                exit_program(1);\n        }\n        *pkt = new_pkt;\n\n        bsfc = bsfc->next;\n    }\n\n    pkt->stream_index = ost->index;\n\n    if (debug_ts) {\n        av_log(NULL, AV_LOG_INFO, \"muxer <- type:%s \"\n                \"pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s\\n\",\n                av_get_media_type_string(ost->st->codec->codec_type),\n                av_ts2str(pkt->pts), av_ts2timestr(pkt->pts, &ost->st->time_base),\n                av_ts2str(pkt->dts), av_ts2timestr(pkt->dts, &ost->st->time_base)\n              );\n    }\n\n    ret = av_interleaved_write_frame(s, pkt);\n    if (ret < 0) {\n        print_error(\"av_interleaved_write_frame()\", ret);\n        exit_program(1);\n    }\n}"}, {"function body": "static void close_output_stream(OutputStream *ost)\n{\n    OutputFile *of = output_files[ost->file_index];\n\n    ost->finished = 1;\n    if (of->shortest) {\n        int i;\n        for (i = 0; i < of->ctx->nb_streams; i++)\n            output_streams[of->ost_index + i]->finished = 1;\n    }\n}"}, {"function body": "static int check_recording_time(OutputStream *ost)\n{\n    OutputFile *of = output_files[ost->file_index];\n\n    if (of->recording_time != INT64_MAX &&\n        av_compare_ts(ost->sync_opts - ost->first_pts, ost->st->codec->time_base, of->recording_time,\n                      AV_TIME_BASE_Q) >= 0) {\n        close_output_stream(ost);\n        return 0;\n    }\n    return 1;\n}"}, {"function body": "static void do_audio_out(AVFormatContext *s, OutputStream *ost,\n                         AVFrame *frame)\n{\n    AVCodecContext *enc = ost->st->codec;\n    AVPacket pkt;\n    int got_packet = 0;\n\n    av_init_packet(&pkt);\n    pkt.data = NULL;\n    pkt.size = 0;\n\n    if (!check_recording_time(ost))\n        return;\n\n    if (frame->pts == AV_NOPTS_VALUE || audio_sync_method < 0)\n        frame->pts = ost->sync_opts;\n    ost->sync_opts = frame->pts + frame->nb_samples;\n\n    av_assert0(pkt.size || !pkt.data);\n    update_benchmark(NULL);\n    if (avcodec_encode_audio2(enc, &pkt, frame, &got_packet) < 0) {\n        av_log(NULL, AV_LOG_FATAL, \"Audio encoding failed (avcodec_encode_audio2)\\n\");\n        exit_program(1);\n    }\n    update_benchmark(\"encode_audio %d.%d\", ost->file_index, ost->index);\n\n    if (got_packet) {\n        if (pkt.pts != AV_NOPTS_VALUE)\n            pkt.pts      = av_rescale_q(pkt.pts,      enc->time_base, ost->st->time_base);\n        if (pkt.dts != AV_NOPTS_VALUE)\n            pkt.dts      = av_rescale_q(pkt.dts,      enc->time_base, ost->st->time_base);\n        if (pkt.duration > 0)\n            pkt.duration = av_rescale_q(pkt.duration, enc->time_base, ost->st->time_base);\n\n        if (debug_ts) {\n            av_log(NULL, AV_LOG_INFO, \"encoder -> type:audio \"\n                   \"pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s\\n\",\n                   av_ts2str(pkt.pts), av_ts2timestr(pkt.pts, &ost->st->time_base),\n                   av_ts2str(pkt.dts), av_ts2timestr(pkt.dts, &ost->st->time_base));\n        }\n\n        audio_size += pkt.size;\n        write_frame(s, &pkt, ost);\n\n        av_free_packet(&pkt);\n    }\n}"}, {"function body": "static void pre_process_video_frame(InputStream *ist, AVPicture *picture, void **bufp)\n{\n    AVCodecContext *dec;\n    AVPicture *picture2;\n    AVPicture picture_tmp;\n    uint8_t *buf = 0;\n\n    dec = ist->st->codec;\n\n    /* deinterlace : must be done before any resize */\n    if (do_deinterlace) {\n        int size;\n\n        /* create temporary picture */\n        size = avpicture_get_size(dec->pix_fmt, dec->width, dec->height);\n        buf  = av_malloc(size);\n        if (!buf)\n            return;\n\n        picture2 = &picture_tmp;\n        avpicture_fill(picture2, buf, dec->pix_fmt, dec->width, dec->height);\n\n        if (avpicture_deinterlace(picture2, picture,\n                                 dec->pix_fmt, dec->width, dec->height) < 0) {\n            /* if error, do not deinterlace */\n            av_log(NULL, AV_LOG_WARNING, \"Deinterlacing failed\\n\");\n            av_free(buf);\n            buf = NULL;\n            picture2 = picture;\n        }\n    } else {\n        picture2 = picture;\n    }\n\n    if (picture != picture2)\n        *picture = *picture2;\n    *bufp = buf;\n}"}, {"function body": "static void do_subtitle_out(AVFormatContext *s,\n                            OutputStream *ost,\n                            InputStream *ist,\n                            AVSubtitle *sub)\n{\n    int subtitle_out_max_size = 1024 * 1024;\n    int subtitle_out_size, nb, i;\n    AVCodecContext *enc;\n    AVPacket pkt;\n    int64_t pts;\n\n    if (sub->pts == AV_NOPTS_VALUE) {\n        av_log(NULL, AV_LOG_ERROR, \"Subtitle packets must have a pts\\n\");\n        if (exit_on_error)\n            exit_program(1);\n        return;\n    }\n\n    enc = ost->st->codec;\n\n    if (!subtitle_out) {\n        subtitle_out = av_malloc(subtitle_out_max_size);\n    }\n\n    /* Note: DVB subtitle need one packet to draw them and one other\n       packet to clear them */\n    /* XXX: signal it in the codec context ? */\n    if (enc->codec_id == AV_CODEC_ID_DVB_SUBTITLE)\n        nb = 2;\n    else\n        nb = 1;\n\n    /* shift timestamp to honor -ss and make check_recording_time() work with -t */\n    pts = sub->pts - output_files[ost->file_index]->start_time;\n    for (i = 0; i < nb; i++) {\n        ost->sync_opts = av_rescale_q(pts, AV_TIME_BASE_Q, enc->time_base);\n        if (!check_recording_time(ost))\n            return;\n\n        sub->pts = pts;\n        // start_display_time is required to be 0\n        sub->pts               += av_rescale_q(sub->start_display_time, (AVRational){ 1, 1000 }, AV_TIME_BASE_Q);\n        sub->end_display_time  -= sub->start_display_time;\n        sub->start_display_time = 0;\n        if (i == 1)\n            sub->num_rects = 0;\n        subtitle_out_size = avcodec_encode_subtitle(enc, subtitle_out,\n                                                    subtitle_out_max_size, sub);\n        if (subtitle_out_size < 0) {\n            av_log(NULL, AV_LOG_FATAL, \"Subtitle encoding failed\\n\");\n            exit_program(1);\n        }\n\n        av_init_packet(&pkt);\n        pkt.data = subtitle_out;\n        pkt.size = subtitle_out_size;\n        pkt.pts  = av_rescale_q(sub->pts, AV_TIME_BASE_Q, ost->st->time_base);\n        pkt.duration = av_rescale_q(sub->end_display_time, (AVRational){ 1, 1000 }, ost->st->time_base);\n        if (enc->codec_id == AV_CODEC_ID_DVB_SUBTITLE) {\n            /* XXX: the pts correction is handled here. Maybe handling\n               it in the codec would be better */\n            if (i == 0)\n                pkt.pts += 90 * sub->start_display_time;\n            else\n                pkt.pts += 90 * sub->end_display_time;\n        }\n        subtitle_size += pkt.size;\n        write_frame(s, &pkt, ost);\n    }\n}"}, {"function body": "static void do_video_out(AVFormatContext *s,\n                         OutputStream *ost,\n                         AVFrame *in_picture,\n                         float quality)\n{\n    int ret, format_video_sync;\n    AVPacket pkt;\n    AVCodecContext *enc = ost->st->codec;\n    int nb_frames, i;\n    double sync_ipts, delta;\n    double duration = 0;\n    int frame_size = 0;\n    InputStream *ist = NULL;\n\n    if (ost->source_index >= 0)\n        ist = input_streams[ost->source_index];\n\n    if(ist && ist->st->start_time != AV_NOPTS_VALUE && ist->st->first_dts != AV_NOPTS_VALUE && ost->frame_rate.num)\n        duration = 1/(av_q2d(ost->frame_rate) * av_q2d(enc->time_base));\n\n    sync_ipts = in_picture->pts;\n    delta = sync_ipts - ost->sync_opts + duration;\n\n    /* by default, we output a single frame */\n    nb_frames = 1;\n\n    format_video_sync = video_sync_method;\n    if (format_video_sync == VSYNC_AUTO)\n        format_video_sync = (s->oformat->flags & AVFMT_VARIABLE_FPS) ? ((s->oformat->flags & AVFMT_NOTIMESTAMPS) ? VSYNC_PASSTHROUGH : VSYNC_VFR) : 1;\n\n    switch (format_video_sync) {\n    case VSYNC_CFR:\n        // FIXME set to 0.5 after we fix some dts/pts bugs like in avidec.c\n        if (delta < -1.1)\n            nb_frames = 0;\n        else if (delta > 1.1)\n            nb_frames = lrintf(delta);\n        break;\n    case VSYNC_VFR:\n        if (delta <= -0.6)\n            nb_frames = 0;\n        else if (delta > 0.6)\n            ost->sync_opts = lrint(sync_ipts);\n        break;\n    case VSYNC_DROP:\n    case VSYNC_PASSTHROUGH:\n        ost->sync_opts = lrint(sync_ipts);\n        break;\n    default:\n        av_assert0(0);\n    }\n\n    nb_frames = FFMIN(nb_frames, ost->max_frames - ost->frame_number);\n    if (nb_frames == 0) {\n        nb_frames_drop++;\n        av_log(NULL, AV_LOG_VERBOSE, \"*** drop!\\n\");\n        return;\n    } else if (nb_frames > 1) {\n        if (nb_frames > dts_error_threshold * 30) {\n            av_log(NULL, AV_LOG_ERROR, \"%d frame duplication too large, skipping\\n\", nb_frames - 1);\n            nb_frames_drop++;\n            return;\n        }\n        nb_frames_dup += nb_frames - 1;\n        av_log(NULL, AV_LOG_VERBOSE, \"*** %d dup!\\n\", nb_frames - 1);\n    }\n\n  /* duplicates frame if needed */\n  for (i = 0; i < nb_frames; i++) {\n    av_init_packet(&pkt);\n    pkt.data = NULL;\n    pkt.size = 0;\n\n    in_picture->pts = ost->sync_opts;\n\n    if (!check_recording_time(ost))\n        return;\n\n    if (s->oformat->flags & AVFMT_RAWPICTURE &&\n        enc->codec->id == AV_CODEC_ID_RAWVIDEO) {\n        /* raw pictures are written as AVPicture structure to\n           avoid any copies. We support temporarily the older\n           method. */\n        enc->coded_frame->interlaced_frame = in_picture->interlaced_frame;\n        enc->coded_frame->top_field_first  = in_picture->top_field_first;\n        pkt.data   = (uint8_t *)in_picture;\n        pkt.size   =  sizeof(AVPicture);\n        pkt.pts    = av_rescale_q(in_picture->pts, enc->time_base, ost->st->time_base);\n        pkt.flags |= AV_PKT_FLAG_KEY;\n\n        video_size += pkt.size;\n        write_frame(s, &pkt, ost);\n    } else {\n        int got_packet;\n        AVFrame big_picture;\n\n        big_picture = *in_picture;\n        /* better than nothing: use input picture interlaced\n           settings */\n        big_picture.interlaced_frame = in_picture->interlaced_frame;\n        if (ost->st->codec->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME)) {\n            if (ost->top_field_first == -1)\n                big_picture.top_field_first = in_picture->top_field_first;\n            else\n                big_picture.top_field_first = !!ost->top_field_first;\n        }\n\n        /* handles same_quant here. This is not correct because it may\n           not be a global option */\n        big_picture.quality = quality;\n        if (!enc->me_threshold)\n            big_picture.pict_type = 0;\n        if (ost->forced_kf_index < ost->forced_kf_count &&\n            big_picture.pts >= ost->forced_kf_pts[ost->forced_kf_index]) {\n            big_picture.pict_type = AV_PICTURE_TYPE_I;\n            ost->forced_kf_index++;\n        }\n        update_benchmark(NULL);\n        ret = avcodec_encode_video2(enc, &pkt, &big_picture, &got_packet);\n        update_benchmark(\"encode_video %d.%d\", ost->file_index, ost->index);\n        if (ret < 0) {\n            av_log(NULL, AV_LOG_FATAL, \"Video encoding failed\\n\");\n            exit_program(1);\n        }\n\n        if (got_packet) {\n            if (pkt.pts == AV_NOPTS_VALUE && !(enc->codec->capabilities & CODEC_CAP_DELAY))\n                pkt.pts = ost->sync_opts;\n\n            if (pkt.pts != AV_NOPTS_VALUE)\n                pkt.pts = av_rescale_q(pkt.pts, enc->time_base, ost->st->time_base);\n            if (pkt.dts != AV_NOPTS_VALUE)\n                pkt.dts = av_rescale_q(pkt.dts, enc->time_base, ost->st->time_base);\n\n            if (debug_ts) {\n                av_log(NULL, AV_LOG_INFO, \"encoder -> type:video \"\n                    \"pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s\\n\",\n                    av_ts2str(pkt.pts), av_ts2timestr(pkt.pts, &ost->st->time_base),\n                    av_ts2str(pkt.dts), av_ts2timestr(pkt.dts, &ost->st->time_base));\n            }\n\n            frame_size = pkt.size;\n            video_size += pkt.size;\n            write_frame(s, &pkt, ost);\n            av_free_packet(&pkt);\n\n            /* if two pass, output log */\n            if (ost->logfile && enc->stats_out) {\n                fprintf(ost->logfile, \"%s\", enc->stats_out);\n            }\n        }\n    }\n    ost->sync_opts++;\n    /*\n     * For video, number of frames in == number of packets out.\n     * But there may be reordering, so we can't throw away frames on encoder\n     * flush, we need to limit them here, before they go into encoder.\n     */\n    ost->frame_number++;\n  }\n\n    if (vstats_filename && frame_size)\n        do_video_stats(output_files[ost->file_index]->ctx, ost, frame_size);\n}"}, {"function body": "static double psnr(double d)\n{\n    return -10.0 * log(d) / log(10.0);\n}"}, {"function body": "static void do_video_stats(AVFormatContext *os, OutputStream *ost,\n                           int frame_size)\n{\n    AVCodecContext *enc;\n    int frame_number;\n    double ti1, bitrate, avg_bitrate;\n\n    /* this is executed just the first time do_video_stats is called */\n    if (!vstats_file) {\n        vstats_file = fopen(vstats_filename, \"w\");\n        if (!vstats_file) {\n            perror(\"fopen\");\n            exit_program(1);\n        }\n    }\n\n    enc = ost->st->codec;\n    if (enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n        frame_number = ost->frame_number;\n        fprintf(vstats_file, \"frame= %5d q= %2.1f \", frame_number, enc->coded_frame->quality / (float)FF_QP2LAMBDA);\n        if (enc->flags&CODEC_FLAG_PSNR)\n            fprintf(vstats_file, \"PSNR= %6.2f \", psnr(enc->coded_frame->error[0] / (enc->width * enc->height * 255.0 * 255.0)));\n\n        fprintf(vstats_file,\"f_size= %6d \", frame_size);\n        /* compute pts value */\n        ti1 = ost->sync_opts * av_q2d(enc->time_base);\n        if (ti1 < 0.01)\n            ti1 = 0.01;\n\n        bitrate     = (frame_size * 8) / av_q2d(enc->time_base) / 1000.0;\n        avg_bitrate = (double)(video_size * 8) / ti1 / 1000.0;\n        fprintf(vstats_file, \"s_size= %8.0fkB time= %0.3f br= %7.1fkbits/s avg_br= %7.1fkbits/s \",\n               (double)video_size / 1024, ti1, bitrate, avg_bitrate);\n        fprintf(vstats_file, \"type= %c\\n\", av_get_picture_type_char(enc->coded_frame->pict_type));\n    }\n}"}, {"function body": "static int reap_filters(void)\n{\n    AVFilterBufferRef *picref;\n    AVFrame *filtered_frame = NULL;\n    int i;\n    int64_t frame_pts;\n\n    /* Reap all buffers present in the buffer sinks */\n    for (i = 0; i < nb_output_streams; i++) {\n        OutputStream *ost = output_streams[i];\n        OutputFile    *of = output_files[ost->file_index];\n        int ret = 0;\n\n        if (!ost->filter)\n            continue;\n\n        if (!ost->filtered_frame && !(ost->filtered_frame = avcodec_alloc_frame())) {\n            return AVERROR(ENOMEM);\n        } else\n            avcodec_get_frame_defaults(ost->filtered_frame);\n        filtered_frame = ost->filtered_frame;\n\n        while (1) {\n            ret = av_buffersink_get_buffer_ref(ost->filter->filter, &picref,\n                                               AV_BUFFERSINK_FLAG_NO_REQUEST);\n            if (ret < 0) {\n                if (ret != AVERROR(EAGAIN) && ret != AVERROR_EOF) {\n                    char buf[256];\n                    av_strerror(ret, buf, sizeof(buf));\n                    av_log(NULL, AV_LOG_WARNING,\n                           \"Error in av_buffersink_get_buffer_ref(): %s\\n\", buf);\n                }\n                break;\n            }\n            frame_pts = AV_NOPTS_VALUE;\n            if (picref->pts != AV_NOPTS_VALUE) {\n                filtered_frame->pts = frame_pts = av_rescale_q(picref->pts,\n                                                ost->filter->filter->inputs[0]->time_base,\n                                                ost->st->codec->time_base) -\n                                    av_rescale_q(of->start_time,\n                                                AV_TIME_BASE_Q,\n                                                ost->st->codec->time_base);\n\n                if (of->start_time && filtered_frame->pts < 0) {\n                    avfilter_unref_buffer(picref);\n                    continue;\n                }\n            }\n            //if (ost->source_index >= 0)\n            //    *filtered_frame= *input_streams[ost->source_index]->decoded_frame; //for me_threshold\n\n\n            switch (ost->filter->filter->inputs[0]->type) {\n            case AVMEDIA_TYPE_VIDEO:\n                avfilter_copy_buf_props(filtered_frame, picref);\n                filtered_frame->pts = frame_pts;\n                if (!ost->frame_aspect_ratio)\n                    ost->st->codec->sample_aspect_ratio = picref->video->sample_aspect_ratio;\n\n                do_video_out(of->ctx, ost, filtered_frame,\n                             same_quant ? ost->last_quality :\n                                          ost->st->codec->global_quality);\n                break;\n            case AVMEDIA_TYPE_AUDIO:\n                avfilter_copy_buf_props(filtered_frame, picref);\n                filtered_frame->pts = frame_pts;\n                do_audio_out(of->ctx, ost, filtered_frame);\n                break;\n            default:\n                // TODO support subtitle filters\n                av_assert0(0);\n            }\n\n            avfilter_unref_buffer(picref);\n        }\n    }\n\n    return 0;\n}"}, {"function body": "static void print_report(int is_last_report, int64_t timer_start, int64_t cur_time)\n{\n    char buf[1024];\n    AVBPrint buf_script;\n    OutputStream *ost;\n    AVFormatContext *oc;\n    int64_t total_size;\n    AVCodecContext *enc;\n    int frame_number, vid, i;\n    double bitrate;\n    int64_t pts = INT64_MIN;\n    static int64_t last_time = -1;\n    static int qp_histogram[52];\n    int hours, mins, secs, us;\n\n    if (!print_stats && !is_last_report && !progress_avio)\n        return;\n\n    if (!is_last_report) {\n        if (last_time == -1) {\n            last_time = cur_time;\n            return;\n        }\n        if ((cur_time - last_time) < 500000)\n            return;\n        last_time = cur_time;\n    }\n\n\n    oc = output_files[0]->ctx;\n\n    total_size = avio_size(oc->pb);\n    if (total_size < 0) { // FIXME improve avio_size() so it works with non seekable output too\n        total_size = avio_tell(oc->pb);\n        if (total_size < 0)\n            total_size = 0;\n    }\n\n    buf[0] = '\\0';\n    vid = 0;\n    av_bprint_init(&buf_script, 0, 1);\n    for (i = 0; i < nb_output_streams; i++) {\n        float q = -1;\n        ost = output_streams[i];\n        enc = ost->st->codec;\n        if (!ost->stream_copy && enc->coded_frame)\n            q = enc->coded_frame->quality / (float)FF_QP2LAMBDA;\n        if (vid && enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n            snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"q=%2.1f \", q);\n            av_bprintf(&buf_script, \"stream_%d_%d_q=%.1f\\n\",\n                       ost->file_index, ost->index, q);\n        }\n        if (!vid && enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n            float fps, t = (cur_time-timer_start) / 1000000.0;\n\n            frame_number = ost->frame_number;\n            fps = t > 1 ? frame_number / t : 0;\n            snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"frame=%5d fps=%3.*f q=%3.1f \",\n                     frame_number, fps < 9.95, fps, q);\n            av_bprintf(&buf_script, \"frame=%d\\n\", frame_number);\n            av_bprintf(&buf_script, \"fps=%.1f\\n\", fps);\n            av_bprintf(&buf_script, \"stream_%d_%d_q=%.1f\\n\",\n                       ost->file_index, ost->index, q);\n            if (is_last_report)\n                snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"L\");\n            if (qp_hist) {\n                int j;\n                int qp = lrintf(q);\n                if (qp >= 0 && qp < FF_ARRAY_ELEMS(qp_histogram))\n                    qp_histogram[qp]++;\n                for (j = 0; j < 32; j++)\n                    snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"%X\", (int)lrintf(log2(qp_histogram[j] + 1)));\n            }\n            if (enc->flags&CODEC_FLAG_PSNR) {\n                int j;\n                double error, error_sum = 0;\n                double scale, scale_sum = 0;\n                double p;\n                char type[3] = { 'Y','U','V' };\n                snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"PSNR=\");\n                for (j = 0; j < 3; j++) {\n                    if (is_last_report) {\n                        error = enc->error[j];\n                        scale = enc->width * enc->height * 255.0 * 255.0 * frame_number;\n                    } else {\n                        error = enc->coded_frame->error[j];\n                        scale = enc->width * enc->height * 255.0 * 255.0;\n                    }\n                    if (j)\n                        scale /= 4;\n                    error_sum += error;\n                    scale_sum += scale;\n                    p = psnr(error / scale);\n                    snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"%c:%2.2f \", type[j], p);\n                    av_bprintf(&buf_script, \"stream_%d_%d_psnr_%c=%2.2f\\n\",\n                               ost->file_index, ost->index, type[i] | 32, p);\n                }\n                p = psnr(error_sum / scale_sum);\n                snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"*:%2.2f \", psnr(error_sum / scale_sum));\n                av_bprintf(&buf_script, \"stream_%d_%d_psnr_all=%2.2f\\n\",\n                           ost->file_index, ost->index, p);\n            }\n            vid = 1;\n        }\n        /* compute min output value */\n        if ((is_last_report || !ost->finished) && ost->st->pts.val != AV_NOPTS_VALUE)\n            pts = FFMAX(pts, av_rescale_q(ost->st->pts.val,\n                                          ost->st->time_base, AV_TIME_BASE_Q));\n    }\n\n    secs = pts / AV_TIME_BASE;\n    us = pts % AV_TIME_BASE;\n    mins = secs / 60;\n    secs %= 60;\n    hours = mins / 60;\n    mins %= 60;\n\n    bitrate = pts ? total_size * 8 / (pts / 1000.0) : 0;\n\n    snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf),\n             \"size=%8.0fkB time=\", total_size / 1024.0);\n    snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf),\n             \"%02d:%02d:%02d.%02d \", hours, mins, secs,\n             (100 * us) / AV_TIME_BASE);\n    snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf),\n             \"bitrate=%6.1fkbits/s\", bitrate);\n    av_bprintf(&buf_script, \"total_size=%\"PRId64\"\\n\", total_size);\n    av_bprintf(&buf_script, \"out_time_ms=%\"PRId64\"\\n\", pts);\n    av_bprintf(&buf_script, \"out_time=%02d:%02d:%02d.%06d\\n\",\n               hours, mins, secs, us);\n\n    if (nb_frames_dup || nb_frames_drop)\n        snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \" dup=%d drop=%d\",\n                nb_frames_dup, nb_frames_drop);\n    av_bprintf(&buf_script, \"dup_frames=%d\\n\", nb_frames_dup);\n    av_bprintf(&buf_script, \"drop_frames=%d\\n\", nb_frames_drop);\n\n    if (print_stats || is_last_report) {\n    av_log(NULL, AV_LOG_INFO, \"%s    \\r\", buf);\n\n    fflush(stderr);\n    }\n\n    if (progress_avio) {\n        av_bprintf(&buf_script, \"progress=%s\\n\",\n                   is_last_report ? \"end\" : \"continue\");\n        avio_write(progress_avio, buf_script.str,\n                   FFMIN(buf_script.len, buf_script.size - 1));\n        avio_flush(progress_avio);\n        av_bprint_finalize(&buf_script, NULL);\n        if (is_last_report) {\n            avio_close(progress_avio);\n            progress_avio = NULL;\n        }\n    }\n\n    if (is_last_report) {\n        int64_t raw= audio_size + video_size + subtitle_size + extra_size;\n        av_log(NULL, AV_LOG_INFO, \"\\n\");\n        av_log(NULL, AV_LOG_INFO, \"video:%1.0fkB audio:%1.0fkB subtitle:%1.0f global headers:%1.0fkB muxing overhead %f%%\\n\",\n               video_size / 1024.0,\n               audio_size / 1024.0,\n               subtitle_size / 1024.0,\n               extra_size / 1024.0,\n               100.0 * (total_size - raw) / raw\n        );\n        if(video_size + audio_size + subtitle_size + extra_size == 0){\n            av_log(NULL, AV_LOG_WARNING, \"Output file is empty, nothing was encoded (check -ss / -t / -frames parameters if used)\\n\");\n        }\n    }\n}"}, {"function body": "static void flush_encoders(void)\n{\n    int i, ret;\n\n    for (i = 0; i < nb_output_streams; i++) {\n        OutputStream   *ost = output_streams[i];\n        AVCodecContext *enc = ost->st->codec;\n        AVFormatContext *os = output_files[ost->file_index]->ctx;\n        int stop_encoding = 0;\n\n        if (!ost->encoding_needed)\n            continue;\n\n        if (ost->st->codec->codec_type == AVMEDIA_TYPE_AUDIO && enc->frame_size <= 1)\n            continue;\n        if (ost->st->codec->codec_type == AVMEDIA_TYPE_VIDEO && (os->oformat->flags & AVFMT_RAWPICTURE) && enc->codec->id == AV_CODEC_ID_RAWVIDEO)\n            continue;\n\n        for (;;) {\n            int (*encode)(AVCodecContext*, AVPacket*, const AVFrame*, int*) = NULL;\n            const char *desc;\n            int64_t *size;\n\n            switch (ost->st->codec->codec_type) {\n            case AVMEDIA_TYPE_AUDIO:\n                encode = avcodec_encode_audio2;\n                desc   = \"Audio\";\n                size   = &audio_size;\n                break;\n            case AVMEDIA_TYPE_VIDEO:\n                encode = avcodec_encode_video2;\n                desc   = \"Video\";\n                size   = &video_size;\n                break;\n            default:\n                stop_encoding = 1;\n            }\n\n            if (encode) {\n                AVPacket pkt;\n                int got_packet;\n                av_init_packet(&pkt);\n                pkt.data = NULL;\n                pkt.size = 0;\n\n                update_benchmark(NULL);\n                ret = encode(enc, &pkt, NULL, &got_packet);\n                update_benchmark(\"flush %s %d.%d\", desc, ost->file_index, ost->index);\n                if (ret < 0) {\n                    av_log(NULL, AV_LOG_FATAL, \"%s encoding failed\\n\", desc);\n                    exit_program(1);\n                }\n                *size += pkt.size;\n                if (ost->logfile && enc->stats_out) {\n                    fprintf(ost->logfile, \"%s\", enc->stats_out);\n                }\n                if (!got_packet) {\n                    stop_encoding = 1;\n                    break;\n                }\n                if (pkt.pts != AV_NOPTS_VALUE)\n                    pkt.pts = av_rescale_q(pkt.pts, enc->time_base, ost->st->time_base);\n                if (pkt.dts != AV_NOPTS_VALUE)\n                    pkt.dts = av_rescale_q(pkt.dts, enc->time_base, ost->st->time_base);\n                write_frame(os, &pkt, ost);\n            }\n\n            if (stop_encoding)\n                break;\n        }\n    }\n}"}, {"function body": "static int check_output_constraints(InputStream *ist, OutputStream *ost)\n{\n    OutputFile *of = output_files[ost->file_index];\n    int ist_index  = input_files[ist->file_index]->ist_index + ist->st->index;\n\n    if (ost->source_index != ist_index)\n        return 0;\n\n    if (of->start_time && ist->pts < of->start_time)\n        return 0;\n\n    return 1;\n}"}, {"function body": "static void do_streamcopy(InputStream *ist, OutputStream *ost, const AVPacket *pkt)\n{\n    OutputFile *of = output_files[ost->file_index];\n    int64_t ost_tb_start_time = av_rescale_q(of->start_time, AV_TIME_BASE_Q, ost->st->time_base);\n    AVPicture pict;\n    AVPacket opkt;\n\n    av_init_packet(&opkt);\n\n    if ((!ost->frame_number && !(pkt->flags & AV_PKT_FLAG_KEY)) &&\n        !ost->copy_initial_nonkeyframes)\n        return;\n\n    if (!ost->frame_number && ist->pts < of->start_time &&\n        !ost->copy_prior_start)\n        return;\n\n    if (of->recording_time != INT64_MAX &&\n        ist->pts >= of->recording_time + of->start_time) {\n        close_output_stream(ost);\n        return;\n    }\n\n    /* force the input stream PTS */\n    if (ost->st->codec->codec_type == AVMEDIA_TYPE_AUDIO)\n        audio_size += pkt->size;\n    else if (ost->st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n        video_size += pkt->size;\n        ost->sync_opts++;\n    } else if (ost->st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n        subtitle_size += pkt->size;\n    }\n\n    if (pkt->pts != AV_NOPTS_VALUE)\n        opkt.pts = av_rescale_q(pkt->pts, ist->st->time_base, ost->st->time_base) - ost_tb_start_time;\n    else\n        opkt.pts = AV_NOPTS_VALUE;\n\n    if (pkt->dts == AV_NOPTS_VALUE)\n        opkt.dts = av_rescale_q(ist->dts, AV_TIME_BASE_Q, ost->st->time_base);\n    else\n        opkt.dts = av_rescale_q(pkt->dts, ist->st->time_base, ost->st->time_base);\n    opkt.dts -= ost_tb_start_time;\n\n    opkt.duration = av_rescale_q(pkt->duration, ist->st->time_base, ost->st->time_base);\n    opkt.flags    = pkt->flags;\n\n    // FIXME remove the following 2 lines they shall be replaced by the bitstream filters\n    if (  ost->st->codec->codec_id != AV_CODEC_ID_H264\n       && ost->st->codec->codec_id != AV_CODEC_ID_MPEG1VIDEO\n       && ost->st->codec->codec_id != AV_CODEC_ID_MPEG2VIDEO\n       && ost->st->codec->codec_id != AV_CODEC_ID_VC1\n       ) {\n        if (av_parser_change(ist->st->parser, ost->st->codec, &opkt.data, &opkt.size, pkt->data, pkt->size, pkt->flags & AV_PKT_FLAG_KEY))\n            opkt.destruct = av_destruct_packet;\n    } else {\n        opkt.data = pkt->data;\n        opkt.size = pkt->size;\n    }\n\n    if (ost->st->codec->codec_type == AVMEDIA_TYPE_VIDEO && (of->ctx->oformat->flags & AVFMT_RAWPICTURE)) {\n        /* store AVPicture in AVPacket, as expected by the output format */\n        avpicture_fill(&pict, opkt.data, ost->st->codec->pix_fmt, ost->st->codec->width, ost->st->codec->height);\n        opkt.data = (uint8_t *)&pict;\n        opkt.size = sizeof(AVPicture);\n        opkt.flags |= AV_PKT_FLAG_KEY;\n    }\n\n    write_frame(of->ctx, &opkt, ost);\n    ost->st->codec->frame_number++;\n    av_free_packet(&opkt);\n}"}, {"function body": "static void rate_emu_sleep(InputStream *ist)\n{\n    if (input_files[ist->file_index]->rate_emu) {\n        int64_t pts = av_rescale(ist->dts, 1000000, AV_TIME_BASE);\n        int64_t now = av_gettime() - ist->start;\n        if (pts > now)\n            av_usleep(pts - now);\n    }\n}"}, {"function body": "int guess_input_channel_layout(InputStream *ist)\n{\n    AVCodecContext *dec = ist->st->codec;\n\n    if (!dec->channel_layout) {\n        char layout_name[256];\n\n        dec->channel_layout = av_get_default_channel_layout(dec->channels);\n        if (!dec->channel_layout)\n            return 0;\n        av_get_channel_layout_string(layout_name, sizeof(layout_name),\n                                     dec->channels, dec->channel_layout);\n        av_log(NULL, AV_LOG_WARNING, \"Guessed Channel Layout for  Input Stream \"\n               \"#%d.%d : %s\\n\", ist->file_index, ist->st->index, layout_name);\n    }\n    return 1;\n}"}, {"function body": "static int decode_audio(InputStream *ist, AVPacket *pkt, int *got_output)\n{\n    AVFrame *decoded_frame;\n    AVCodecContext *avctx = ist->st->codec;\n    int i, ret, resample_changed;\n    AVRational decoded_frame_tb;\n\n    if (!ist->decoded_frame && !(ist->decoded_frame = avcodec_alloc_frame()))\n        return AVERROR(ENOMEM);\n    else\n        avcodec_get_frame_defaults(ist->decoded_frame);\n    decoded_frame = ist->decoded_frame;\n\n    update_benchmark(NULL);\n    ret = avcodec_decode_audio4(avctx, decoded_frame, got_output, pkt);\n    update_benchmark(\"decode_audio %d.%d\", ist->file_index, ist->st->index);\n\n    if (ret >= 0 && avctx->sample_rate <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Sample rate %d invalid\\n\", avctx->sample_rate);\n        ret = AVERROR_INVALIDDATA;\n    }\n\n    if (!*got_output || ret < 0) {\n        if (!pkt->size) {\n            for (i = 0; i < ist->nb_filters; i++)\n                av_buffersrc_add_ref(ist->filters[i]->filter, NULL, 0);\n        }\n        return ret;\n    }\n\n#if 1\n    /* increment next_dts to use for the case where the input stream does not\n       have timestamps or there are multiple frames in the packet */\n    ist->next_pts += ((int64_t)AV_TIME_BASE * decoded_frame->nb_samples) /\n                     avctx->sample_rate;\n    ist->next_dts += ((int64_t)AV_TIME_BASE * decoded_frame->nb_samples) /\n                     avctx->sample_rate;\n#endif\n\n    rate_emu_sleep(ist);\n\n    resample_changed = ist->resample_sample_fmt     != decoded_frame->format         ||\n                       ist->resample_channels       != avctx->channels               ||\n                       ist->resample_channel_layout != decoded_frame->channel_layout ||\n                       ist->resample_sample_rate    != decoded_frame->sample_rate;\n    if (resample_changed) {\n        char layout1[64], layout2[64];\n\n        if (!guess_input_channel_layout(ist)) {\n            av_log(NULL, AV_LOG_FATAL, \"Unable to find default channel \"\n                   \"layout for Input Stream #%d.%d\\n\", ist->file_index,\n                   ist->st->index);\n            exit_program(1);\n        }\n        decoded_frame->channel_layout = avctx->channel_layout;\n\n        av_get_channel_layout_string(layout1, sizeof(layout1), ist->resample_channels,\n                                     ist->resample_channel_layout);\n        av_get_channel_layout_string(layout2, sizeof(layout2), avctx->channels,\n                                     decoded_frame->channel_layout);\n\n        av_log(NULL, AV_LOG_INFO,\n               \"Input stream #%d:%d frame changed from rate:%d fmt:%s ch:%d chl:%s to rate:%d fmt:%s ch:%d chl:%s\\n\",\n               ist->file_index, ist->st->index,\n               ist->resample_sample_rate,  av_get_sample_fmt_name(ist->resample_sample_fmt),\n               ist->resample_channels, layout1,\n               decoded_frame->sample_rate, av_get_sample_fmt_name(decoded_frame->format),\n               avctx->channels, layout2);\n\n        ist->resample_sample_fmt     = decoded_frame->format;\n        ist->resample_sample_rate    = decoded_frame->sample_rate;\n        ist->resample_channel_layout = decoded_frame->channel_layout;\n        ist->resample_channels       = avctx->channels;\n\n        for (i = 0; i < nb_filtergraphs; i++)\n            if (ist_in_filtergraph(filtergraphs[i], ist)) {\n                FilterGraph *fg = filtergraphs[i];\n                int j;\n                if (configure_filtergraph(fg) < 0) {\n                    av_log(NULL, AV_LOG_FATAL, \"Error reinitializing filters!\\n\");\n                    exit_program(1);\n                }\n                for (j = 0; j < fg->nb_outputs; j++) {\n                    OutputStream *ost = fg->outputs[j]->ost;\n                    if (ost->enc->type == AVMEDIA_TYPE_AUDIO &&\n                        !(ost->enc->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE))\n                        av_buffersink_set_frame_size(ost->filter->filter,\n                                                     ost->st->codec->frame_size);\n                }\n            }\n    }\n\n    /* if the decoder provides a pts, use it instead of the last packet pts.\n       the decoder could be delaying output by a packet or more. */\n    if (decoded_frame->pts != AV_NOPTS_VALUE) {\n        ist->dts = ist->next_dts = ist->pts = ist->next_pts = av_rescale_q(decoded_frame->pts, avctx->time_base, AV_TIME_BASE_Q);\n        decoded_frame_tb   = avctx->time_base;\n    } else if (decoded_frame->pkt_pts != AV_NOPTS_VALUE) {\n        decoded_frame->pts = decoded_frame->pkt_pts;\n        pkt->pts           = AV_NOPTS_VALUE;\n        decoded_frame_tb   = ist->st->time_base;\n    } else if (pkt->pts != AV_NOPTS_VALUE) {\n        decoded_frame->pts = pkt->pts;\n        pkt->pts           = AV_NOPTS_VALUE;\n        decoded_frame_tb   = ist->st->time_base;\n    }else {\n        decoded_frame->pts = ist->dts;\n        decoded_frame_tb   = AV_TIME_BASE_Q;\n    }\n    if (decoded_frame->pts != AV_NOPTS_VALUE)\n        decoded_frame->pts = av_rescale_q(decoded_frame->pts,\n                                          decoded_frame_tb,\n                                          (AVRational){1, ist->st->codec->sample_rate});\n    for (i = 0; i < ist->nb_filters; i++)\n        av_buffersrc_add_frame(ist->filters[i]->filter, decoded_frame,\n                               AV_BUFFERSRC_FLAG_PUSH);\n\n    decoded_frame->pts = AV_NOPTS_VALUE;\n\n    return ret;\n}"}, {"function body": "static int decode_video(InputStream *ist, AVPacket *pkt, int *got_output)\n{\n    AVFrame *decoded_frame;\n    void *buffer_to_free = NULL;\n    int i, ret = 0, resample_changed;\n    int64_t best_effort_timestamp;\n    AVRational *frame_sample_aspect;\n    float quality;\n\n    if (!ist->decoded_frame && !(ist->decoded_frame = avcodec_alloc_frame()))\n        return AVERROR(ENOMEM);\n    else\n        avcodec_get_frame_defaults(ist->decoded_frame);\n    decoded_frame = ist->decoded_frame;\n    pkt->dts  = av_rescale_q(ist->dts, AV_TIME_BASE_Q, ist->st->time_base);\n\n    update_benchmark(NULL);\n    ret = avcodec_decode_video2(ist->st->codec,\n                                decoded_frame, got_output, pkt);\n    update_benchmark(\"decode_video %d.%d\", ist->file_index, ist->st->index);\n    if (!*got_output || ret < 0) {\n        if (!pkt->size) {\n            for (i = 0; i < ist->nb_filters; i++)\n                av_buffersrc_add_ref(ist->filters[i]->filter, NULL, 0);\n        }\n        return ret;\n    }\n\n    quality = same_quant ? decoded_frame->quality : 0;\n\n    if(ist->top_field_first>=0)\n        decoded_frame->top_field_first = ist->top_field_first;\n\n    best_effort_timestamp= av_frame_get_best_effort_timestamp(decoded_frame);\n    if(best_effort_timestamp != AV_NOPTS_VALUE)\n        ist->next_pts = ist->pts = av_rescale_q(decoded_frame->pts = best_effort_timestamp, ist->st->time_base, AV_TIME_BASE_Q);\n\n    if (debug_ts) {\n        av_log(NULL, AV_LOG_INFO, \"decoder -> ist_index:%d type:video \"\n                \"frame_pts:%s frame_pts_time:%s best_effort_ts:%\"PRId64\" best_effort_ts_time:%s keyframe:%d frame_type:%d \\n\",\n                ist->st->index, av_ts2str(decoded_frame->pts),\n                av_ts2timestr(decoded_frame->pts, &ist->st->time_base),\n                best_effort_timestamp,\n                av_ts2timestr(best_effort_timestamp, &ist->st->time_base),\n                decoded_frame->key_frame, decoded_frame->pict_type);\n    }\n\n    pkt->size = 0;\n    pre_process_video_frame(ist, (AVPicture *)decoded_frame, &buffer_to_free);\n\n    rate_emu_sleep(ist);\n\n    if (ist->st->sample_aspect_ratio.num)\n        decoded_frame->sample_aspect_ratio = ist->st->sample_aspect_ratio;\n\n    resample_changed = ist->resample_width   != decoded_frame->width  ||\n                       ist->resample_height  != decoded_frame->height ||\n                       ist->resample_pix_fmt != decoded_frame->format;\n    if (resample_changed) {\n        av_log(NULL, AV_LOG_INFO,\n               \"Input stream #%d:%d frame changed from size:%dx%d fmt:%s to size:%dx%d fmt:%s\\n\",\n               ist->file_index, ist->st->index,\n               ist->resample_width,  ist->resample_height,  av_get_pix_fmt_name(ist->resample_pix_fmt),\n               decoded_frame->width, decoded_frame->height, av_get_pix_fmt_name(decoded_frame->format));\n\n        ist->resample_width   = decoded_frame->width;\n        ist->resample_height  = decoded_frame->height;\n        ist->resample_pix_fmt = decoded_frame->format;\n\n        for (i = 0; i < nb_filtergraphs; i++)\n            if (ist_in_filtergraph(filtergraphs[i], ist) &&\n                configure_filtergraph(filtergraphs[i]) < 0) {\n                av_log(NULL, AV_LOG_FATAL, \"Error reinitializing filters!\\n\");\n                exit_program(1);\n            }\n    }\n\n    frame_sample_aspect= av_opt_ptr(avcodec_get_frame_class(), decoded_frame, \"sample_aspect_ratio\");\n    for (i = 0; i < ist->nb_filters; i++) {\n        int changed =      ist->st->codec->width   != ist->filters[i]->filter->outputs[0]->w\n                        || ist->st->codec->height  != ist->filters[i]->filter->outputs[0]->h\n                        || ist->st->codec->pix_fmt != ist->filters[i]->filter->outputs[0]->format;\n        // XXX what an ugly hack\n        if (ist->filters[i]->graph->nb_outputs == 1)\n            ist->filters[i]->graph->outputs[0]->ost->last_quality = quality;\n\n        if (!frame_sample_aspect->num)\n            *frame_sample_aspect = ist->st->sample_aspect_ratio;\n        if (ist->dr1 && decoded_frame->type==FF_BUFFER_TYPE_USER && !changed) {\n            FrameBuffer      *buf = decoded_frame->opaque;\n            AVFilterBufferRef *fb = avfilter_get_video_buffer_ref_from_arrays(\n                                        decoded_frame->data, decoded_frame->linesize,\n                                        AV_PERM_READ | AV_PERM_PRESERVE,\n                                        ist->st->codec->width, ist->st->codec->height,\n                                        ist->st->codec->pix_fmt);\n\n            avfilter_copy_frame_props(fb, decoded_frame);\n            fb->buf->priv           = buf;\n            fb->buf->free           = filter_release_buffer;\n\n            av_assert0(buf->refcount>0);\n            buf->refcount++;\n            av_buffersrc_add_ref(ist->filters[i]->filter, fb,\n                                 AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT |\n                                 AV_BUFFERSRC_FLAG_NO_COPY |\n                                 AV_BUFFERSRC_FLAG_PUSH);\n        } else\n        if(av_buffersrc_add_frame(ist->filters[i]->filter, decoded_frame, AV_BUFFERSRC_FLAG_PUSH)<0) {\n            av_log(NULL, AV_LOG_FATAL, \"Failed to inject frame into filter network\\n\");\n            exit_program(1);\n        }\n\n    }\n\n    av_free(buffer_to_free);\n    return ret;\n}"}, {"function body": "static int transcode_subtitles(InputStream *ist, AVPacket *pkt, int *got_output)\n{\n    AVSubtitle subtitle;\n    int i, ret = avcodec_decode_subtitle2(ist->st->codec,\n                                          &subtitle, got_output, pkt);\n    if (ret < 0 || !*got_output) {\n        if (!pkt->size)\n            sub2video_flush(ist);\n        return ret;\n    }\n\n    if (ist->fix_sub_duration) {\n        if (ist->prev_sub.got_output) {\n            int end = av_rescale(subtitle.pts - ist->prev_sub.subtitle.pts,\n                                 1000, AV_TIME_BASE);\n            if (end < ist->prev_sub.subtitle.end_display_time) {\n                av_log(ist->st->codec, AV_LOG_DEBUG,\n                       \"Subtitle duration reduced from %d to %d\\n\",\n                       ist->prev_sub.subtitle.end_display_time, end);\n                ist->prev_sub.subtitle.end_display_time = end;\n            }\n        }\n        FFSWAP(int,        *got_output, ist->prev_sub.got_output);\n        FFSWAP(int,        ret,         ist->prev_sub.ret);\n        FFSWAP(AVSubtitle, subtitle,    ist->prev_sub.subtitle);\n    }\n\n    sub2video_update(ist, &subtitle);\n\n    if (!*got_output || !subtitle.num_rects)\n        return ret;\n\n    rate_emu_sleep(ist);\n\n    for (i = 0; i < nb_output_streams; i++) {\n        OutputStream *ost = output_streams[i];\n\n        if (!check_output_constraints(ist, ost) || !ost->encoding_needed)\n            continue;\n\n        do_subtitle_out(output_files[ost->file_index]->ctx, ost, ist, &subtitle);\n    }\n\n    avsubtitle_free(&subtitle);\n    return ret;\n}"}, {"function body": "static int output_packet(InputStream *ist, const AVPacket *pkt)\n{\n    int ret = 0, i;\n    int got_output;\n\n    AVPacket avpkt;\n    if (!ist->saw_first_ts) {\n        ist->dts = ist->st->avg_frame_rate.num ? - ist->st->codec->has_b_frames * AV_TIME_BASE / av_q2d(ist->st->avg_frame_rate) : 0;\n        ist->pts = 0;\n        if (pkt != NULL && pkt->pts != AV_NOPTS_VALUE && !ist->decoding_needed) {\n            ist->dts += av_rescale_q(pkt->pts, ist->st->time_base, AV_TIME_BASE_Q);\n            ist->pts = ist->dts; //unused but better to set it to a value thats not totally wrong\n        }\n        ist->saw_first_ts = 1;\n    }\n\n    if (ist->next_dts == AV_NOPTS_VALUE)\n        ist->next_dts = ist->dts;\n    if (ist->next_pts == AV_NOPTS_VALUE)\n        ist->next_pts = ist->pts;\n\n    if (pkt == NULL) {\n        /* EOF handling */\n        av_init_packet(&avpkt);\n        avpkt.data = NULL;\n        avpkt.size = 0;\n        goto handle_eof;\n    } else {\n        avpkt = *pkt;\n    }\n\n    if (pkt->dts != AV_NOPTS_VALUE) {\n        ist->next_dts = ist->dts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n        if (ist->st->codec->codec_type != AVMEDIA_TYPE_VIDEO || !ist->decoding_needed)\n            ist->next_pts = ist->pts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n    }\n\n    // while we have more to decode or while the decoder did output something on EOF\n    while (ist->decoding_needed && (avpkt.size > 0 || (!pkt && got_output))) {\n        int duration;\n    handle_eof:\n\n        ist->pts = ist->next_pts;\n        ist->dts = ist->next_dts;\n\n        if (avpkt.size && avpkt.size != pkt->size) {\n            av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING,\n                   \"Multiple frames in a packet from stream %d\\n\", pkt->stream_index);\n            ist->showed_multi_packet_warning = 1;\n        }\n\n        switch (ist->st->codec->codec_type) {\n        case AVMEDIA_TYPE_AUDIO:\n            ret = decode_audio    (ist, &avpkt, &got_output);\n            break;\n        case AVMEDIA_TYPE_VIDEO:\n            ret = decode_video    (ist, &avpkt, &got_output);\n            if (avpkt.duration) {\n                duration = av_rescale_q(avpkt.duration, ist->st->time_base, AV_TIME_BASE_Q);\n            } else if(ist->st->codec->time_base.num != 0 && ist->st->codec->time_base.den != 0) {\n                int ticks= ist->st->parser ? ist->st->parser->repeat_pict+1 : ist->st->codec->ticks_per_frame;\n                duration = ((int64_t)AV_TIME_BASE *\n                                ist->st->codec->time_base.num * ticks) /\n                                ist->st->codec->time_base.den;\n            } else\n                duration = 0;\n\n            if(ist->dts != AV_NOPTS_VALUE && duration) {\n                ist->next_dts += duration;\n            }else\n                ist->next_dts = AV_NOPTS_VALUE;\n\n            if (got_output)\n                ist->next_pts += duration; //FIXME the duration is not correct in some cases\n            break;\n        case AVMEDIA_TYPE_SUBTITLE:\n            ret = transcode_subtitles(ist, &avpkt, &got_output);\n            break;\n        default:\n            return -1;\n        }\n\n        if (ret < 0)\n            return ret;\n\n        avpkt.dts=\n        avpkt.pts= AV_NOPTS_VALUE;\n\n        // touch data and size only if not EOF\n        if (pkt) {\n            if(ist->st->codec->codec_type != AVMEDIA_TYPE_AUDIO)\n                ret = avpkt.size;\n            avpkt.data += ret;\n            avpkt.size -= ret;\n        }\n        if (!got_output) {\n            continue;\n        }\n    }\n\n    /* handle stream copy */\n    if (!ist->decoding_needed) {\n        rate_emu_sleep(ist);\n        ist->dts = ist->next_dts;\n        switch (ist->st->codec->codec_type) {\n        case AVMEDIA_TYPE_AUDIO:\n            ist->next_dts += ((int64_t)AV_TIME_BASE * ist->st->codec->frame_size) /\n                             ist->st->codec->sample_rate;\n            break;\n        case AVMEDIA_TYPE_VIDEO:\n            if (pkt->duration) {\n                ist->next_dts += av_rescale_q(pkt->duration, ist->st->time_base, AV_TIME_BASE_Q);\n            } else if(ist->st->codec->time_base.num != 0) {\n                int ticks= ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->st->codec->ticks_per_frame;\n                ist->next_dts += ((int64_t)AV_TIME_BASE *\n                                  ist->st->codec->time_base.num * ticks) /\n                                  ist->st->codec->time_base.den;\n            }\n            break;\n        }\n        ist->pts = ist->dts;\n        ist->next_pts = ist->next_dts;\n    }\n    for (i = 0; pkt && i < nb_output_streams; i++) {\n        OutputStream *ost = output_streams[i];\n\n        if (!check_output_constraints(ist, ost) || ost->encoding_needed)\n            continue;\n\n        do_streamcopy(ist, ost, pkt);\n    }\n\n    return 0;\n}"}, {"function body": "static void print_sdp(void)\n{\n    char sdp[2048];\n    int i;\n    AVFormatContext **avc = av_malloc(sizeof(*avc) * nb_output_files);\n\n    if (!avc)\n        exit_program(1);\n    for (i = 0; i < nb_output_files; i++)\n        avc[i] = output_files[i]->ctx;\n\n    av_sdp_create(avc, nb_output_files, sdp, sizeof(sdp));\n    printf(\"SDP:\\n%s\\n\", sdp);\n    fflush(stdout);\n    av_freep(&avc);\n}"}, {"function body": "static int init_input_stream(int ist_index, char *error, int error_len)\n{\n    InputStream *ist = input_streams[ist_index];\n\n    if (ist->decoding_needed) {\n        AVCodec *codec = ist->dec;\n        if (!codec) {\n            snprintf(error, error_len, \"Decoder (codec %s) not found for input stream #%d:%d\",\n                    avcodec_get_name(ist->st->codec->codec_id), ist->file_index, ist->st->index);\n            return AVERROR(EINVAL);\n        }\n\n        ist->dr1 = (codec->capabilities & CODEC_CAP_DR1) && !do_deinterlace;\n        if (codec->type == AVMEDIA_TYPE_VIDEO && ist->dr1) {\n            ist->st->codec->get_buffer     = codec_get_buffer;\n            ist->st->codec->release_buffer = codec_release_buffer;\n            ist->st->codec->opaque         = &ist->buffer_pool;\n        }\n\n        if (!av_dict_get(ist->opts, \"threads\", NULL, 0))\n            av_dict_set(&ist->opts, \"threads\", \"auto\", 0);\n        if (avcodec_open2(ist->st->codec, codec, &ist->opts) < 0) {\n            snprintf(error, error_len, \"Error while opening decoder for input stream #%d:%d\",\n                    ist->file_index, ist->st->index);\n            return AVERROR(EINVAL);\n        }\n        assert_codec_experimental(ist->st->codec, 0);\n        assert_avoptions(ist->opts);\n    }\n\n    ist->next_pts = AV_NOPTS_VALUE;\n    ist->next_dts = AV_NOPTS_VALUE;\n    ist->is_start = 1;\n\n    return 0;\n}"}, {"function body": "static InputStream *get_input_stream(OutputStream *ost)\n{\n    if (ost->source_index >= 0)\n        return input_streams[ost->source_index];\n    return NULL;\n}"}, {"function body": "static void parse_forced_key_frames(char *kf, OutputStream *ost,\n                                    AVCodecContext *avctx)\n{\n    char *p;\n    int n = 1, i;\n    int64_t t;\n\n    for (p = kf; *p; p++)\n        if (*p == ',')\n            n++;\n    ost->forced_kf_count = n;\n    ost->forced_kf_pts   = av_malloc(sizeof(*ost->forced_kf_pts) * n);\n    if (!ost->forced_kf_pts) {\n        av_log(NULL, AV_LOG_FATAL, \"Could not allocate forced key frames array.\\n\");\n        exit_program(1);\n    }\n\n    p = kf;\n    for (i = 0; i < n; i++) {\n        char *next = strchr(p, ',');\n\n        if (next)\n            *next++ = 0;\n\n        t = parse_time_or_die(\"force_key_frames\", p, 1);\n        ost->forced_kf_pts[i] = av_rescale_q(t, AV_TIME_BASE_Q, avctx->time_base);\n\n        p = next;\n    }\n}"}, {"function body": "static void report_new_stream(int input_index, AVPacket *pkt)\n{\n    InputFile *file = input_files[input_index];\n    AVStream *st = file->ctx->streams[pkt->stream_index];\n\n    if (pkt->stream_index < file->nb_streams_warn)\n        return;\n    av_log(file->ctx, AV_LOG_WARNING,\n           \"New %s stream %d:%d at pos:%\"PRId64\" and DTS:%ss\\n\",\n           av_get_media_type_string(st->codec->codec_type),\n           input_index, pkt->stream_index,\n           pkt->pos, av_ts2timestr(pkt->dts, &st->time_base));\n    file->nb_streams_warn = pkt->stream_index + 1;\n}"}, {"function body": "static int transcode_init(void)\n{\n    int ret = 0, i, j, k;\n    AVFormatContext *oc;\n    AVCodecContext *codec;\n    OutputStream *ost;\n    InputStream *ist;\n    char error[1024];\n    int want_sdp = 1;\n\n    /* init framerate emulation */\n    for (i = 0; i < nb_input_files; i++) {\n        InputFile *ifile = input_files[i];\n        if (ifile->rate_emu)\n            for (j = 0; j < ifile->nb_streams; j++)\n                input_streams[j + ifile->ist_index]->start = av_gettime();\n    }\n\n    /* output stream init */\n    for (i = 0; i < nb_output_files; i++) {\n        oc = output_files[i]->ctx;\n        if (!oc->nb_streams && !(oc->oformat->flags & AVFMT_NOSTREAMS)) {\n            av_dump_format(oc, i, oc->filename, 1);\n            av_log(NULL, AV_LOG_ERROR, \"Output file #%d does not contain any stream\\n\", i);\n            return AVERROR(EINVAL);\n        }\n    }\n\n    /* init complex filtergraphs */\n    for (i = 0; i < nb_filtergraphs; i++)\n        if ((ret = avfilter_graph_config(filtergraphs[i]->graph, NULL)) < 0)\n            return ret;\n\n    /* for each output stream, we compute the right encoding parameters */\n    for (i = 0; i < nb_output_streams; i++) {\n        AVCodecContext *icodec = NULL;\n        ost = output_streams[i];\n        oc  = output_files[ost->file_index]->ctx;\n        ist = get_input_stream(ost);\n\n        if (ost->attachment_filename)\n            continue;\n\n        codec  = ost->st->codec;\n\n        if (ist) {\n            icodec = ist->st->codec;\n\n            ost->st->disposition          = ist->st->disposition;\n            codec->bits_per_raw_sample    = icodec->bits_per_raw_sample;\n            codec->chroma_sample_location = icodec->chroma_sample_location;\n        }\n\n        if (ost->stream_copy) {\n            uint64_t extra_size;\n\n            av_assert0(ist && !ost->filter);\n\n            extra_size = (uint64_t)icodec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE;\n\n            if (extra_size > INT_MAX) {\n                return AVERROR(EINVAL);\n            }\n\n            /* if stream_copy is selected, no need to decode or encode */\n            codec->codec_id   = icodec->codec_id;\n            codec->codec_type = icodec->codec_type;\n\n            if (!codec->codec_tag) {\n                if (!oc->oformat->codec_tag ||\n                     av_codec_get_id (oc->oformat->codec_tag, icodec->codec_tag) == codec->codec_id ||\n                     av_codec_get_tag(oc->oformat->codec_tag, icodec->codec_id) <= 0)\n                    codec->codec_tag = icodec->codec_tag;\n            }\n\n            codec->bit_rate       = icodec->bit_rate;\n            codec->rc_max_rate    = icodec->rc_max_rate;\n            codec->rc_buffer_size = icodec->rc_buffer_size;\n            codec->field_order    = icodec->field_order;\n            codec->extradata      = av_mallocz(extra_size);\n            if (!codec->extradata) {\n                return AVERROR(ENOMEM);\n            }\n            memcpy(codec->extradata, icodec->extradata, icodec->extradata_size);\n            codec->extradata_size= icodec->extradata_size;\n            codec->bits_per_coded_sample  = icodec->bits_per_coded_sample;\n\n            codec->time_base = ist->st->time_base;\n            /*\n             * Avi is a special case here because it supports variable fps but\n             * having the fps and timebase differe significantly adds quite some\n             * overhead\n             */\n            if(!strcmp(oc->oformat->name, \"avi\")) {\n                if ( copy_tb<0 && av_q2d(ist->st->r_frame_rate) >= av_q2d(ist->st->avg_frame_rate)\n                               && 0.5/av_q2d(ist->st->r_frame_rate) > av_q2d(ist->st->time_base)\n                               && 0.5/av_q2d(ist->st->r_frame_rate) > av_q2d(icodec->time_base)\n                               && av_q2d(ist->st->time_base) < 1.0/500 && av_q2d(icodec->time_base) < 1.0/500\n                     || copy_tb==2){\n                    codec->time_base.num = ist->st->r_frame_rate.den;\n                    codec->time_base.den = 2*ist->st->r_frame_rate.num;\n                    codec->ticks_per_frame = 2;\n                } else if (   copy_tb<0 && av_q2d(icodec->time_base)*icodec->ticks_per_frame > 2*av_q2d(ist->st->time_base)\n                                 && av_q2d(ist->st->time_base) < 1.0/500\n                    || copy_tb==0){\n                    codec->time_base = icodec->time_base;\n                    codec->time_base.num *= icodec->ticks_per_frame;\n                    codec->time_base.den *= 2;\n                    codec->ticks_per_frame = 2;\n                }\n            } else if(!(oc->oformat->flags & AVFMT_VARIABLE_FPS)\n                      && strcmp(oc->oformat->name, \"mov\") && strcmp(oc->oformat->name, \"mp4\") && strcmp(oc->oformat->name, \"3gp\")\n                      && strcmp(oc->oformat->name, \"3g2\") && strcmp(oc->oformat->name, \"psp\") && strcmp(oc->oformat->name, \"ipod\")\n                      && strcmp(oc->oformat->name, \"f4v\")\n            ) {\n                if(   copy_tb<0 && icodec->time_base.den\n                                && av_q2d(icodec->time_base)*icodec->ticks_per_frame > av_q2d(ist->st->time_base)\n                                && av_q2d(ist->st->time_base) < 1.0/500\n                   || copy_tb==0){\n                    codec->time_base = icodec->time_base;\n                    codec->time_base.num *= icodec->ticks_per_frame;\n                }\n            }\n\n            if(ost->frame_rate.num)\n                codec->time_base = av_inv_q(ost->frame_rate);\n\n            av_reduce(&codec->time_base.num, &codec->time_base.den,\n                        codec->time_base.num, codec->time_base.den, INT_MAX);\n\n            switch (codec->codec_type) {\n            case AVMEDIA_TYPE_AUDIO:\n                if (audio_volume != 256) {\n                    av_log(NULL, AV_LOG_FATAL, \"-acodec copy and -vol are incompatible (frames are not decoded)\\n\");\n                    exit_program(1);\n                }\n                codec->channel_layout     = icodec->channel_layout;\n                codec->sample_rate        = icodec->sample_rate;\n                codec->channels           = icodec->channels;\n                codec->frame_size         = icodec->frame_size;\n                codec->audio_service_type = icodec->audio_service_type;\n                codec->block_align        = icodec->block_align;\n                if((codec->block_align == 1 || codec->block_align == 1152) && codec->codec_id == AV_CODEC_ID_MP3)\n                    codec->block_align= 0;\n                if(codec->codec_id == AV_CODEC_ID_AC3)\n                    codec->block_align= 0;\n                break;\n            case AVMEDIA_TYPE_VIDEO:\n                codec->pix_fmt            = icodec->pix_fmt;\n                codec->width              = icodec->width;\n                codec->height             = icodec->height;\n                codec->has_b_frames       = icodec->has_b_frames;\n                if (!codec->sample_aspect_ratio.num) {\n                    codec->sample_aspect_ratio   =\n                    ost->st->sample_aspect_ratio =\n                        ist->st->sample_aspect_ratio.num ? ist->st->sample_aspect_ratio :\n                        ist->st->codec->sample_aspect_ratio.num ?\n                        ist->st->codec->sample_aspect_ratio : (AVRational){0, 1};\n                }\n                ost->st->avg_frame_rate = ist->st->avg_frame_rate;\n                break;\n            case AVMEDIA_TYPE_SUBTITLE:\n                codec->width  = icodec->width;\n                codec->height = icodec->height;\n                break;\n            case AVMEDIA_TYPE_DATA:\n            case AVMEDIA_TYPE_ATTACHMENT:\n                break;\n            default:\n                abort();\n            }\n        } else {\n            if (!ost->enc)\n                ost->enc = avcodec_find_encoder(codec->codec_id);\n            if (!ost->enc) {\n                /* should only happen when a default codec is not present. */\n                snprintf(error, sizeof(error), \"Encoder (codec %s) not found for output stream #%d:%d\",\n                         avcodec_get_name(ost->st->codec->codec_id), ost->file_index, ost->index);\n                ret = AVERROR(EINVAL);\n                goto dump_format;\n            }\n\n            if (ist)\n                ist->decoding_needed++;\n            ost->encoding_needed = 1;\n\n            if (!ost->filter &&\n                (codec->codec_type == AVMEDIA_TYPE_VIDEO ||\n                 codec->codec_type == AVMEDIA_TYPE_AUDIO)) {\n                    FilterGraph *fg;\n                    fg = init_simple_filtergraph(ist, ost);\n                    if (configure_filtergraph(fg)) {\n                        av_log(NULL, AV_LOG_FATAL, \"Error opening filters!\\n\");\n                        exit(1);\n                    }\n            }\n\n            if (codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n                if (ost->filter && !ost->frame_rate.num)\n                    ost->frame_rate = av_buffersink_get_frame_rate(ost->filter->filter);\n                if (ist && !ost->frame_rate.num)\n                    ost->frame_rate = ist->framerate;\n                if (ist && !ost->frame_rate.num)\n                    ost->frame_rate = ist->st->r_frame_rate.num ? ist->st->r_frame_rate : (AVRational){25, 1};\n//                    ost->frame_rate = ist->st->avg_frame_rate.num ? ist->st->avg_frame_rate : (AVRational){25, 1};\n                if (ost->enc && ost->enc->supported_framerates && !ost->force_fps) {\n                    int idx = av_find_nearest_q_idx(ost->frame_rate, ost->enc->supported_framerates);\n                    ost->frame_rate = ost->enc->supported_framerates[idx];\n                }\n            }\n\n            switch (codec->codec_type) {\n            case AVMEDIA_TYPE_AUDIO:\n                codec->sample_fmt     = ost->filter->filter->inputs[0]->format;\n                codec->sample_rate    = ost->filter->filter->inputs[0]->sample_rate;\n                codec->channel_layout = ost->filter->filter->inputs[0]->channel_layout;\n                codec->channels       = av_get_channel_layout_nb_channels(codec->channel_layout);\n                codec->time_base      = (AVRational){ 1, codec->sample_rate };\n                break;\n            case AVMEDIA_TYPE_VIDEO:\n                codec->time_base = av_inv_q(ost->frame_rate);\n                if (ost->filter && !(codec->time_base.num && codec->time_base.den))\n                    codec->time_base = ost->filter->filter->inputs[0]->time_base;\n                if (   av_q2d(codec->time_base) < 0.001 && video_sync_method != VSYNC_PASSTHROUGH\n                   && (video_sync_method == VSYNC_CFR || (video_sync_method == VSYNC_AUTO && !(oc->oformat->flags & AVFMT_VARIABLE_FPS)))){\n                    av_log(oc, AV_LOG_WARNING, \"Frame rate very high for a muxer not efficiently supporting it.\\n\"\n                                               \"Please consider specifying a lower framerate, a different muxer or -vsync 2\\n\");\n                }\n                for (j = 0; j < ost->forced_kf_count; j++)\n                    ost->forced_kf_pts[j] = av_rescale_q(ost->forced_kf_pts[j],\n                                                         AV_TIME_BASE_Q,\n                                                         codec->time_base);\n\n                codec->width  = ost->filter->filter->inputs[0]->w;\n                codec->height = ost->filter->filter->inputs[0]->h;\n                codec->sample_aspect_ratio = ost->st->sample_aspect_ratio =\n                    ost->frame_aspect_ratio ? // overridden by the -aspect cli option\n                    av_d2q(ost->frame_aspect_ratio * codec->height/codec->width, 255) :\n                    ost->filter->filter->inputs[0]->sample_aspect_ratio;\n                codec->pix_fmt = ost->filter->filter->inputs[0]->format;\n\n                if (!icodec ||\n                    codec->width   != icodec->width  ||\n                    codec->height  != icodec->height ||\n                    codec->pix_fmt != icodec->pix_fmt) {\n                    codec->bits_per_raw_sample = frame_bits_per_raw_sample;\n                }\n\n                if (ost->forced_keyframes)\n                    parse_forced_key_frames(ost->forced_keyframes, ost,\n                                            ost->st->codec);\n                break;\n            case AVMEDIA_TYPE_SUBTITLE:\n                codec->time_base = (AVRational){1, 1000};\n                if (!codec->width) {\n                    codec->width     = input_streams[ost->source_index]->st->codec->width;\n                    codec->height    = input_streams[ost->source_index]->st->codec->height;\n                }\n                break;\n            default:\n                abort();\n                break;\n            }\n            /* two pass mode */\n            if (codec->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2)) {\n                char logfilename[1024];\n                FILE *f;\n\n                snprintf(logfilename, sizeof(logfilename), \"%s-%d.log\",\n                         ost->logfile_prefix ? ost->logfile_prefix :\n                                               DEFAULT_PASS_LOGFILENAME_PREFIX,\n                         i);\n                if (!strcmp(ost->enc->name, \"libx264\")) {\n                    av_dict_set(&ost->opts, \"stats\", logfilename, AV_DICT_DONT_OVERWRITE);\n                } else {\n                    if (codec->flags & CODEC_FLAG_PASS2) {\n                        char  *logbuffer;\n                        size_t logbuffer_size;\n                        if (cmdutils_read_file(logfilename, &logbuffer, &logbuffer_size) < 0) {\n                            av_log(NULL, AV_LOG_FATAL, \"Error reading log file '%s' for pass-2 encoding\\n\",\n                                   logfilename);\n                            exit_program(1);\n                        }\n                        codec->stats_in = logbuffer;\n                    }\n                    if (codec->flags & CODEC_FLAG_PASS1) {\n                        f = fopen(logfilename, \"wb\");\n                        if (!f) {\n                            av_log(NULL, AV_LOG_FATAL, \"Cannot write log file '%s' for pass-1 encoding: %s\\n\",\n                                logfilename, strerror(errno));\n                            exit_program(1);\n                        }\n                        ost->logfile = f;\n                    }\n                }\n            }\n        }\n    }\n\n    /* open each encoder */\n    for (i = 0; i < nb_output_streams; i++) {\n        ost = output_streams[i];\n        if (ost->encoding_needed) {\n            AVCodec      *codec = ost->enc;\n            AVCodecContext *dec = NULL;\n\n            if ((ist = get_input_stream(ost)))\n                dec = ist->st->codec;\n            if (dec && dec->subtitle_header) {\n                /* ASS code assumes this buffer is null terminated so add extra byte. */\n                ost->st->codec->subtitle_header = av_mallocz(dec->subtitle_header_size + 1);\n                if (!ost->st->codec->subtitle_header) {\n                    ret = AVERROR(ENOMEM);\n                    goto dump_format;\n                }\n                memcpy(ost->st->codec->subtitle_header, dec->subtitle_header, dec->subtitle_header_size);\n                ost->st->codec->subtitle_header_size = dec->subtitle_header_size;\n            }\n            if (!av_dict_get(ost->opts, \"threads\", NULL, 0))\n                av_dict_set(&ost->opts, \"threads\", \"auto\", 0);\n            if (avcodec_open2(ost->st->codec, codec, &ost->opts) < 0) {\n                snprintf(error, sizeof(error), \"Error while opening encoder for output stream #%d:%d - maybe incorrect parameters such as bit_rate, rate, width or height\",\n                        ost->file_index, ost->index);\n                ret = AVERROR(EINVAL);\n                goto dump_format;\n            }\n            if (ost->enc->type == AVMEDIA_TYPE_AUDIO &&\n                !(ost->enc->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE))\n                av_buffersink_set_frame_size(ost->filter->filter,\n                                             ost->st->codec->frame_size);\n            assert_codec_experimental(ost->st->codec, 1);\n            assert_avoptions(ost->opts);\n            if (ost->st->codec->bit_rate && ost->st->codec->bit_rate < 1000)\n                av_log(NULL, AV_LOG_WARNING, \"The bitrate parameter is set too low.\"\n                                             \" It takes bits/s as argument, not kbits/s\\n\");\n            extra_size += ost->st->codec->extradata_size;\n\n            if (ost->st->codec->me_threshold)\n                input_streams[ost->source_index]->st->codec->debug |= FF_DEBUG_MV;\n        }\n    }\n\n    /* init input streams */\n    for (i = 0; i < nb_input_streams; i++)\n        if ((ret = init_input_stream(i, error, sizeof(error))) < 0)\n            goto dump_format;\n\n    /* discard unused programs */\n    for (i = 0; i < nb_input_files; i++) {\n        InputFile *ifile = input_files[i];\n        for (j = 0; j < ifile->ctx->nb_programs; j++) {\n            AVProgram *p = ifile->ctx->programs[j];\n            int discard  = AVDISCARD_ALL;\n\n            for (k = 0; k < p->nb_stream_indexes; k++)\n                if (!input_streams[ifile->ist_index + p->stream_index[k]]->discard) {\n                    discard = AVDISCARD_DEFAULT;\n                    break;\n                }\n            p->discard = discard;\n        }\n    }\n\n    /* open files and write file headers */\n    for (i = 0; i < nb_output_files; i++) {\n        oc = output_files[i]->ctx;\n        oc->interrupt_callback = int_cb;\n        if ((ret = avformat_write_header(oc, &output_files[i]->opts)) < 0) {\n            char errbuf[128];\n            const char *errbuf_ptr = errbuf;\n            if (av_strerror(ret, errbuf, sizeof(errbuf)) < 0)\n                errbuf_ptr = strerror(AVUNERROR(ret));\n            snprintf(error, sizeof(error), \"Could not write header for output file #%d (incorrect codec parameters ?): %s\", i, errbuf_ptr);\n            ret = AVERROR(EINVAL);\n            goto dump_format;\n        }\n//         assert_avoptions(output_files[i]->opts);\n        if (strcmp(oc->oformat->name, \"rtp\")) {\n            want_sdp = 0;\n        }\n    }\n\n dump_format:\n    /* dump the file output parameters - cannot be done before in case\n       of stream copy */\n    for (i = 0; i < nb_output_files; i++) {\n        av_dump_format(output_files[i]->ctx, i, output_files[i]->ctx->filename, 1);\n    }\n\n    /* dump the stream mapping */\n    av_log(NULL, AV_LOG_INFO, \"Stream mapping:\\n\");\n    for (i = 0; i < nb_input_streams; i++) {\n        ist = input_streams[i];\n\n        for (j = 0; j < ist->nb_filters; j++) {\n            if (ist->filters[j]->graph->graph_desc) {\n                av_log(NULL, AV_LOG_INFO, \"  Stream #%d:%d (%s) -> %s\",\n                       ist->file_index, ist->st->index, ist->dec ? ist->dec->name : \"?\",\n                       ist->filters[j]->name);\n                if (nb_filtergraphs > 1)\n                    av_log(NULL, AV_LOG_INFO, \" (graph %d)\", ist->filters[j]->graph->index);\n                av_log(NULL, AV_LOG_INFO, \"\\n\");\n            }\n        }\n    }\n\n    for (i = 0; i < nb_output_streams; i++) {\n        ost = output_streams[i];\n\n        if (ost->attachment_filename) {\n            /* an attached file */\n            av_log(NULL, AV_LOG_INFO, \"  File %s -> Stream #%d:%d\\n\",\n                   ost->attachment_filename, ost->file_index, ost->index);\n            continue;\n        }\n\n        if (ost->filter && ost->filter->graph->graph_desc) {\n            /* output from a complex graph */\n            av_log(NULL, AV_LOG_INFO, \"  %s\", ost->filter->name);\n            if (nb_filtergraphs > 1)\n                av_log(NULL, AV_LOG_INFO, \" (graph %d)\", ost->filter->graph->index);\n\n            av_log(NULL, AV_LOG_INFO, \" -> Stream #%d:%d (%s)\\n\", ost->file_index,\n                   ost->index, ost->enc ? ost->enc->name : \"?\");\n            continue;\n        }\n\n        av_log(NULL, AV_LOG_INFO, \"  Stream #%d:%d -> #%d:%d\",\n               input_streams[ost->source_index]->file_index,\n               input_streams[ost->source_index]->st->index,\n               ost->file_index,\n               ost->index);\n        if (ost->sync_ist != input_streams[ost->source_index])\n            av_log(NULL, AV_LOG_INFO, \" [sync #%d:%d]\",\n                   ost->sync_ist->file_index,\n                   ost->sync_ist->st->index);\n        if (ost->stream_copy)\n            av_log(NULL, AV_LOG_INFO, \" (copy)\");\n        else\n            av_log(NULL, AV_LOG_INFO, \" (%s -> %s)\", input_streams[ost->source_index]->dec ?\n                   input_streams[ost->source_index]->dec->name : \"?\",\n                   ost->enc ? ost->enc->name : \"?\");\n        av_log(NULL, AV_LOG_INFO, \"\\n\");\n    }\n\n    if (ret) {\n        av_log(NULL, AV_LOG_ERROR, \"%s\\n\", error);\n        return ret;\n    }\n\n    if (want_sdp) {\n        print_sdp();\n    }\n\n    return 0;\n}"}, {"function body": "static int need_output(void)\n{\n    int i;\n\n    for (i = 0; i < nb_output_streams; i++) {\n        OutputStream *ost    = output_streams[i];\n        OutputFile *of       = output_files[ost->file_index];\n        AVFormatContext *os  = output_files[ost->file_index]->ctx;\n\n        if (ost->finished ||\n            (os->pb && avio_tell(os->pb) >= of->limit_filesize))\n            continue;\n        if (ost->frame_number >= ost->max_frames) {\n            int j;\n            for (j = 0; j < of->ctx->nb_streams; j++)\n                close_output_stream(output_streams[of->ost_index + j]);\n            continue;\n        }\n\n        return 1;\n    }\n\n    return 0;\n}"}, {"function body": "static OutputStream *choose_output(void)\n{\n    int i;\n    int64_t opts_min = INT64_MAX;\n    OutputStream *ost_min = NULL;\n\n    for (i = 0; i < nb_output_streams; i++) {\n        OutputStream *ost = output_streams[i];\n        int64_t opts = av_rescale_q(ost->st->cur_dts, ost->st->time_base,\n                                    AV_TIME_BASE_Q);\n        if (!ost->unavailable && !ost->finished && opts < opts_min) {\n            opts_min = opts;\n            ost_min  = ost;\n        }\n    }\n    return ost_min;\n}"}, {"function body": "static int check_keyboard_interaction(int64_t cur_time)\n{\n    int i, ret, key;\n    static int64_t last_time;\n    if (received_nb_signals)\n        return AVERROR_EXIT;\n    /* read_key() returns 0 on EOF */\n    if(cur_time - last_time >= 100000 && !run_as_daemon){\n        key =  read_key();\n        last_time = cur_time;\n    }else\n        key = -1;\n    if (key == 'q')\n        return AVERROR_EXIT;\n    if (key == '+') av_log_set_level(av_log_get_level()+10);\n    if (key == '-') av_log_set_level(av_log_get_level()-10);\n    if (key == 's') qp_hist     ^= 1;\n    if (key == 'h'){\n        if (do_hex_dump){\n            do_hex_dump = do_pkt_dump = 0;\n        } else if(do_pkt_dump){\n            do_hex_dump = 1;\n        } else\n            do_pkt_dump = 1;\n        av_log_set_level(AV_LOG_DEBUG);\n    }\n    if (key == 'c' || key == 'C'){\n        char buf[4096], target[64], command[256], arg[256] = {0};\n        double time;\n        int k, n = 0;\n        fprintf(stderr, \"\\nEnter command: <target> <time> <command>[ <argument>]\\n\");\n        i = 0;\n        while ((k = read_key()) != '\\n' && k != '\\r' && i < sizeof(buf)-1)\n            if (k > 0)\n                buf[i++] = k;\n        buf[i] = 0;\n        if (k > 0 &&\n            (n = sscanf(buf, \"%63[^ ] %lf %255[^ ] %255[^\\n]\", target, &time, command, arg)) >= 3) {\n            av_log(NULL, AV_LOG_DEBUG, \"Processing command target:%s time:%f command:%s arg:%s\",\n                   target, time, command, arg);\n            for (i = 0; i < nb_filtergraphs; i++) {\n                FilterGraph *fg = filtergraphs[i];\n                if (fg->graph) {\n                    if (time < 0) {\n                        ret = avfilter_graph_send_command(fg->graph, target, command, arg, buf, sizeof(buf),\n                                                          key == 'c' ? AVFILTER_CMD_FLAG_ONE : 0);\n                        fprintf(stderr, \"Command reply for stream %d: ret:%d res:%s\\n\", i, ret, buf);\n                    } else {\n                        ret = avfilter_graph_queue_command(fg->graph, target, command, arg, 0, time);\n                    }\n                }\n            }\n        } else {\n            av_log(NULL, AV_LOG_ERROR,\n                   \"Parse error, at least 3 arguments were expected, \"\n                   \"only %d given in string '%s'\\n\", n, buf);\n        }\n    }\n    if (key == 'd' || key == 'D'){\n        int debug=0;\n        if(key == 'D') {\n            debug = input_streams[0]->st->codec->debug<<1;\n            if(!debug) debug = 1;\n            while(debug & (FF_DEBUG_DCT_COEFF|FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE)) //unsupported, would just crash\n                debug += debug;\n        }else\n            if(scanf(\"%d\", &debug)!=1)\n                fprintf(stderr,\"error parsing debug value\\n\");\n        for(i=0;i<nb_input_streams;i++) {\n            input_streams[i]->st->codec->debug = debug;\n        }\n        for(i=0;i<nb_output_streams;i++) {\n            OutputStream *ost = output_streams[i];\n            ost->st->codec->debug = debug;\n        }\n        if(debug) av_log_set_level(AV_LOG_DEBUG);\n        fprintf(stderr,\"debug=%d\\n\", debug);\n    }\n    if (key == '?'){\n        fprintf(stderr, \"key    function\\n\"\n                        \"?      show this help\\n\"\n                        \"+      increase verbosity\\n\"\n                        \"-      decrease verbosity\\n\"\n                        \"c      Send command to filtergraph\\n\"\n                        \"D      cycle through available debug modes\\n\"\n                        \"h      dump packets/hex press to cycle through the 3 states\\n\"\n                        \"q      quit\\n\"\n                        \"s      Show QP histogram\\n\"\n        );\n    }\n    return 0;\n}"}, {"function body": "static void *input_thread(void *arg)\n{\n    InputFile *f = arg;\n    int ret = 0;\n\n    while (!transcoding_finished && ret >= 0) {\n        AVPacket pkt;\n        ret = av_read_frame(f->ctx, &pkt);\n\n        if (ret == AVERROR(EAGAIN)) {\n            av_usleep(10000);\n            ret = 0;\n            continue;\n        } else if (ret < 0)\n            break;\n\n        pthread_mutex_lock(&f->fifo_lock);\n        while (!av_fifo_space(f->fifo))\n            pthread_cond_wait(&f->fifo_cond, &f->fifo_lock);\n\n        av_dup_packet(&pkt);\n        av_fifo_generic_write(f->fifo, &pkt, sizeof(pkt), NULL);\n\n        pthread_mutex_unlock(&f->fifo_lock);\n    }\n\n    f->finished = 1;\n    return NULL;\n}"}, {"function body": "static void free_input_threads(void)\n{\n    int i;\n\n    if (nb_input_files == 1)\n        return;\n\n    transcoding_finished = 1;\n\n    for (i = 0; i < nb_input_files; i++) {\n        InputFile *f = input_files[i];\n        AVPacket pkt;\n\n        if (!f->fifo || f->joined)\n            continue;\n\n        pthread_mutex_lock(&f->fifo_lock);\n        while (av_fifo_size(f->fifo)) {\n            av_fifo_generic_read(f->fifo, &pkt, sizeof(pkt), NULL);\n            av_free_packet(&pkt);\n        }\n        pthread_cond_signal(&f->fifo_cond);\n        pthread_mutex_unlock(&f->fifo_lock);\n\n        pthread_join(f->thread, NULL);\n        f->joined = 1;\n\n        while (av_fifo_size(f->fifo)) {\n            av_fifo_generic_read(f->fifo, &pkt, sizeof(pkt), NULL);\n            av_free_packet(&pkt);\n        }\n        av_fifo_free(f->fifo);\n    }\n}"}, {"function body": "static int init_input_threads(void)\n{\n    int i, ret;\n\n    if (nb_input_files == 1)\n        return 0;\n\n    for (i = 0; i < nb_input_files; i++) {\n        InputFile *f = input_files[i];\n\n        if (!(f->fifo = av_fifo_alloc(8*sizeof(AVPacket))))\n            return AVERROR(ENOMEM);\n\n        pthread_mutex_init(&f->fifo_lock, NULL);\n        pthread_cond_init (&f->fifo_cond, NULL);\n\n        if ((ret = pthread_create(&f->thread, NULL, input_thread, f)))\n            return AVERROR(ret);\n    }\n    return 0;\n}"}, {"function body": "static int get_input_packet_mt(InputFile *f, AVPacket *pkt)\n{\n    int ret = 0;\n\n    pthread_mutex_lock(&f->fifo_lock);\n\n    if (av_fifo_size(f->fifo)) {\n        av_fifo_generic_read(f->fifo, pkt, sizeof(*pkt), NULL);\n        pthread_cond_signal(&f->fifo_cond);\n    } else {\n        if (f->finished)\n            ret = AVERROR_EOF;\n        else\n            ret = AVERROR(EAGAIN);\n    }\n\n    pthread_mutex_unlock(&f->fifo_lock);\n\n    return ret;\n}"}, {"function body": "static int get_input_packet(InputFile *f, AVPacket *pkt)\n{\n#if HAVE_PTHREADS\n    if (nb_input_files > 1)\n        return get_input_packet_mt(f, pkt);\n#endif\n    return av_read_frame(f->ctx, pkt);\n}"}, {"function body": "static int got_eagain(void)\n{\n    int i;\n    for (i = 0; i < nb_output_streams; i++)\n        if (output_streams[i]->unavailable)\n            return 1;\n    return 0;\n}"}, {"function body": "static void reset_eagain(void)\n{\n    int i;\n    for (i = 0; i < nb_input_files; i++)\n        input_files[i]->eagain = 0;\n    for (i = 0; i < nb_output_streams; i++)\n        output_streams[i]->unavailable = 0;\n}"}, {"function body": "static int process_input(int file_index)\n{\n    InputFile *ifile = input_files[file_index];\n    AVFormatContext *is;\n    InputStream *ist;\n    AVPacket pkt;\n    int ret, i, j;\n\n    is  = ifile->ctx;\n    ret = get_input_packet(ifile, &pkt);\n\n    if (ret == AVERROR(EAGAIN)) {\n        ifile->eagain = 1;\n        return ret;\n    }\n    if (ret < 0) {\n        if (ret != AVERROR_EOF) {\n            print_error(is->filename, ret);\n            if (exit_on_error)\n                exit_program(1);\n        }\n        ifile->eof_reached = 1;\n\n        for (i = 0; i < ifile->nb_streams; i++) {\n            ist = input_streams[ifile->ist_index + i];\n            if (ist->decoding_needed)\n                output_packet(ist, NULL);\n\n            /* mark all outputs that don't go through lavfi as finished */\n            for (j = 0; j < nb_output_streams; j++) {\n                OutputStream *ost = output_streams[j];\n\n                if (ost->source_index == ifile->ist_index + i &&\n                    (ost->stream_copy || ost->enc->type == AVMEDIA_TYPE_SUBTITLE))\n                    close_output_stream(ost);\n            }\n        }\n\n        return AVERROR(EAGAIN);\n    }\n\n    reset_eagain();\n\n    if (do_pkt_dump) {\n        av_pkt_dump_log2(NULL, AV_LOG_DEBUG, &pkt, do_hex_dump,\n                         is->streams[pkt.stream_index]);\n    }\n    /* the following test is needed in case new streams appear\n       dynamically in stream : we ignore them */\n    if (pkt.stream_index >= ifile->nb_streams) {\n        report_new_stream(file_index, &pkt);\n        goto discard_packet;\n    }\n\n    ist = input_streams[ifile->ist_index + pkt.stream_index];\n    if (ist->discard)\n        goto discard_packet;\n\n    if(!ist->wrap_correction_done && input_files[file_index]->ctx->start_time != AV_NOPTS_VALUE && ist->st->pts_wrap_bits < 64){\n        int64_t stime = av_rescale_q(input_files[file_index]->ctx->start_time, AV_TIME_BASE_Q, ist->st->time_base);\n        int64_t stime2= stime + (1ULL<<ist->st->pts_wrap_bits);\n        ist->wrap_correction_done = 1;\n\n        if(stime2 > stime && pkt.dts != AV_NOPTS_VALUE && pkt.dts > stime + (1LL<<(ist->st->pts_wrap_bits-1))) {\n            pkt.dts -= 1ULL<<ist->st->pts_wrap_bits;\n            ist->wrap_correction_done = 0;\n        }\n        if(stime2 > stime && pkt.pts != AV_NOPTS_VALUE && pkt.pts > stime + (1LL<<(ist->st->pts_wrap_bits-1))) {\n            pkt.pts -= 1ULL<<ist->st->pts_wrap_bits;\n            ist->wrap_correction_done = 0;\n        }\n    }\n\n    if (pkt.dts != AV_NOPTS_VALUE)\n        pkt.dts += av_rescale_q(ifile->ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\n    if (pkt.pts != AV_NOPTS_VALUE)\n        pkt.pts += av_rescale_q(ifile->ts_offset, AV_TIME_BASE_Q, ist->st->time_base);\n\n    if (pkt.pts != AV_NOPTS_VALUE)\n        pkt.pts *= ist->ts_scale;\n    if (pkt.dts != AV_NOPTS_VALUE)\n        pkt.dts *= ist->ts_scale;\n\n    if (debug_ts) {\n        av_log(NULL, AV_LOG_INFO, \"demuxer -> ist_index:%d type:%s \"\n                \"next_dts:%s next_dts_time:%s next_pts:%s next_pts_time:%s  pkt_pts:%s pkt_pts_time:%s pkt_dts:%s pkt_dts_time:%s off:%\"PRId64\"\\n\",\n                ifile->ist_index + pkt.stream_index, av_get_media_type_string(ist->st->codec->codec_type),\n                av_ts2str(ist->next_dts), av_ts2timestr(ist->next_dts, &AV_TIME_BASE_Q),\n                av_ts2str(ist->next_pts), av_ts2timestr(ist->next_pts, &AV_TIME_BASE_Q),\n                av_ts2str(pkt.pts), av_ts2timestr(pkt.pts, &ist->st->time_base),\n                av_ts2str(pkt.dts), av_ts2timestr(pkt.dts, &ist->st->time_base),\n                input_files[ist->file_index]->ts_offset);\n    }\n\n    if (pkt.dts != AV_NOPTS_VALUE && ist->next_dts != AV_NOPTS_VALUE &&\n        !copy_ts) {\n        int64_t pkt_dts = av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);\n        int64_t delta   = pkt_dts - ist->next_dts;\n        if (is->iformat->flags & AVFMT_TS_DISCONT) {\n        if(delta < -1LL*dts_delta_threshold*AV_TIME_BASE ||\n            (delta > 1LL*dts_delta_threshold*AV_TIME_BASE &&\n                ist->st->codec->codec_type != AVMEDIA_TYPE_SUBTITLE) ||\n            pkt_dts+1<ist->pts){\n            ifile->ts_offset -= delta;\n            av_log(NULL, AV_LOG_DEBUG,\n                   \"timestamp discontinuity %\"PRId64\", new offset= %\"PRId64\"\\n\",\n                   delta, ifile->ts_offset);\n            pkt.dts -= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n            if (pkt.pts != AV_NOPTS_VALUE)\n                pkt.pts -= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n        }\n        } else {\n            if ( delta < -1LL*dts_error_threshold*AV_TIME_BASE ||\n                (delta > 1LL*dts_error_threshold*AV_TIME_BASE && ist->st->codec->codec_type != AVMEDIA_TYPE_SUBTITLE)\n               ) {\n                av_log(NULL, AV_LOG_WARNING, \"DTS %\"PRId64\", next:%\"PRId64\" st:%d invalid dropping\\n\", pkt.dts, ist->next_dts, pkt.stream_index);\n                pkt.dts = AV_NOPTS_VALUE;\n            }\n            if (pkt.pts != AV_NOPTS_VALUE){\n                int64_t pkt_pts = av_rescale_q(pkt.pts, ist->st->time_base, AV_TIME_BASE_Q);\n                delta   = pkt_pts - ist->next_dts;\n                if ( delta < -1LL*dts_error_threshold*AV_TIME_BASE ||\n                    (delta > 1LL*dts_error_threshold*AV_TIME_BASE && ist->st->codec->codec_type != AVMEDIA_TYPE_SUBTITLE)\n                   ) {\n                    av_log(NULL, AV_LOG_WARNING, \"PTS %\"PRId64\", next:%\"PRId64\" invalid dropping st:%d\\n\", pkt.pts, ist->next_dts, pkt.stream_index);\n                    pkt.pts = AV_NOPTS_VALUE;\n                }\n            }\n        }\n    }\n\n    sub2video_heartbeat(ist, pkt.pts);\n\n    ret = output_packet(ist, &pkt);\n    if (ret < 0) {\n        char buf[128];\n        av_strerror(ret, buf, sizeof(buf));\n        av_log(NULL, AV_LOG_ERROR, \"Error while decoding stream #%d:%d: %s\\n\",\n                ist->file_index, ist->st->index, buf);\n        if (exit_on_error)\n            exit_program(1);\n    }\n\ndiscard_packet:\n    av_free_packet(&pkt);\n\n    return 0;\n}"}, {"function body": "static int transcode_from_filter(FilterGraph *graph, InputStream **best_ist)\n{\n    int i, ret;\n    int nb_requests, nb_requests_max = 0;\n    InputFilter *ifilter;\n    InputStream *ist;\n\n    *best_ist = NULL;\n    ret = avfilter_graph_request_oldest(graph->graph);\n    if (ret >= 0)\n        return reap_filters();\n\n    if (ret == AVERROR_EOF) {\n        ret = reap_filters();\n        for (i = 0; i < graph->nb_outputs; i++)\n            close_output_stream(graph->outputs[i]->ost);\n        return ret;\n    }\n    if (ret != AVERROR(EAGAIN))\n        return ret;\n\n    for (i = 0; i < graph->nb_inputs; i++) {\n        ifilter = graph->inputs[i];\n        ist = ifilter->ist;\n        if (input_files[ist->file_index]->eagain ||\n            input_files[ist->file_index]->eof_reached)\n            continue;\n        nb_requests = av_buffersrc_get_nb_failed_requests(ifilter->filter);\n        if (nb_requests > nb_requests_max) {\n            nb_requests_max = nb_requests;\n            *best_ist = ist;\n        }\n    }\n\n    if (!*best_ist)\n        for (i = 0; i < graph->nb_outputs; i++)\n            graph->outputs[i]->ost->unavailable = 1;\n\n    return 0;\n}"}, {"function body": "static int transcode_step(void)\n{\n    OutputStream *ost;\n    InputStream  *ist;\n    int ret;\n\n    ost = choose_output();\n    if (!ost) {\n        if (got_eagain()) {\n            reset_eagain();\n            av_usleep(10000);\n            return 0;\n        }\n        av_log(NULL, AV_LOG_VERBOSE, \"No more inputs to read from, finishing.\\n\");\n        return AVERROR_EOF;\n    }\n\n    if (ost->filter) {\n        if ((ret = transcode_from_filter(ost->filter->graph, &ist)) < 0)\n            return ret;\n        if (!ist)\n            return 0;\n    } else {\n        av_assert0(ost->source_index >= 0);\n        ist = input_streams[ost->source_index];\n    }\n\n    ret = process_input(ist->file_index);\n    if (ret == AVERROR(EAGAIN)) {\n        if (input_files[ist->file_index]->eagain)\n            ost->unavailable = 1;\n        return 0;\n    }\n    if (ret < 0)\n        return ret == AVERROR_EOF ? 0 : ret;\n\n    return reap_filters();\n}"}, {"function body": "static int transcode(void)\n{\n    int ret, i;\n    AVFormatContext *os;\n    OutputStream *ost;\n    InputStream *ist;\n    int64_t timer_start;\n\n    ret = transcode_init();\n    if (ret < 0)\n        goto fail;\n\n    if (stdin_interaction) {\n        av_log(NULL, AV_LOG_INFO, \"Press [q] to stop, [?] for help\\n\");\n    }\n\n    timer_start = av_gettime();\n\n#if HAVE_PTHREADS\n    if ((ret = init_input_threads()) < 0)\n        goto fail;\n#endif\n\n    while (!received_sigterm) {\n        int64_t cur_time= av_gettime();\n\n        /* if 'q' pressed, exits */\n        if (stdin_interaction)\n            if (check_keyboard_interaction(cur_time) < 0)\n                break;\n\n        /* check if there's any stream where output is still needed */\n        if (!need_output()) {\n            av_log(NULL, AV_LOG_VERBOSE, \"No more output streams to write to, finishing.\\n\");\n            break;\n        }\n\n        ret = transcode_step();\n        if (ret < 0) {\n            if (ret == AVERROR_EOF || ret == AVERROR(EAGAIN))\n                continue;\n\n            av_log(NULL, AV_LOG_ERROR, \"Error while filtering.\\n\");\n            break;\n        }\n\n        /* dump report by using the output first video and audio streams */\n        print_report(0, timer_start, cur_time);\n    }\n#if HAVE_PTHREADS\n    free_input_threads();\n#endif\n\n    /* at the end of stream, we must flush the decoder buffers */\n    for (i = 0; i < nb_input_streams; i++) {\n        ist = input_streams[i];\n        if (!input_files[ist->file_index]->eof_reached && ist->decoding_needed) {\n            output_packet(ist, NULL);\n        }\n    }\n    flush_encoders();\n\n    term_exit();\n\n    /* write the trailer if needed and close file */\n    for (i = 0; i < nb_output_files; i++) {\n        os = output_files[i]->ctx;\n        av_write_trailer(os);\n    }\n\n    /* dump report by using the first video and audio streams */\n    print_report(1, timer_start, av_gettime());\n\n    /* close each encoder */\n    for (i = 0; i < nb_output_streams; i++) {\n        ost = output_streams[i];\n        if (ost->encoding_needed) {\n            av_freep(&ost->st->codec->stats_in);\n            avcodec_close(ost->st->codec);\n        }\n    }\n\n    /* close each decoder */\n    for (i = 0; i < nb_input_streams; i++) {\n        ist = input_streams[i];\n        if (ist->decoding_needed) {\n            avcodec_close(ist->st->codec);\n        }\n    }\n\n    /* finished ! */\n    ret = 0;\n\n fail:\n#if HAVE_PTHREADS\n    free_input_threads();\n#endif\n\n    if (output_streams) {\n        for (i = 0; i < nb_output_streams; i++) {\n            ost = output_streams[i];\n            if (ost) {\n                if (ost->stream_copy)\n                    av_freep(&ost->st->codec->extradata);\n                if (ost->logfile) {\n                    fclose(ost->logfile);\n                    ost->logfile = NULL;\n                }\n                av_freep(&ost->st->codec->subtitle_header);\n                av_free(ost->forced_kf_pts);\n                av_dict_free(&ost->opts);\n            }\n        }\n    }\n    return ret;\n}"}, {"function body": "static int64_t getutime(void)\n{\n#if HAVE_GETRUSAGE\n    struct rusage rusage;\n\n    getrusage(RUSAGE_SELF, &rusage);\n    return (rusage.ru_utime.tv_sec * 1000000LL) + rusage.ru_utime.tv_usec;\n#elif HAVE_GETPROCESSTIMES\n    HANDLE proc;\n    FILETIME c, e, k, u;\n    proc = GetCurrentProcess();\n    GetProcessTimes(proc, &c, &e, &k, &u);\n    return ((int64_t) u.dwHighDateTime << 32 | u.dwLowDateTime) / 10;\n#else\n    return av_gettime();\n#endif\n}"}, {"function body": "static int64_t getmaxrss(void)\n{\n#if HAVE_GETRUSAGE && HAVE_STRUCT_RUSAGE_RU_MAXRSS\n    struct rusage rusage;\n    getrusage(RUSAGE_SELF, &rusage);\n    return (int64_t)rusage.ru_maxrss * 1024;\n#elif HAVE_GETPROCESSMEMORYINFO\n    HANDLE proc;\n    PROCESS_MEMORY_COUNTERS memcounters;\n    proc = GetCurrentProcess();\n    memcounters.cb = sizeof(memcounters);\n    GetProcessMemoryInfo(proc, &memcounters, sizeof(memcounters));\n    return memcounters.PeakPagefileUsage;\n#else\n    return 0;\n#endif\n}"}, {"function body": "static void log_callback_null(void *ptr, int level, const char *fmt, va_list vl)\n{\n}"}, {"function body": "static void parse_cpuflags(int argc, char **argv, const OptionDef *options)\n{\n    int idx = locate_option(argc, argv, options, \"cpuflags\");\n    if (idx && argv[idx + 1])\n        opt_cpuflags(NULL, \"cpuflags\", argv[idx + 1]);\n}"}, {"function body": "int main(int argc, char **argv)\n{\n    OptionsContext o = { 0 };\n    int64_t ti;\n\n    reset_options(&o, 0);\n\n    av_log_set_flags(AV_LOG_SKIP_REPEATED);\n    parse_loglevel(argc, argv, options);\n\n    if(argc>1 && !strcmp(argv[1], \"-d\")){\n        run_as_daemon=1;\n        av_log_set_callback(log_callback_null);\n        argc--;\n        argv++;\n    }\n\n    avcodec_register_all();\n#if CONFIG_AVDEVICE\n    avdevice_register_all();\n#endif\n    avfilter_register_all();\n    av_register_all();\n    avformat_network_init();\n\n    show_banner(argc, argv, options);\n\n    term_init();\n\n    parse_cpuflags(argc, argv, options);\n\n    /* parse options */\n    parse_options(&o, argc, argv, options, opt_output_file);\n\n    if (nb_output_files <= 0 && nb_input_files == 0) {\n        show_usage();\n        av_log(NULL, AV_LOG_WARNING, \"Use -h to get full help or, even better, run 'man %s'\\n\", program_name);\n        exit_program(1);\n    }\n\n    /* file converter / grab */\n    if (nb_output_files <= 0) {\n        av_log(NULL, AV_LOG_FATAL, \"At least one output file must be specified\\n\");\n        exit_program(1);\n    }\n\n//     if (nb_input_files == 0) {\n//         av_log(NULL, AV_LOG_FATAL, \"At least one input file must be specified\\n\");\n//         exit_program(1);\n//     }\n\n    current_time = ti = getutime();\n    if (transcode() < 0)\n        exit_program(1);\n    ti = getutime() - ti;\n    if (do_benchmark) {\n        int maxrss = getmaxrss() / 1024;\n        printf(\"bench: utime=%0.3fs maxrss=%ikB\\n\", ti / 1000000.0, maxrss);\n    }\n\n    exit_program(0);\n    return 0;\n}"}]}, {"ffplay.c": [{"function body": "av_noreturn exit_program(int ret)\n{\n    exit(ret);\n}"}, {"function body": "static int packet_queue_put_private(PacketQueue *q, AVPacket *pkt)\n{\n    AVPacketList *pkt1;\n\n    if (q->abort_request)\n       return -1;\n\n    pkt1 = av_malloc(sizeof(AVPacketList));\n    if (!pkt1)\n        return -1;\n    pkt1->pkt = *pkt;\n    pkt1->next = NULL;\n\n    if (!q->last_pkt)\n        q->first_pkt = pkt1;\n    else\n        q->last_pkt->next = pkt1;\n    q->last_pkt = pkt1;\n    q->nb_packets++;\n    q->size += pkt1->pkt.size + sizeof(*pkt1);\n    /* XXX: should duplicate packet data in DV case */\n    SDL_CondSignal(q->cond);\n    return 0;\n}"}, {"function body": "static int packet_queue_put(PacketQueue *q, AVPacket *pkt)\n{\n    int ret;\n\n    /* duplicate the packet */\n    if (pkt != &flush_pkt && av_dup_packet(pkt) < 0)\n        return -1;\n\n    SDL_LockMutex(q->mutex);\n    ret = packet_queue_put_private(q, pkt);\n    SDL_UnlockMutex(q->mutex);\n\n    if (pkt != &flush_pkt && ret < 0)\n        av_free_packet(pkt);\n\n    return ret;\n}"}, {"function body": "static void packet_queue_init(PacketQueue *q)\n{\n    memset(q, 0, sizeof(PacketQueue));\n    q->mutex = SDL_CreateMutex();\n    q->cond = SDL_CreateCond();\n    q->abort_request = 1;\n}"}, {"function body": "static void packet_queue_flush(PacketQueue *q)\n{\n    AVPacketList *pkt, *pkt1;\n\n    SDL_LockMutex(q->mutex);\n    for (pkt = q->first_pkt; pkt != NULL; pkt = pkt1) {\n        pkt1 = pkt->next;\n        av_free_packet(&pkt->pkt);\n        av_freep(&pkt);\n    }\n    q->last_pkt = NULL;\n    q->first_pkt = NULL;\n    q->nb_packets = 0;\n    q->size = 0;\n    SDL_UnlockMutex(q->mutex);\n}"}, {"function body": "static void packet_queue_destroy(PacketQueue *q)\n{\n    packet_queue_flush(q);\n    SDL_DestroyMutex(q->mutex);\n    SDL_DestroyCond(q->cond);\n}"}, {"function body": "static void packet_queue_abort(PacketQueue *q)\n{\n    SDL_LockMutex(q->mutex);\n\n    q->abort_request = 1;\n\n    SDL_CondSignal(q->cond);\n\n    SDL_UnlockMutex(q->mutex);\n}"}, {"function body": "static void packet_queue_start(PacketQueue *q)\n{\n    SDL_LockMutex(q->mutex);\n    q->abort_request = 0;\n    packet_queue_put_private(q, &flush_pkt);\n    SDL_UnlockMutex(q->mutex);\n}"}, {"function body": "static int packet_queue_get(PacketQueue *q, AVPacket *pkt, int block)\n{\n    AVPacketList *pkt1;\n    int ret;\n\n    SDL_LockMutex(q->mutex);\n\n    for (;;) {\n        if (q->abort_request) {\n            ret = -1;\n            break;\n        }\n\n        pkt1 = q->first_pkt;\n        if (pkt1) {\n            q->first_pkt = pkt1->next;\n            if (!q->first_pkt)\n                q->last_pkt = NULL;\n            q->nb_packets--;\n            q->size -= pkt1->pkt.size + sizeof(*pkt1);\n            *pkt = pkt1->pkt;\n            av_free(pkt1);\n            ret = 1;\n            break;\n        } else if (!block) {\n            ret = 0;\n            break;\n        } else {\n            SDL_CondWait(q->cond, q->mutex);\n        }\n    }\n    SDL_UnlockMutex(q->mutex);\n    return ret;\n}"}, {"function body": "static inline void fill_rectangle(SDL_Surface *screen,\n                                  int x, int y, int w, int h, int color)\n{\n    SDL_Rect rect;\n    rect.x = x;\n    rect.y = y;\n    rect.w = w;\n    rect.h = h;\n    SDL_FillRect(screen, &rect, color);\n}"}, {"function body": "static void blend_subrect(AVPicture *dst, const AVSubtitleRect *rect, int imgw, int imgh)\n{\n    int wrap, wrap3, width2, skip2;\n    int y, u, v, a, u1, v1, a1, w, h;\n    uint8_t *lum, *cb, *cr;\n    const uint8_t *p;\n    const uint32_t *pal;\n    int dstx, dsty, dstw, dsth;\n\n    dstw = av_clip(rect->w, 0, imgw);\n    dsth = av_clip(rect->h, 0, imgh);\n    dstx = av_clip(rect->x, 0, imgw - dstw);\n    dsty = av_clip(rect->y, 0, imgh - dsth);\n    lum = dst->data[0] + dsty * dst->linesize[0];\n    cb  = dst->data[1] + (dsty >> 1) * dst->linesize[1];\n    cr  = dst->data[2] + (dsty >> 1) * dst->linesize[2];\n\n    width2 = ((dstw + 1) >> 1) + (dstx & ~dstw & 1);\n    skip2 = dstx >> 1;\n    wrap = dst->linesize[0];\n    wrap3 = rect->pict.linesize[0];\n    p = rect->pict.data[0];\n    pal = (const uint32_t *)rect->pict.data[1];  /* Now in YCrCb! */\n\n    if (dsty & 1) {\n        lum += dstx;\n        cb += skip2;\n        cr += skip2;\n\n        if (dstx & 1) {\n            YUVA_IN(y, u, v, a, p, pal);\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            cb[0] = ALPHA_BLEND(a >> 2, cb[0], u, 0);\n            cr[0] = ALPHA_BLEND(a >> 2, cr[0], v, 0);\n            cb++;\n            cr++;\n            lum++;\n            p += BPP;\n        }\n        for (w = dstw - (dstx & 1); w >= 2; w -= 2) {\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 = u;\n            v1 = v;\n            a1 = a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n\n            YUVA_IN(y, u, v, a, p + BPP, pal);\n            u1 += u;\n            v1 += v;\n            a1 += a;\n            lum[1] = ALPHA_BLEND(a, lum[1], y, 0);\n            cb[0] = ALPHA_BLEND(a1 >> 2, cb[0], u1, 1);\n            cr[0] = ALPHA_BLEND(a1 >> 2, cr[0], v1, 1);\n            cb++;\n            cr++;\n            p += 2 * BPP;\n            lum += 2;\n        }\n        if (w) {\n            YUVA_IN(y, u, v, a, p, pal);\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            cb[0] = ALPHA_BLEND(a >> 2, cb[0], u, 0);\n            cr[0] = ALPHA_BLEND(a >> 2, cr[0], v, 0);\n            p++;\n            lum++;\n        }\n        p += wrap3 - dstw * BPP;\n        lum += wrap - dstw - dstx;\n        cb += dst->linesize[1] - width2 - skip2;\n        cr += dst->linesize[2] - width2 - skip2;\n    }\n    for (h = dsth - (dsty & 1); h >= 2; h -= 2) {\n        lum += dstx;\n        cb += skip2;\n        cr += skip2;\n\n        if (dstx & 1) {\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 = u;\n            v1 = v;\n            a1 = a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            p += wrap3;\n            lum += wrap;\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 += u;\n            v1 += v;\n            a1 += a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            cb[0] = ALPHA_BLEND(a1 >> 2, cb[0], u1, 1);\n            cr[0] = ALPHA_BLEND(a1 >> 2, cr[0], v1, 1);\n            cb++;\n            cr++;\n            p += -wrap3 + BPP;\n            lum += -wrap + 1;\n        }\n        for (w = dstw - (dstx & 1); w >= 2; w -= 2) {\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 = u;\n            v1 = v;\n            a1 = a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n\n            YUVA_IN(y, u, v, a, p + BPP, pal);\n            u1 += u;\n            v1 += v;\n            a1 += a;\n            lum[1] = ALPHA_BLEND(a, lum[1], y, 0);\n            p += wrap3;\n            lum += wrap;\n\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 += u;\n            v1 += v;\n            a1 += a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n\n            YUVA_IN(y, u, v, a, p + BPP, pal);\n            u1 += u;\n            v1 += v;\n            a1 += a;\n            lum[1] = ALPHA_BLEND(a, lum[1], y, 0);\n\n            cb[0] = ALPHA_BLEND(a1 >> 2, cb[0], u1, 2);\n            cr[0] = ALPHA_BLEND(a1 >> 2, cr[0], v1, 2);\n\n            cb++;\n            cr++;\n            p += -wrap3 + 2 * BPP;\n            lum += -wrap + 2;\n        }\n        if (w) {\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 = u;\n            v1 = v;\n            a1 = a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            p += wrap3;\n            lum += wrap;\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 += u;\n            v1 += v;\n            a1 += a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            cb[0] = ALPHA_BLEND(a1 >> 2, cb[0], u1, 1);\n            cr[0] = ALPHA_BLEND(a1 >> 2, cr[0], v1, 1);\n            cb++;\n            cr++;\n            p += -wrap3 + BPP;\n            lum += -wrap + 1;\n        }\n        p += wrap3 + (wrap3 - dstw * BPP);\n        lum += wrap + (wrap - dstw - dstx);\n        cb += dst->linesize[1] - width2 - skip2;\n        cr += dst->linesize[2] - width2 - skip2;\n    }\n    /* handle odd height */\n    if (h) {\n        lum += dstx;\n        cb += skip2;\n        cr += skip2;\n\n        if (dstx & 1) {\n            YUVA_IN(y, u, v, a, p, pal);\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            cb[0] = ALPHA_BLEND(a >> 2, cb[0], u, 0);\n            cr[0] = ALPHA_BLEND(a >> 2, cr[0], v, 0);\n            cb++;\n            cr++;\n            lum++;\n            p += BPP;\n        }\n        for (w = dstw - (dstx & 1); w >= 2; w -= 2) {\n            YUVA_IN(y, u, v, a, p, pal);\n            u1 = u;\n            v1 = v;\n            a1 = a;\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n\n            YUVA_IN(y, u, v, a, p + BPP, pal);\n            u1 += u;\n            v1 += v;\n            a1 += a;\n            lum[1] = ALPHA_BLEND(a, lum[1], y, 0);\n            cb[0] = ALPHA_BLEND(a1 >> 2, cb[0], u, 1);\n            cr[0] = ALPHA_BLEND(a1 >> 2, cr[0], v, 1);\n            cb++;\n            cr++;\n            p += 2 * BPP;\n            lum += 2;\n        }\n        if (w) {\n            YUVA_IN(y, u, v, a, p, pal);\n            lum[0] = ALPHA_BLEND(a, lum[0], y, 0);\n            cb[0] = ALPHA_BLEND(a >> 2, cb[0], u, 0);\n            cr[0] = ALPHA_BLEND(a >> 2, cr[0], v, 0);\n        }\n    }\n}"}, {"function body": "static void free_subpicture(SubPicture *sp)\n{\n    avsubtitle_free(&sp->sub);\n}"}, {"function body": "static void calculate_display_rect(SDL_Rect *rect, int scr_xleft, int scr_ytop, int scr_width, int scr_height, VideoPicture *vp)\n{\n    float aspect_ratio;\n    int width, height, x, y;\n\n    if (vp->sample_aspect_ratio.num == 0)\n        aspect_ratio = 0;\n    else\n        aspect_ratio = av_q2d(vp->sample_aspect_ratio);\n\n    if (aspect_ratio <= 0.0)\n        aspect_ratio = 1.0;\n    aspect_ratio *= (float)vp->width / (float)vp->height;\n\n    /* XXX: we suppose the screen has a 1.0 pixel ratio */\n    height = scr_height;\n    width = ((int)rint(height * aspect_ratio)) & ~1;\n    if (width > scr_width) {\n        width = scr_width;\n        height = ((int)rint(width / aspect_ratio)) & ~1;\n    }\n    x = (scr_width - width) / 2;\n    y = (scr_height - height) / 2;\n    rect->x = scr_xleft + x;\n    rect->y = scr_ytop  + y;\n    rect->w = FFMAX(width,  1);\n    rect->h = FFMAX(height, 1);\n}"}, {"function body": "static void video_image_display(VideoState *is)\n{\n    VideoPicture *vp;\n    SubPicture *sp;\n    AVPicture pict;\n    SDL_Rect rect;\n    int i;\n\n    vp = &is->pictq[is->pictq_rindex];\n    if (vp->bmp) {\n        if (is->subtitle_st) {\n            if (is->subpq_size > 0) {\n                sp = &is->subpq[is->subpq_rindex];\n\n                if (vp->pts >= sp->pts + ((float) sp->sub.start_display_time / 1000)) {\n                    SDL_LockYUVOverlay (vp->bmp);\n\n                    pict.data[0] = vp->bmp->pixels[0];\n                    pict.data[1] = vp->bmp->pixels[2];\n                    pict.data[2] = vp->bmp->pixels[1];\n\n                    pict.linesize[0] = vp->bmp->pitches[0];\n                    pict.linesize[1] = vp->bmp->pitches[2];\n                    pict.linesize[2] = vp->bmp->pitches[1];\n\n                    for (i = 0; i < sp->sub.num_rects; i++)\n                        blend_subrect(&pict, sp->sub.rects[i],\n                                      vp->bmp->w, vp->bmp->h);\n\n                    SDL_UnlockYUVOverlay (vp->bmp);\n                }\n            }\n        }\n\n        calculate_display_rect(&rect, is->xleft, is->ytop, is->width, is->height, vp);\n\n        SDL_DisplayYUVOverlay(vp->bmp, &rect);\n    }\n}"}, {"function body": "static inline int compute_mod(int a, int b)\n{\n    return a < 0 ? a%b + b : a%b;\n}"}, {"function body": "static void video_audio_display(VideoState *s)\n{\n    int i, i_start, x, y1, y, ys, delay, n, nb_display_channels;\n    int ch, channels, h, h2, bgcolor, fgcolor;\n    int16_t time_diff;\n    int rdft_bits, nb_freq;\n\n    for (rdft_bits = 1; (1 << rdft_bits) < 2 * s->height; rdft_bits++)\n        ;\n    nb_freq = 1 << (rdft_bits - 1);\n\n    /* compute display index : center on currently output samples */\n    channels = s->audio_tgt.channels;\n    nb_display_channels = channels;\n    if (!s->paused) {\n        int data_used= s->show_mode == SHOW_MODE_WAVES ? s->width : (2*nb_freq);\n        n = 2 * channels;\n        delay = s->audio_write_buf_size;\n        delay /= n;\n\n        /* to be more precise, we take into account the time spent since\n           the last buffer computation */\n        if (audio_callback_time) {\n            time_diff = av_gettime() - audio_callback_time;\n            delay -= (time_diff * s->audio_tgt.freq) / 1000000;\n        }\n\n        delay += 2 * data_used;\n        if (delay < data_used)\n            delay = data_used;\n\n        i_start= x = compute_mod(s->sample_array_index - delay * channels, SAMPLE_ARRAY_SIZE);\n        if (s->show_mode == SHOW_MODE_WAVES) {\n            h = INT_MIN;\n            for (i = 0; i < 1000; i += channels) {\n                int idx = (SAMPLE_ARRAY_SIZE + x - i) % SAMPLE_ARRAY_SIZE;\n                int a = s->sample_array[idx];\n                int b = s->sample_array[(idx + 4 * channels) % SAMPLE_ARRAY_SIZE];\n                int c = s->sample_array[(idx + 5 * channels) % SAMPLE_ARRAY_SIZE];\n                int d = s->sample_array[(idx + 9 * channels) % SAMPLE_ARRAY_SIZE];\n                int score = a - d;\n                if (h < score && (b ^ c) < 0) {\n                    h = score;\n                    i_start = idx;\n                }\n            }\n        }\n\n        s->last_i_start = i_start;\n    } else {\n        i_start = s->last_i_start;\n    }\n\n    bgcolor = SDL_MapRGB(screen->format, 0x00, 0x00, 0x00);\n    if (s->show_mode == SHOW_MODE_WAVES) {\n        fill_rectangle(screen,\n                       s->xleft, s->ytop, s->width, s->height,\n                       bgcolor);\n\n        fgcolor = SDL_MapRGB(screen->format, 0xff, 0xff, 0xff);\n\n        /* total height for one channel */\n        h = s->height / nb_display_channels;\n        /* graph height / 2 */\n        h2 = (h * 9) / 20;\n        for (ch = 0; ch < nb_display_channels; ch++) {\n            i = i_start + ch;\n            y1 = s->ytop + ch * h + (h / 2); /* position of center line */\n            for (x = 0; x < s->width; x++) {\n                y = (s->sample_array[i] * h2) >> 15;\n                if (y < 0) {\n                    y = -y;\n                    ys = y1 - y;\n                } else {\n                    ys = y1;\n                }\n                fill_rectangle(screen,\n                               s->xleft + x, ys, 1, y,\n                               fgcolor);\n                i += channels;\n                if (i >= SAMPLE_ARRAY_SIZE)\n                    i -= SAMPLE_ARRAY_SIZE;\n            }\n        }\n\n        fgcolor = SDL_MapRGB(screen->format, 0x00, 0x00, 0xff);\n\n        for (ch = 1; ch < nb_display_channels; ch++) {\n            y = s->ytop + ch * h;\n            fill_rectangle(screen,\n                           s->xleft, y, s->width, 1,\n                           fgcolor);\n        }\n        SDL_UpdateRect(screen, s->xleft, s->ytop, s->width, s->height);\n    } else {\n        nb_display_channels= FFMIN(nb_display_channels, 2);\n        if (rdft_bits != s->rdft_bits) {\n            av_rdft_end(s->rdft);\n            av_free(s->rdft_data);\n            s->rdft = av_rdft_init(rdft_bits, DFT_R2C);\n            s->rdft_bits = rdft_bits;\n            s->rdft_data = av_malloc(4 * nb_freq * sizeof(*s->rdft_data));\n        }\n        {\n            FFTSample *data[2];\n            for (ch = 0; ch < nb_display_channels; ch++) {\n                data[ch] = s->rdft_data + 2 * nb_freq * ch;\n                i = i_start + ch;\n                for (x = 0; x < 2 * nb_freq; x++) {\n                    double w = (x-nb_freq) * (1.0 / nb_freq);\n                    data[ch][x] = s->sample_array[i] * (1.0 - w * w);\n                    i += channels;\n                    if (i >= SAMPLE_ARRAY_SIZE)\n                        i -= SAMPLE_ARRAY_SIZE;\n                }\n                av_rdft_calc(s->rdft, data[ch]);\n            }\n            // least efficient way to do this, we should of course directly access it but its more than fast enough\n            for (y = 0; y < s->height; y++) {\n                double w = 1 / sqrt(nb_freq);\n                int a = sqrt(w * sqrt(data[0][2 * y + 0] * data[0][2 * y + 0] + data[0][2 * y + 1] * data[0][2 * y + 1]));\n                int b = (nb_display_channels == 2 ) ? sqrt(w * sqrt(data[1][2 * y + 0] * data[1][2 * y + 0]\n                       + data[1][2 * y + 1] * data[1][2 * y + 1])) : a;\n                a = FFMIN(a, 255);\n                b = FFMIN(b, 255);\n                fgcolor = SDL_MapRGB(screen->format, a, b, (a + b) / 2);\n\n                fill_rectangle(screen,\n                            s->xpos, s->height-y, 1, 1,\n                            fgcolor);\n            }\n        }\n        SDL_UpdateRect(screen, s->xpos, s->ytop, 1, s->height);\n        if (!s->paused)\n            s->xpos++;\n        if (s->xpos >= s->width)\n            s->xpos= s->xleft;\n    }\n}"}, {"function body": "static void stream_close(VideoState *is)\n{\n    VideoPicture *vp;\n    int i;\n    /* XXX: use a special url_shutdown call to abort parse cleanly */\n    is->abort_request = 1;\n    SDL_WaitThread(is->read_tid, NULL);\n    SDL_WaitThread(is->refresh_tid, NULL);\n    packet_queue_destroy(&is->videoq);\n    packet_queue_destroy(&is->audioq);\n    packet_queue_destroy(&is->subtitleq);\n\n    /* free all pictures */\n    for (i = 0; i < VIDEO_PICTURE_QUEUE_SIZE; i++) {\n        vp = &is->pictq[i];\n#if CONFIG_AVFILTER\n        avfilter_unref_bufferp(&vp->picref);\n#endif\n        if (vp->bmp) {\n            SDL_FreeYUVOverlay(vp->bmp);\n            vp->bmp = NULL;\n        }\n    }\n    SDL_DestroyMutex(is->pictq_mutex);\n    SDL_DestroyCond(is->pictq_cond);\n    SDL_DestroyMutex(is->subpq_mutex);\n    SDL_DestroyCond(is->subpq_cond);\n    SDL_DestroyCond(is->continue_read_thread);\n#if !CONFIG_AVFILTER\n    if (is->img_convert_ctx)\n        sws_freeContext(is->img_convert_ctx);\n#endif\n    av_free(is);\n}"}, {"function body": "static void do_exit(VideoState *is)\n{\n    if (is) {\n        stream_close(is);\n    }\n    av_lockmgr_register(NULL);\n    uninit_opts();\n#if CONFIG_AVFILTER\n    avfilter_uninit();\n    av_freep(&vfilters);\n#endif\n    avformat_network_deinit();\n    if (show_status)\n        printf(\"\\n\");\n    SDL_Quit();\n    av_log(NULL, AV_LOG_QUIET, \"%s\", \"\");\n    exit(0);\n}"}, {"function body": "static void sigterm_handler(int sig)\n{\n    exit(123);\n}"}, {"function body": "static int video_open(VideoState *is, int force_set_video_mode)\n{\n    int flags = SDL_HWSURFACE | SDL_ASYNCBLIT | SDL_HWACCEL;\n    int w,h;\n    VideoPicture *vp = &is->pictq[is->pictq_rindex];\n    SDL_Rect rect;\n\n    if (is_full_screen) flags |= SDL_FULLSCREEN;\n    else                flags |= SDL_RESIZABLE;\n\n    if (is_full_screen && fs_screen_width) {\n        w = fs_screen_width;\n        h = fs_screen_height;\n    } else if (!is_full_screen && screen_width) {\n        w = screen_width;\n        h = screen_height;\n    } else if (vp->width) {\n        calculate_display_rect(&rect, 0, 0, INT_MAX, vp->height, vp);\n        w = rect.w;\n        h = rect.h;\n    } else {\n        w = 640;\n        h = 480;\n    }\n    if (screen && is->width == screen->w && screen->w == w\n       && is->height== screen->h && screen->h == h && !force_set_video_mode)\n        return 0;\n    screen = SDL_SetVideoMode(w, h, 0, flags);\n    if (!screen) {\n        fprintf(stderr, \"SDL: could not set video mode - exiting\\n\");\n        do_exit(is);\n    }\n    if (!window_title)\n        window_title = input_filename;\n    SDL_WM_SetCaption(window_title, window_title);\n\n    is->width  = screen->w;\n    is->height = screen->h;\n\n    return 0;\n}"}, {"function body": "static void video_display(VideoState *is)\n{\n    if (!screen)\n        video_open(is, 0);\n    if (is->audio_st && is->show_mode != SHOW_MODE_VIDEO)\n        video_audio_display(is);\n    else if (is->video_st)\n        video_image_display(is);\n}"}, {"function body": "static int refresh_thread(void *opaque)\n{\n    VideoState *is= opaque;\n    while (!is->abort_request) {\n        SDL_Event event;\n        event.type = FF_REFRESH_EVENT;\n        event.user.data1 = opaque;\n        if (!is->refresh && (!is->paused || is->force_refresh)) {\n            is->refresh = 1;\n            SDL_PushEvent(&event);\n        }\n        //FIXME ideally we should wait the correct time but SDLs event passing is so slow it would be silly\n        av_usleep(is->audio_st && is->show_mode != SHOW_MODE_VIDEO ? rdftspeed*1000 : 5000);\n    }\n    return 0;\n}"}, {"function body": "static double get_audio_clock(VideoState *is)\n{\n    if (is->paused) {\n        return is->audio_current_pts;\n    } else {\n        return is->audio_current_pts_drift + av_gettime() / 1000000.0;\n    }\n}"}, {"function body": "static double get_video_clock(VideoState *is)\n{\n    if (is->paused) {\n        return is->video_current_pts;\n    } else {\n        return is->video_current_pts_drift + av_gettime() / 1000000.0;\n    }\n}"}, {"function body": "static double get_external_clock(VideoState *is)\n{\n    int64_t ti;\n    ti = av_gettime();\n    return is->external_clock + ((ti - is->external_clock_time) * 1e-6);\n}"}, {"function body": "static double get_master_clock(VideoState *is)\n{\n    double val;\n\n    if (is->av_sync_type == AV_SYNC_VIDEO_MASTER) {\n        if (is->video_st)\n            val = get_video_clock(is);\n        else\n            val = get_audio_clock(is);\n    } else if (is->av_sync_type == AV_SYNC_AUDIO_MASTER) {\n        if (is->audio_st)\n            val = get_audio_clock(is);\n        else\n            val = get_video_clock(is);\n    } else {\n        val = get_external_clock(is);\n    }\n    return val;\n}"}, {"function body": "static void stream_seek(VideoState *is, int64_t pos, int64_t rel, int seek_by_bytes)\n{\n    if (!is->seek_req) {\n        is->seek_pos = pos;\n        is->seek_rel = rel;\n        is->seek_flags &= ~AVSEEK_FLAG_BYTE;\n        if (seek_by_bytes)\n            is->seek_flags |= AVSEEK_FLAG_BYTE;\n        is->seek_req = 1;\n    }\n}"}, {"function body": "static void stream_toggle_pause(VideoState *is)\n{\n    if (is->paused) {\n        is->frame_timer += av_gettime() / 1000000.0 + is->video_current_pts_drift - is->video_current_pts;\n        if (is->read_pause_return != AVERROR(ENOSYS)) {\n            is->video_current_pts = is->video_current_pts_drift + av_gettime() / 1000000.0;\n        }\n        is->video_current_pts_drift = is->video_current_pts - av_gettime() / 1000000.0;\n    }\n    is->paused = !is->paused;\n}"}, {"function body": "static double compute_target_delay(double delay, VideoState *is)\n{\n    double sync_threshold, diff;\n\n    /* update delay to follow master synchronisation source */\n    if (((is->av_sync_type == AV_SYNC_AUDIO_MASTER && is->audio_st) ||\n         is->av_sync_type == AV_SYNC_EXTERNAL_CLOCK)) {\n        /* if video is slave, we try to correct big delays by\n           duplicating or deleting a frame */\n        diff = get_video_clock(is) - get_master_clock(is);\n\n        /* skip or repeat frame. We take into account the\n           delay to compute the threshold. I still don't know\n           if it is the best guess */\n        sync_threshold = FFMAX(AV_SYNC_THRESHOLD, delay);\n        if (fabs(diff) < AV_NOSYNC_THRESHOLD) {\n            if (diff <= -sync_threshold)\n                delay = 0;\n            else if (diff >= sync_threshold)\n                delay = 2 * delay;\n        }\n    }\n\n    av_dlog(NULL, \"video: delay=%0.3f A-V=%f\\n\",\n            delay, -diff);\n\n    return delay;\n}"}, {"function body": "static void pictq_next_picture(VideoState *is) {\n    /* update queue size and signal for next picture */\n    if (++is->pictq_rindex == VIDEO_PICTURE_QUEUE_SIZE)\n        is->pictq_rindex = 0;\n\n    SDL_LockMutex(is->pictq_mutex);\n    is->pictq_size--;\n    SDL_CondSignal(is->pictq_cond);\n    SDL_UnlockMutex(is->pictq_mutex);\n}"}, {"function body": "static void pictq_prev_picture(VideoState *is) {\n    VideoPicture *prevvp;\n    /* update queue size and signal for the previous picture */\n    prevvp = &is->pictq[(is->pictq_rindex + VIDEO_PICTURE_QUEUE_SIZE - 1) % VIDEO_PICTURE_QUEUE_SIZE];\n    if (prevvp->allocated && !prevvp->skip) {\n        SDL_LockMutex(is->pictq_mutex);\n        if (is->pictq_size < VIDEO_PICTURE_QUEUE_SIZE - 1) {\n            if (--is->pictq_rindex == -1)\n                is->pictq_rindex = VIDEO_PICTURE_QUEUE_SIZE - 1;\n            is->pictq_size++;\n        }\n        SDL_CondSignal(is->pictq_cond);\n        SDL_UnlockMutex(is->pictq_mutex);\n    }\n}"}, {"function body": "static void update_video_pts(VideoState *is, double pts, int64_t pos) {\n    double time = av_gettime() / 1000000.0;\n    /* update current video pts */\n    is->video_current_pts = pts;\n    is->video_current_pts_drift = is->video_current_pts - time;\n    is->video_current_pos = pos;\n    is->frame_last_pts = pts;\n}"}, {"function body": "static void video_refresh(void *opaque)\n{\n    VideoState *is = opaque;\n    VideoPicture *vp;\n    double time;\n\n    SubPicture *sp, *sp2;\n\n    if (is->video_st) {\n        if (is->force_refresh)\n            pictq_prev_picture(is);\nretry:\n        if (is->pictq_size == 0) {\n            SDL_LockMutex(is->pictq_mutex);\n            if (is->frame_last_dropped_pts != AV_NOPTS_VALUE && is->frame_last_dropped_pts > is->frame_last_pts) {\n                update_video_pts(is, is->frame_last_dropped_pts, is->frame_last_dropped_pos);\n                is->frame_last_dropped_pts = AV_NOPTS_VALUE;\n            }\n            SDL_UnlockMutex(is->pictq_mutex);\n            // nothing to do, no picture to display in the que\n        } else {\n            double last_duration, duration, delay;\n            /* dequeue the picture */\n            vp = &is->pictq[is->pictq_rindex];\n\n            if (vp->skip) {\n                pictq_next_picture(is);\n                goto retry;\n            }\n\n            if (is->paused)\n                goto display;\n\n            /* compute nominal last_duration */\n            last_duration = vp->pts - is->frame_last_pts;\n            if (last_duration > 0 && last_duration < 10.0) {\n                /* if duration of the last frame was sane, update last_duration in video state */\n                is->frame_last_duration = last_duration;\n            }\n            delay = compute_target_delay(is->frame_last_duration, is);\n\n            time= av_gettime()/1000000.0;\n            if (time < is->frame_timer + delay)\n                return;\n\n            if (delay > 0)\n                is->frame_timer += delay * FFMAX(1, floor((time-is->frame_timer) / delay));\n\n            SDL_LockMutex(is->pictq_mutex);\n            update_video_pts(is, vp->pts, vp->pos);\n            SDL_UnlockMutex(is->pictq_mutex);\n\n            if (is->pictq_size > 1) {\n                VideoPicture *nextvp = &is->pictq[(is->pictq_rindex + 1) % VIDEO_PICTURE_QUEUE_SIZE];\n                duration = nextvp->pts - vp->pts;\n                if((framedrop>0 || (framedrop && is->audio_st)) && time > is->frame_timer + duration){\n                    is->frame_drops_late++;\n                    pictq_next_picture(is);\n                    goto retry;\n                }\n            }\n\n            if (is->subtitle_st) {\n                if (is->subtitle_stream_changed) {\n                    SDL_LockMutex(is->subpq_mutex);\n\n                    while (is->subpq_size) {\n                        free_subpicture(&is->subpq[is->subpq_rindex]);\n\n                        /* update queue size and signal for next picture */\n                        if (++is->subpq_rindex == SUBPICTURE_QUEUE_SIZE)\n                            is->subpq_rindex = 0;\n\n                        is->subpq_size--;\n                    }\n                    is->subtitle_stream_changed = 0;\n\n                    SDL_CondSignal(is->subpq_cond);\n                    SDL_UnlockMutex(is->subpq_mutex);\n                } else {\n                    if (is->subpq_size > 0) {\n                        sp = &is->subpq[is->subpq_rindex];\n\n                        if (is->subpq_size > 1)\n                            sp2 = &is->subpq[(is->subpq_rindex + 1) % SUBPICTURE_QUEUE_SIZE];\n                        else\n                            sp2 = NULL;\n\n                        if ((is->video_current_pts > (sp->pts + ((float) sp->sub.end_display_time / 1000)))\n                                || (sp2 && is->video_current_pts > (sp2->pts + ((float) sp2->sub.start_display_time / 1000))))\n                        {\n                            free_subpicture(sp);\n\n                            /* update queue size and signal for next picture */\n                            if (++is->subpq_rindex == SUBPICTURE_QUEUE_SIZE)\n                                is->subpq_rindex = 0;\n\n                            SDL_LockMutex(is->subpq_mutex);\n                            is->subpq_size--;\n                            SDL_CondSignal(is->subpq_cond);\n                            SDL_UnlockMutex(is->subpq_mutex);\n                        }\n                    }\n                }\n            }\n\ndisplay:\n            /* display picture */\n            if (!display_disable)\n                video_display(is);\n\n            pictq_next_picture(is);\n        }\n    } else if (is->audio_st) {\n        /* draw the next audio frame */\n\n        /* if only audio stream, then display the audio bars (better\n           than nothing, just to test the implementation */\n\n        /* display picture */\n        if (!display_disable)\n            video_display(is);\n    }\n    is->force_refresh = 0;\n    if (show_status) {\n        static int64_t last_time;\n        int64_t cur_time;\n        int aqsize, vqsize, sqsize;\n        double av_diff;\n\n        cur_time = av_gettime();\n        if (!last_time || (cur_time - last_time) >= 30000) {\n            aqsize = 0;\n            vqsize = 0;\n            sqsize = 0;\n            if (is->audio_st)\n                aqsize = is->audioq.size;\n            if (is->video_st)\n                vqsize = is->videoq.size;\n            if (is->subtitle_st)\n                sqsize = is->subtitleq.size;\n            av_diff = 0;\n            if (is->audio_st && is->video_st)\n                av_diff = get_audio_clock(is) - get_video_clock(is);\n            printf(\"%7.2f A-V:%7.3f fd=%4d aq=%5dKB vq=%5dKB sq=%5dB f=%\"PRId64\"/%\"PRId64\"   \\r\",\n                   get_master_clock(is),\n                   av_diff,\n                   is->frame_drops_early + is->frame_drops_late,\n                   aqsize / 1024,\n                   vqsize / 1024,\n                   sqsize,\n                   is->video_st ? is->video_st->codec->pts_correction_num_faulty_dts : 0,\n                   is->video_st ? is->video_st->codec->pts_correction_num_faulty_pts : 0);\n            fflush(stdout);\n            last_time = cur_time;\n        }\n    }\n}"}, {"function body": "a picture (needs to do that in main thread to avoid\n   potential locking problems */\nstatic void alloc_picture(VideoState *is)\n{\n    VideoPicture *vp;\n\n    vp = &is->pictq[is->pictq_windex];\n\n    if (vp->bmp)\n        SDL_FreeYUVOverlay(vp->bmp);\n\n#if CONFIG_AVFILTER\n    avfilter_unref_bufferp(&vp->picref);\n#endif\n\n    video_open(is, 0);\n\n    vp->bmp = SDL_CreateYUVOverlay(vp->width, vp->height,\n                                   SDL_YV12_OVERLAY,\n                                   screen);\n    if (!vp->bmp || vp->bmp->pitches[0] < vp->width) {\n        /* SDL allocates a buffer smaller than requested if the video\n         * overlay hardware is unable to support the requested size. */\n        fprintf(stderr, \"Error: the video system does not support an image\\n\"\n                        \"size of %dx%d pixels. Try using -lowres or -vf \\\"scale=w:h\\\"\\n\"\n                        \"to reduce the image size.\\n\", vp->width, vp->height );\n        do_exit(is);\n    }\n\n    SDL_LockMutex(is->pictq_mutex);\n    vp->allocated = 1;\n    SDL_CondSignal(is->pictq_cond);\n    SDL_UnlockMutex(is->pictq_mutex);\n}"}, {"function body": "static int queue_picture(VideoState *is, AVFrame *src_frame, double pts1, int64_t pos)\n{\n    VideoPicture *vp;\n    double frame_delay, pts = pts1;\n\n    /* compute the exact PTS for the picture if it is omitted in the stream\n     * pts1 is the dts of the pkt / pts of the frame */\n    if (pts != 0) {\n        /* update video clock with pts, if present */\n        is->video_clock = pts;\n    } else {\n        pts = is->video_clock;\n    }\n    /* update video clock for next frame */\n    frame_delay = av_q2d(is->video_st->codec->time_base);\n    /* for MPEG2, the frame can be repeated, so we update the\n       clock accordingly */\n    frame_delay += src_frame->repeat_pict * (frame_delay * 0.5);\n    is->video_clock += frame_delay;\n\n#if defined(DEBUG_SYNC) && 0\n    printf(\"frame_type=%c clock=%0.3f pts=%0.3f\\n\",\n           av_get_picture_type_char(src_frame->pict_type), pts, pts1);\n#endif\n\n    /* wait until we have space to put a new picture */\n    SDL_LockMutex(is->pictq_mutex);\n\n    /* keep the last already displayed picture in the queue */\n    while (is->pictq_size >= VIDEO_PICTURE_QUEUE_SIZE - 2 &&\n           !is->videoq.abort_request) {\n        SDL_CondWait(is->pictq_cond, is->pictq_mutex);\n    }\n    SDL_UnlockMutex(is->pictq_mutex);\n\n    if (is->videoq.abort_request)\n        return -1;\n\n    vp = &is->pictq[is->pictq_windex];\n\n#if CONFIG_AVFILTER\n    vp->sample_aspect_ratio = ((AVFilterBufferRef *)src_frame->opaque)->video->sample_aspect_ratio;\n#else\n    vp->sample_aspect_ratio = av_guess_sample_aspect_ratio(is->ic, is->video_st, src_frame);\n#endif\n\n    /* alloc or resize hardware picture buffer */\n    if (!vp->bmp || vp->reallocate || !vp->allocated ||\n        vp->width  != src_frame->width ||\n        vp->height != src_frame->height) {\n        SDL_Event event;\n\n        vp->allocated  = 0;\n        vp->reallocate = 0;\n        vp->width = src_frame->width;\n        vp->height = src_frame->height;\n\n        /* the allocation must be done in the main thread to avoid\n           locking problems. */\n        event.type = FF_ALLOC_EVENT;\n        event.user.data1 = is;\n        SDL_PushEvent(&event);\n\n        /* wait until the picture is allocated */\n        SDL_LockMutex(is->pictq_mutex);\n        while (!vp->allocated && !is->videoq.abort_request) {\n            SDL_CondWait(is->pictq_cond, is->pictq_mutex);\n        }\n        /* if the queue is aborted, we have to pop the pending ALLOC event or wait for the allocation to complete */\n        if (is->videoq.abort_request && SDL_PeepEvents(&event, 1, SDL_GETEVENT, SDL_EVENTMASK(FF_ALLOC_EVENT)) != 1) {\n            while (!vp->allocated) {\n                SDL_CondWait(is->pictq_cond, is->pictq_mutex);\n            }\n        }\n        SDL_UnlockMutex(is->pictq_mutex);\n\n        if (is->videoq.abort_request)\n            return -1;\n    }\n\n    /* if the frame is not skipped, then display it */\n    if (vp->bmp) {\n        AVPicture pict = { { 0 } };\n#if CONFIG_AVFILTER\n        avfilter_unref_bufferp(&vp->picref);\n        vp->picref = src_frame->opaque;\n#endif\n\n        /* get a pointer on the bitmap */\n        SDL_LockYUVOverlay (vp->bmp);\n\n        pict.data[0] = vp->bmp->pixels[0];\n        pict.data[1] = vp->bmp->pixels[2];\n        pict.data[2] = vp->bmp->pixels[1];\n\n        pict.linesize[0] = vp->bmp->pitches[0];\n        pict.linesize[1] = vp->bmp->pitches[2];\n        pict.linesize[2] = vp->bmp->pitches[1];\n\n#if CONFIG_AVFILTER\n        // FIXME use direct rendering\n        av_picture_copy(&pict, (AVPicture *)src_frame,\n                        src_frame->format, vp->width, vp->height);\n#else\n        sws_flags = av_get_int(sws_opts, \"sws_flags\", NULL);\n        is->img_convert_ctx = sws_getCachedContext(is->img_convert_ctx,\n            vp->width, vp->height, src_frame->format, vp->width, vp->height,\n            PIX_FMT_YUV420P, sws_flags, NULL, NULL, NULL);\n        if (is->img_convert_ctx == NULL) {\n            fprintf(stderr, \"Cannot initialize the conversion context\\n\");\n            exit(1);\n        }\n        sws_scale(is->img_convert_ctx, src_frame->data, src_frame->linesize,\n                  0, vp->height, pict.data, pict.linesize);\n#endif\n        /* update the bitmap content */\n        SDL_UnlockYUVOverlay(vp->bmp);\n\n        vp->pts = pts;\n        vp->pos = pos;\n        vp->skip = 0;\n\n        /* now we can update the picture count */\n        if (++is->pictq_windex == VIDEO_PICTURE_QUEUE_SIZE)\n            is->pictq_windex = 0;\n        SDL_LockMutex(is->pictq_mutex);\n        is->pictq_size++;\n        SDL_UnlockMutex(is->pictq_mutex);\n    }\n    return 0;\n}"}, {"function body": "static int get_video_frame(VideoState *is, AVFrame *frame, int64_t *pts, AVPacket *pkt)\n{\n    int got_picture, i;\n\n    if (packet_queue_get(&is->videoq, pkt, 1) < 0)\n        return -1;\n\n    if (pkt->data == flush_pkt.data) {\n        avcodec_flush_buffers(is->video_st->codec);\n\n        SDL_LockMutex(is->pictq_mutex);\n        // Make sure there are no long delay timers (ideally we should just flush the que but thats harder)\n        for (i = 0; i < VIDEO_PICTURE_QUEUE_SIZE; i++) {\n            is->pictq[i].skip = 1;\n        }\n        while (is->pictq_size && !is->videoq.abort_request) {\n            SDL_CondWait(is->pictq_cond, is->pictq_mutex);\n        }\n        is->video_current_pos = -1;\n        is->frame_last_pts = AV_NOPTS_VALUE;\n        is->frame_last_duration = 0;\n        is->frame_timer = (double)av_gettime() / 1000000.0;\n        is->frame_last_dropped_pts = AV_NOPTS_VALUE;\n        SDL_UnlockMutex(is->pictq_mutex);\n\n        return 0;\n    }\n\n    if(avcodec_decode_video2(is->video_st->codec, frame, &got_picture, pkt) < 0)\n        return 0;\n\n    if (got_picture) {\n        int ret = 1;\n\n        if (decoder_reorder_pts == -1) {\n            *pts = av_frame_get_best_effort_timestamp(frame);\n        } else if (decoder_reorder_pts) {\n            *pts = frame->pkt_pts;\n        } else {\n            *pts = frame->pkt_dts;\n        }\n\n        if (*pts == AV_NOPTS_VALUE) {\n            *pts = 0;\n        }\n\n        if (((is->av_sync_type == AV_SYNC_AUDIO_MASTER && is->audio_st) || is->av_sync_type == AV_SYNC_EXTERNAL_CLOCK) &&\n             (framedrop>0 || (framedrop && is->audio_st))) {\n            SDL_LockMutex(is->pictq_mutex);\n            if (is->frame_last_pts != AV_NOPTS_VALUE && *pts) {\n                double clockdiff = get_video_clock(is) - get_master_clock(is);\n                double dpts = av_q2d(is->video_st->time_base) * *pts;\n                double ptsdiff = dpts - is->frame_last_pts;\n                if (fabs(clockdiff) < AV_NOSYNC_THRESHOLD &&\n                     ptsdiff > 0 && ptsdiff < AV_NOSYNC_THRESHOLD &&\n                     clockdiff + ptsdiff - is->frame_last_filter_delay < 0) {\n                    is->frame_last_dropped_pos = pkt->pos;\n                    is->frame_last_dropped_pts = dpts;\n                    is->frame_drops_early++;\n                    ret = 0;\n                }\n            }\n            SDL_UnlockMutex(is->pictq_mutex);\n        }\n\n        return ret;\n    }\n    return 0;\n}"}, {"function body": "static int configure_filtergraph(AVFilterGraph *graph, const char *filtergraph,\n                                 AVFilterContext *source_ctx, AVFilterContext *sink_ctx)\n{\n    int ret;\n    AVFilterInOut *outputs = NULL, *inputs = NULL;\n\n    if (filtergraph) {\n        outputs = avfilter_inout_alloc();\n        inputs  = avfilter_inout_alloc();\n        if (!outputs || !inputs) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n\n        outputs->name       = av_strdup(\"in\");\n        outputs->filter_ctx = source_ctx;\n        outputs->pad_idx    = 0;\n        outputs->next       = NULL;\n\n        inputs->name        = av_strdup(\"out\");\n        inputs->filter_ctx  = sink_ctx;\n        inputs->pad_idx     = 0;\n        inputs->next        = NULL;\n\n        if ((ret = avfilter_graph_parse(graph, filtergraph, &inputs, &outputs, NULL)) < 0)\n            goto fail;\n    } else {\n        if ((ret = avfilter_link(source_ctx, 0, sink_ctx, 0)) < 0)\n            goto fail;\n    }\n\n    return avfilter_graph_config(graph, NULL);\nfail:\n    avfilter_inout_free(&outputs);\n    avfilter_inout_free(&inputs);\n    return ret;\n}"}, {"function body": "static int configure_video_filters(AVFilterGraph *graph, VideoState *is, const char *vfilters)\n{\n    static const enum PixelFormat pix_fmts[] = { PIX_FMT_YUV420P, PIX_FMT_NONE };\n    char sws_flags_str[128];\n    char buffersrc_args[256];\n    int ret;\n    AVBufferSinkParams *buffersink_params = av_buffersink_params_alloc();\n    AVFilterContext *filt_src = NULL, *filt_out = NULL, *filt_format, *filt_crop;\n    AVCodecContext *codec = is->video_st->codec;\n\n    snprintf(sws_flags_str, sizeof(sws_flags_str), \"flags=%d\", sws_flags);\n    graph->scale_sws_opts = av_strdup(sws_flags_str);\n\n    snprintf(buffersrc_args, sizeof(buffersrc_args),\n             \"video_size=%dx%d:pix_fmt=%d:time_base=%d/%d:pixel_aspect=%d/%d\",\n             codec->width, codec->height, codec->pix_fmt,\n             is->video_st->time_base.num, is->video_st->time_base.den,\n             codec->sample_aspect_ratio.num, codec->sample_aspect_ratio.den);\n\n    if ((ret = avfilter_graph_create_filter(&filt_src,\n                                            avfilter_get_by_name(\"buffer\"),\n                                            \"ffplay_buffer\", buffersrc_args, NULL,\n                                            graph)) < 0)\n        return ret;\n\n    buffersink_params->pixel_fmts = pix_fmts;\n    ret = avfilter_graph_create_filter(&filt_out,\n                                       avfilter_get_by_name(\"ffbuffersink\"),\n                                       \"ffplay_buffersink\", NULL, buffersink_params, graph);\n    av_freep(&buffersink_params);\n    if (ret < 0)\n        return ret;\n\n    /* SDL YUV code is not handling odd width/height for some driver\n     * combinations, therefore we crop the picture to an even width/height. */\n    if ((ret = avfilter_graph_create_filter(&filt_crop,\n                                            avfilter_get_by_name(\"crop\"),\n                                            \"ffplay_crop\", \"floor(in_w/2)*2:floor(in_h/2)*2\", NULL, graph)) < 0)\n        return ret;\n    if ((ret = avfilter_graph_create_filter(&filt_format,\n                                            avfilter_get_by_name(\"format\"),\n                                            \"format\", \"yuv420p\", NULL, graph)) < 0)\n        return ret;\n    if ((ret = avfilter_link(filt_crop, 0, filt_format, 0)) < 0)\n        return ret;\n    if ((ret = avfilter_link(filt_format, 0, filt_out, 0)) < 0)\n        return ret;\n\n    if ((ret = configure_filtergraph(graph, vfilters, filt_src, filt_crop)) < 0)\n        return ret;\n\n    is->in_video_filter  = filt_src;\n    is->out_video_filter = filt_out;\n\n    return ret;\n}"}, {"function body": "static int video_thread(void *arg)\n{\n    AVPacket pkt = { 0 };\n    VideoState *is = arg;\n    AVFrame *frame = avcodec_alloc_frame();\n    int64_t pts_int = AV_NOPTS_VALUE, pos = -1;\n    double pts;\n    int ret;\n\n#if CONFIG_AVFILTER\n    AVCodecContext *codec = is->video_st->codec;\n    AVFilterGraph *graph = avfilter_graph_alloc();\n    AVFilterContext *filt_out = NULL, *filt_in = NULL;\n    int last_w = 0;\n    int last_h = 0;\n    enum PixelFormat last_format = -2;\n\n    if (codec->codec->capabilities & CODEC_CAP_DR1) {\n        is->use_dr1 = 1;\n        codec->get_buffer     = codec_get_buffer;\n        codec->release_buffer = codec_release_buffer;\n        codec->opaque         = &is->buffer_pool;\n    }\n#endif\n\n    for (;;) {\n#if CONFIG_AVFILTER\n        AVFilterBufferRef *picref;\n        AVRational tb;\n#endif\n        while (is->paused && !is->videoq.abort_request)\n            SDL_Delay(10);\n\n        avcodec_get_frame_defaults(frame);\n        av_free_packet(&pkt);\n\n        ret = get_video_frame(is, frame, &pts_int, &pkt);\n        if (ret < 0)\n            goto the_end;\n\n        if (!ret)\n            continue;\n\n#if CONFIG_AVFILTER\n        if (   last_w != is->video_st->codec->width\n            || last_h != is->video_st->codec->height\n            || last_format != is->video_st->codec->pix_fmt) {\n            av_log(NULL, AV_LOG_INFO, \"Frame changed from size:%dx%d to size:%dx%d\\n\",\n                   last_w, last_h, is->video_st->codec->width, is->video_st->codec->height);\n            avfilter_graph_free(&graph);\n            graph = avfilter_graph_alloc();\n            if ((ret = configure_video_filters(graph, is, vfilters)) < 0) {\n                SDL_Event event;\n                event.type = FF_QUIT_EVENT;\n                event.user.data1 = is;\n                SDL_PushEvent(&event);\n                av_free_packet(&pkt);\n                goto the_end;\n            }\n            filt_in  = is->in_video_filter;\n            filt_out = is->out_video_filter;\n            last_w = is->video_st->codec->width;\n            last_h = is->video_st->codec->height;\n            last_format = is->video_st->codec->pix_fmt;\n        }\n\n        frame->pts = pts_int;\n        frame->sample_aspect_ratio = av_guess_sample_aspect_ratio(is->ic, is->video_st, frame);\n        if (is->use_dr1 && frame->opaque) {\n            FrameBuffer      *buf = frame->opaque;\n            AVFilterBufferRef *fb = avfilter_get_video_buffer_ref_from_arrays(\n                                        frame->data, frame->linesize,\n                                        AV_PERM_READ | AV_PERM_PRESERVE,\n                                        frame->width, frame->height,\n                                        frame->format);\n\n            avfilter_copy_frame_props(fb, frame);\n            fb->buf->priv           = buf;\n            fb->buf->free           = filter_release_buffer;\n\n            buf->refcount++;\n            av_buffersrc_add_ref(filt_in, fb, AV_BUFFERSRC_FLAG_NO_COPY);\n\n        } else\n            av_buffersrc_write_frame(filt_in, frame);\n\n        av_free_packet(&pkt);\n\n        while (ret >= 0) {\n            is->frame_last_returned_time = av_gettime() / 1000000.0;\n\n            ret = av_buffersink_get_buffer_ref(filt_out, &picref, 0);\n            if (ret < 0) {\n                ret = 0;\n                break;\n            }\n\n            is->frame_last_filter_delay = av_gettime() / 1000000.0 - is->frame_last_returned_time;\n            if (fabs(is->frame_last_filter_delay) > AV_NOSYNC_THRESHOLD / 10.0)\n                is->frame_last_filter_delay = 0;\n\n            avfilter_copy_buf_props(frame, picref);\n\n            pts_int = picref->pts;\n            tb      = filt_out->inputs[0]->time_base;\n            pos     = picref->pos;\n            frame->opaque = picref;\n\n            if (av_cmp_q(tb, is->video_st->time_base)) {\n                av_unused int64_t pts1 = pts_int;\n                pts_int = av_rescale_q(pts_int, tb, is->video_st->time_base);\n                av_dlog(NULL, \"video_thread(): \"\n                        \"tb:%d/%d pts:%\"PRId64\" -> tb:%d/%d pts:%\"PRId64\"\\n\",\n                        tb.num, tb.den, pts1,\n                        is->video_st->time_base.num, is->video_st->time_base.den, pts_int);\n            }\n            pts = pts_int * av_q2d(is->video_st->time_base);\n            ret = queue_picture(is, frame, pts, pos);\n        }\n#else\n        pts = pts_int * av_q2d(is->video_st->time_base);\n        ret = queue_picture(is, frame, pts, pkt.pos);\n#endif\n\n        if (ret < 0)\n            goto the_end;\n\n        if (is->step)\n            stream_toggle_pause(is);\n    }\n the_end:\n    avcodec_flush_buffers(is->video_st->codec);\n#if CONFIG_AVFILTER\n    avfilter_graph_free(&graph);\n#endif\n    av_free_packet(&pkt);\n    avcodec_free_frame(&frame);\n    return 0;\n}"}, {"function body": "static int subtitle_thread(void *arg)\n{\n    VideoState *is = arg;\n    SubPicture *sp;\n    AVPacket pkt1, *pkt = &pkt1;\n    int got_subtitle;\n    double pts;\n    int i, j;\n    int r, g, b, y, u, v, a;\n\n    for (;;) {\n        while (is->paused && !is->subtitleq.abort_request) {\n            SDL_Delay(10);\n        }\n        if (packet_queue_get(&is->subtitleq, pkt, 1) < 0)\n            break;\n\n        if (pkt->data == flush_pkt.data) {\n            avcodec_flush_buffers(is->subtitle_st->codec);\n            continue;\n        }\n        SDL_LockMutex(is->subpq_mutex);\n        while (is->subpq_size >= SUBPICTURE_QUEUE_SIZE &&\n               !is->subtitleq.abort_request) {\n            SDL_CondWait(is->subpq_cond, is->subpq_mutex);\n        }\n        SDL_UnlockMutex(is->subpq_mutex);\n\n        if (is->subtitleq.abort_request)\n            return 0;\n\n        sp = &is->subpq[is->subpq_windex];\n\n       /* NOTE: ipts is the PTS of the _first_ picture beginning in\n           this packet, if any */\n        pts = 0;\n        if (pkt->pts != AV_NOPTS_VALUE)\n            pts = av_q2d(is->subtitle_st->time_base) * pkt->pts;\n\n        avcodec_decode_subtitle2(is->subtitle_st->codec, &sp->sub,\n                                 &got_subtitle, pkt);\n        if (got_subtitle && sp->sub.format == 0) {\n            if (sp->sub.pts != AV_NOPTS_VALUE)\n                pts = sp->sub.pts / (double)AV_TIME_BASE;\n            sp->pts = pts;\n\n            for (i = 0; i < sp->sub.num_rects; i++)\n            {\n                for (j = 0; j < sp->sub.rects[i]->nb_colors; j++)\n                {\n                    RGBA_IN(r, g, b, a, (uint32_t*)sp->sub.rects[i]->pict.data[1] + j);\n                    y = RGB_TO_Y_CCIR(r, g, b);\n                    u = RGB_TO_U_CCIR(r, g, b, 0);\n                    v = RGB_TO_V_CCIR(r, g, b, 0);\n                    YUVA_OUT((uint32_t*)sp->sub.rects[i]->pict.data[1] + j, y, u, v, a);\n                }\n            }\n\n            /* now we can update the picture count */\n            if (++is->subpq_windex == SUBPICTURE_QUEUE_SIZE)\n                is->subpq_windex = 0;\n            SDL_LockMutex(is->subpq_mutex);\n            is->subpq_size++;\n            SDL_UnlockMutex(is->subpq_mutex);\n        }\n        av_free_packet(pkt);\n    }\n    return 0;\n}"}, {"function body": "static void update_sample_display(VideoState *is, short *samples, int samples_size)\n{\n    int size, len;\n\n    size = samples_size / sizeof(short);\n    while (size > 0) {\n        len = SAMPLE_ARRAY_SIZE - is->sample_array_index;\n        if (len > size)\n            len = size;\n        memcpy(is->sample_array + is->sample_array_index, samples, len * sizeof(short));\n        samples += len;\n        is->sample_array_index += len;\n        if (is->sample_array_index >= SAMPLE_ARRAY_SIZE)\n            is->sample_array_index = 0;\n        size -= len;\n    }\n}"}, {"function body": "static int synchronize_audio(VideoState *is, int nb_samples)\n{\n    int wanted_nb_samples = nb_samples;\n\n    /* if not master, then we try to remove or add samples to correct the clock */\n    if (((is->av_sync_type == AV_SYNC_VIDEO_MASTER && is->video_st) ||\n         is->av_sync_type == AV_SYNC_EXTERNAL_CLOCK)) {\n        double diff, avg_diff;\n        int min_nb_samples, max_nb_samples;\n\n        diff = get_audio_clock(is) - get_master_clock(is);\n\n        if (diff < AV_NOSYNC_THRESHOLD) {\n            is->audio_diff_cum = diff + is->audio_diff_avg_coef * is->audio_diff_cum;\n            if (is->audio_diff_avg_count < AUDIO_DIFF_AVG_NB) {\n                /* not enough measures to have a correct estimate */\n                is->audio_diff_avg_count++;\n            } else {\n                /* estimate the A-V difference */\n                avg_diff = is->audio_diff_cum * (1.0 - is->audio_diff_avg_coef);\n\n                if (fabs(avg_diff) >= is->audio_diff_threshold) {\n                    wanted_nb_samples = nb_samples + (int)(diff * is->audio_src.freq);\n                    min_nb_samples = ((nb_samples * (100 - SAMPLE_CORRECTION_PERCENT_MAX) / 100));\n                    max_nb_samples = ((nb_samples * (100 + SAMPLE_CORRECTION_PERCENT_MAX) / 100));\n                    wanted_nb_samples = FFMIN(FFMAX(wanted_nb_samples, min_nb_samples), max_nb_samples);\n                }\n                av_dlog(NULL, \"diff=%f adiff=%f sample_diff=%d apts=%0.3f vpts=%0.3f %f\\n\",\n                        diff, avg_diff, wanted_nb_samples - nb_samples,\n                        is->audio_clock, is->video_clock, is->audio_diff_threshold);\n            }\n        } else {\n            /* too big difference : may be initial PTS errors, so\n               reset A-V filter */\n            is->audio_diff_avg_count = 0;\n            is->audio_diff_cum       = 0;\n        }\n    }\n\n    return wanted_nb_samples;\n}"}, {"function body": "static int audio_decode_frame(VideoState *is, double *pts_ptr)\n{\n    AVPacket *pkt_temp = &is->audio_pkt_temp;\n    AVPacket *pkt = &is->audio_pkt;\n    AVCodecContext *dec = is->audio_st->codec;\n    int len1, len2, data_size, resampled_data_size;\n    int64_t dec_channel_layout;\n    int got_frame;\n    double pts;\n    int new_packet = 0;\n    int flush_complete = 0;\n    int wanted_nb_samples;\n\n    for (;;) {\n        /* NOTE: the audio packet can contain several frames */\n        while (pkt_temp->size > 0 || (!pkt_temp->data && new_packet)) {\n            if (!is->frame) {\n                if (!(is->frame = avcodec_alloc_frame()))\n                    return AVERROR(ENOMEM);\n            } else\n                avcodec_get_frame_defaults(is->frame);\n\n            if (is->paused)\n                return -1;\n\n            if (flush_complete)\n                break;\n            new_packet = 0;\n            len1 = avcodec_decode_audio4(dec, is->frame, &got_frame, pkt_temp);\n            if (len1 < 0) {\n                /* if error, we skip the frame */\n                pkt_temp->size = 0;\n                break;\n            }\n\n            pkt_temp->data += len1;\n            pkt_temp->size -= len1;\n\n            if (!got_frame) {\n                /* stop sending empty packets if the decoder is finished */\n                if (!pkt_temp->data && dec->codec->capabilities & CODEC_CAP_DELAY)\n                    flush_complete = 1;\n                continue;\n            }\n            data_size = av_samples_get_buffer_size(NULL, dec->channels,\n                                                   is->frame->nb_samples,\n                                                   dec->sample_fmt, 1);\n\n            dec_channel_layout =\n                (dec->channel_layout && dec->channels == av_get_channel_layout_nb_channels(dec->channel_layout)) ?\n                dec->channel_layout : av_get_default_channel_layout(dec->channels);\n            wanted_nb_samples = synchronize_audio(is, is->frame->nb_samples);\n\n            if (dec->sample_fmt    != is->audio_src.fmt            ||\n                dec_channel_layout != is->audio_src.channel_layout ||\n                dec->sample_rate   != is->audio_src.freq           ||\n                (wanted_nb_samples != is->frame->nb_samples && !is->swr_ctx)) {\n                swr_free(&is->swr_ctx);\n                is->swr_ctx = swr_alloc_set_opts(NULL,\n                                                 is->audio_tgt.channel_layout, is->audio_tgt.fmt, is->audio_tgt.freq,\n                                                 dec_channel_layout,           dec->sample_fmt,   dec->sample_rate,\n                                                 0, NULL);\n                if (!is->swr_ctx || swr_init(is->swr_ctx) < 0) {\n                    fprintf(stderr, \"Cannot create sample rate converter for conversion of %d Hz %s %d channels to %d Hz %s %d channels!\\n\",\n                        dec->sample_rate,   av_get_sample_fmt_name(dec->sample_fmt),   dec->channels,\n                        is->audio_tgt.freq, av_get_sample_fmt_name(is->audio_tgt.fmt), is->audio_tgt.channels);\n                    break;\n                }\n                is->audio_src.channel_layout = dec_channel_layout;\n                is->audio_src.channels = dec->channels;\n                is->audio_src.freq = dec->sample_rate;\n                is->audio_src.fmt = dec->sample_fmt;\n            }\n\n            if (is->swr_ctx) {\n                const uint8_t **in = (const uint8_t **)is->frame->extended_data;\n                uint8_t *out[] = {is->audio_buf2};\n                int out_count = sizeof(is->audio_buf2) / is->audio_tgt.channels / av_get_bytes_per_sample(is->audio_tgt.fmt);\n                if (wanted_nb_samples != is->frame->nb_samples) {\n                    if (swr_set_compensation(is->swr_ctx, (wanted_nb_samples - is->frame->nb_samples) * is->audio_tgt.freq / dec->sample_rate,\n                                                wanted_nb_samples * is->audio_tgt.freq / dec->sample_rate) < 0) {\n                        fprintf(stderr, \"swr_set_compensation() failed\\n\");\n                        break;\n                    }\n                }\n                len2 = swr_convert(is->swr_ctx, out, out_count, in, is->frame->nb_samples);\n                if (len2 < 0) {\n                    fprintf(stderr, \"swr_convert() failed\\n\");\n                    break;\n                }\n                if (len2 == out_count) {\n                    fprintf(stderr, \"warning: audio buffer is probably too small\\n\");\n                    swr_init(is->swr_ctx);\n                }\n                is->audio_buf = is->audio_buf2;\n                resampled_data_size = len2 * is->audio_tgt.channels * av_get_bytes_per_sample(is->audio_tgt.fmt);\n            } else {\n                is->audio_buf = is->frame->data[0];\n                resampled_data_size = data_size;\n            }\n\n            /* if no pts, then compute it */\n            pts = is->audio_clock;\n            *pts_ptr = pts;\n            is->audio_clock += (double)data_size /\n                (dec->channels * dec->sample_rate * av_get_bytes_per_sample(dec->sample_fmt));\n#ifdef DEBUG\n            {\n                static double last_clock;\n                printf(\"audio: delay=%0.3f clock=%0.3f pts=%0.3f\\n\",\n                       is->audio_clock - last_clock,\n                       is->audio_clock, pts);\n                last_clock = is->audio_clock;\n            }\n#endif\n            return resampled_data_size;\n        }\n\n        /* free the current packet */\n        if (pkt->data)\n            av_free_packet(pkt);\n        memset(pkt_temp, 0, sizeof(*pkt_temp));\n\n        if (is->paused || is->audioq.abort_request) {\n            return -1;\n        }\n\n        if (is->audioq.nb_packets == 0)\n            SDL_CondSignal(is->continue_read_thread);\n\n        /* read next packet */\n        if ((new_packet = packet_queue_get(&is->audioq, pkt, 1)) < 0)\n            return -1;\n\n        if (pkt->data == flush_pkt.data) {\n            avcodec_flush_buffers(dec);\n            flush_complete = 0;\n        }\n\n        *pkt_temp = *pkt;\n\n        /* if update the audio clock with the pts */\n        if (pkt->pts != AV_NOPTS_VALUE) {\n            is->audio_clock = av_q2d(is->audio_st->time_base)*pkt->pts;\n        }\n    }\n}"}, {"function body": "static void sdl_audio_callback(void *opaque, Uint8 *stream, int len)\n{\n    VideoState *is = opaque;\n    int audio_size, len1;\n    int bytes_per_sec;\n    int frame_size = av_samples_get_buffer_size(NULL, is->audio_tgt.channels, 1, is->audio_tgt.fmt, 1);\n    double pts;\n\n    audio_callback_time = av_gettime();\n\n    while (len > 0) {\n        if (is->audio_buf_index >= is->audio_buf_size) {\n           audio_size = audio_decode_frame(is, &pts);\n           if (audio_size < 0) {\n                /* if error, just output silence */\n               is->audio_buf      = is->silence_buf;\n               is->audio_buf_size = sizeof(is->silence_buf) / frame_size * frame_size;\n           } else {\n               if (is->show_mode != SHOW_MODE_VIDEO)\n                   update_sample_display(is, (int16_t *)is->audio_buf, audio_size);\n               is->audio_buf_size = audio_size;\n           }\n           is->audio_buf_index = 0;\n        }\n        len1 = is->audio_buf_size - is->audio_buf_index;\n        if (len1 > len)\n            len1 = len;\n        memcpy(stream, (uint8_t *)is->audio_buf + is->audio_buf_index, len1);\n        len -= len1;\n        stream += len1;\n        is->audio_buf_index += len1;\n    }\n    bytes_per_sec = is->audio_tgt.freq * is->audio_tgt.channels * av_get_bytes_per_sample(is->audio_tgt.fmt);\n    is->audio_write_buf_size = is->audio_buf_size - is->audio_buf_index;\n    /* Let's assume the audio driver that is used by SDL has two periods. */\n    is->audio_current_pts = is->audio_clock - (double)(2 * is->audio_hw_buf_size + is->audio_write_buf_size) / bytes_per_sec;\n    is->audio_current_pts_drift = is->audio_current_pts - audio_callback_time / 1000000.0;\n}"}, {"function body": "static int audio_open(void *opaque, int64_t wanted_channel_layout, int wanted_nb_channels, int wanted_sample_rate, struct AudioParams *audio_hw_params)\n{\n    SDL_AudioSpec wanted_spec, spec;\n    const char *env;\n    const int next_nb_channels[] = {0, 0, 1, 6, 2, 6, 4, 6};\n\n    env = SDL_getenv(\"SDL_AUDIO_CHANNELS\");\n    if (env) {\n        wanted_nb_channels = atoi(env);\n        wanted_channel_layout = av_get_default_channel_layout(wanted_nb_channels);\n    }\n    if (!wanted_channel_layout || wanted_nb_channels != av_get_channel_layout_nb_channels(wanted_channel_layout)) {\n        wanted_channel_layout = av_get_default_channel_layout(wanted_nb_channels);\n        wanted_channel_layout &= ~AV_CH_LAYOUT_STEREO_DOWNMIX;\n    }\n    wanted_spec.channels = av_get_channel_layout_nb_channels(wanted_channel_layout);\n    wanted_spec.freq = wanted_sample_rate;\n    if (wanted_spec.freq <= 0 || wanted_spec.channels <= 0) {\n        fprintf(stderr, \"Invalid sample rate or channel count!\\n\");\n        return -1;\n    }\n    wanted_spec.format = AUDIO_S16SYS;\n    wanted_spec.silence = 0;\n    wanted_spec.samples = SDL_AUDIO_BUFFER_SIZE;\n    wanted_spec.callback = sdl_audio_callback;\n    wanted_spec.userdata = opaque;\n    while (SDL_OpenAudio(&wanted_spec, &spec) < 0) {\n        fprintf(stderr, \"SDL_OpenAudio (%d channels): %s\\n\", wanted_spec.channels, SDL_GetError());\n        wanted_spec.channels = next_nb_channels[FFMIN(7, wanted_spec.channels)];\n        if (!wanted_spec.channels) {\n            fprintf(stderr, \"No more channel combinations to try, audio open failed\\n\");\n            return -1;\n        }\n        wanted_channel_layout = av_get_default_channel_layout(wanted_spec.channels);\n    }\n    if (spec.format != AUDIO_S16SYS) {\n        fprintf(stderr, \"SDL advised audio format %d is not supported!\\n\", spec.format);\n        return -1;\n    }\n    if (spec.channels != wanted_spec.channels) {\n        wanted_channel_layout = av_get_default_channel_layout(spec.channels);\n        if (!wanted_channel_layout) {\n            fprintf(stderr, \"SDL advised channel count %d is not supported!\\n\", spec.channels);\n            return -1;\n        }\n    }\n\n    audio_hw_params->fmt = AV_SAMPLE_FMT_S16;\n    audio_hw_params->freq = spec.freq;\n    audio_hw_params->channel_layout = wanted_channel_layout;\n    audio_hw_params->channels =  spec.channels;\n    return spec.size;\n}"}, {"function body": "static int stream_component_open(VideoState *is, int stream_index)\n{\n    AVFormatContext *ic = is->ic;\n    AVCodecContext *avctx;\n    AVCodec *codec;\n    AVDictionary *opts;\n    AVDictionaryEntry *t = NULL;\n\n    if (stream_index < 0 || stream_index >= ic->nb_streams)\n        return -1;\n    avctx = ic->streams[stream_index]->codec;\n\n    codec = avcodec_find_decoder(avctx->codec_id);\n    opts = filter_codec_opts(codec_opts, avctx->codec_id, ic, ic->streams[stream_index], codec);\n\n    switch(avctx->codec_type){\n        case AVMEDIA_TYPE_AUDIO   : is->last_audio_stream    = stream_index; if(audio_codec_name   ) codec= avcodec_find_decoder_by_name(   audio_codec_name); break;\n        case AVMEDIA_TYPE_SUBTITLE: is->last_subtitle_stream = stream_index; if(subtitle_codec_name) codec= avcodec_find_decoder_by_name(subtitle_codec_name); break;\n        case AVMEDIA_TYPE_VIDEO   : is->last_video_stream    = stream_index; if(video_codec_name   ) codec= avcodec_find_decoder_by_name(   video_codec_name); break;\n    }\n    if (!codec)\n        return -1;\n\n    avctx->workaround_bugs   = workaround_bugs;\n    avctx->lowres            = lowres;\n    if(avctx->lowres > codec->max_lowres){\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n                codec->max_lowres);\n        avctx->lowres= codec->max_lowres;\n    }\n    avctx->idct_algo         = idct;\n    avctx->skip_frame        = skip_frame;\n    avctx->skip_idct         = skip_idct;\n    avctx->skip_loop_filter  = skip_loop_filter;\n    avctx->error_concealment = error_concealment;\n\n    if(avctx->lowres) avctx->flags |= CODEC_FLAG_EMU_EDGE;\n    if (fast)   avctx->flags2 |= CODEC_FLAG2_FAST;\n    if(codec->capabilities & CODEC_CAP_DR1)\n        avctx->flags |= CODEC_FLAG_EMU_EDGE;\n\n    if (!av_dict_get(opts, \"threads\", NULL, 0))\n        av_dict_set(&opts, \"threads\", \"auto\", 0);\n    if (!codec ||\n        avcodec_open2(avctx, codec, &opts) < 0)\n        return -1;\n    if ((t = av_dict_get(opts, \"\", NULL, AV_DICT_IGNORE_SUFFIX))) {\n        av_log(NULL, AV_LOG_ERROR, \"Option %s not found.\\n\", t->key);\n        return AVERROR_OPTION_NOT_FOUND;\n    }\n\n    /* prepare audio output */\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO) {\n        int audio_hw_buf_size = audio_open(is, avctx->channel_layout, avctx->channels, avctx->sample_rate, &is->audio_src);\n        if (audio_hw_buf_size < 0)\n            return -1;\n        is->audio_hw_buf_size = audio_hw_buf_size;\n        is->audio_tgt = is->audio_src;\n    }\n\n    ic->streams[stream_index]->discard = AVDISCARD_DEFAULT;\n    switch (avctx->codec_type) {\n    case AVMEDIA_TYPE_AUDIO:\n        is->audio_stream = stream_index;\n        is->audio_st = ic->streams[stream_index];\n        is->audio_buf_size  = 0;\n        is->audio_buf_index = 0;\n\n        /* init averaging filter */\n        is->audio_diff_avg_coef  = exp(log(0.01) / AUDIO_DIFF_AVG_NB);\n        is->audio_diff_avg_count = 0;\n        /* since we do not have a precise anough audio fifo fullness,\n           we correct audio sync only if larger than this threshold */\n        is->audio_diff_threshold = 2.0 * is->audio_hw_buf_size / av_samples_get_buffer_size(NULL, is->audio_tgt.channels, is->audio_tgt.freq, is->audio_tgt.fmt, 1);\n\n        memset(&is->audio_pkt, 0, sizeof(is->audio_pkt));\n        memset(&is->audio_pkt_temp, 0, sizeof(is->audio_pkt_temp));\n        packet_queue_start(&is->audioq);\n        SDL_PauseAudio(0);\n        break;\n    case AVMEDIA_TYPE_VIDEO:\n        is->video_stream = stream_index;\n        is->video_st = ic->streams[stream_index];\n\n        packet_queue_start(&is->videoq);\n        is->video_tid = SDL_CreateThread(video_thread, is);\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        is->subtitle_stream = stream_index;\n        is->subtitle_st = ic->streams[stream_index];\n        packet_queue_start(&is->subtitleq);\n\n        is->subtitle_tid = SDL_CreateThread(subtitle_thread, is);\n        break;\n    default:\n        break;\n    }\n    return 0;\n}"}, {"function body": "static void stream_component_close(VideoState *is, int stream_index)\n{\n    AVFormatContext *ic = is->ic;\n    AVCodecContext *avctx;\n\n    if (stream_index < 0 || stream_index >= ic->nb_streams)\n        return;\n    avctx = ic->streams[stream_index]->codec;\n\n    switch (avctx->codec_type) {\n    case AVMEDIA_TYPE_AUDIO:\n        packet_queue_abort(&is->audioq);\n\n        SDL_CloseAudio();\n\n        packet_queue_flush(&is->audioq);\n        av_free_packet(&is->audio_pkt);\n        swr_free(&is->swr_ctx);\n        av_freep(&is->audio_buf1);\n        is->audio_buf = NULL;\n        avcodec_free_frame(&is->frame);\n\n        if (is->rdft) {\n            av_rdft_end(is->rdft);\n            av_freep(&is->rdft_data);\n            is->rdft = NULL;\n            is->rdft_bits = 0;\n        }\n        break;\n    case AVMEDIA_TYPE_VIDEO:\n        packet_queue_abort(&is->videoq);\n\n        /* note: we also signal this mutex to make sure we deblock the\n           video thread in all cases */\n        SDL_LockMutex(is->pictq_mutex);\n        SDL_CondSignal(is->pictq_cond);\n        SDL_UnlockMutex(is->pictq_mutex);\n\n        SDL_WaitThread(is->video_tid, NULL);\n\n        packet_queue_flush(&is->videoq);\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        packet_queue_abort(&is->subtitleq);\n\n        /* note: we also signal this mutex to make sure we deblock the\n           video thread in all cases */\n        SDL_LockMutex(is->subpq_mutex);\n        is->subtitle_stream_changed = 1;\n\n        SDL_CondSignal(is->subpq_cond);\n        SDL_UnlockMutex(is->subpq_mutex);\n\n        SDL_WaitThread(is->subtitle_tid, NULL);\n\n        packet_queue_flush(&is->subtitleq);\n        break;\n    default:\n        break;\n    }\n\n    ic->streams[stream_index]->discard = AVDISCARD_ALL;\n    avcodec_close(avctx);\n#if CONFIG_AVFILTER\n    free_buffer_pool(&is->buffer_pool);\n#endif\n    switch (avctx->codec_type) {\n    case AVMEDIA_TYPE_AUDIO:\n        is->audio_st = NULL;\n        is->audio_stream = -1;\n        break;\n    case AVMEDIA_TYPE_VIDEO:\n        is->video_st = NULL;\n        is->video_stream = -1;\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        is->subtitle_st = NULL;\n        is->subtitle_stream = -1;\n        break;\n    default:\n        break;\n    }\n}"}, {"function body": "static int decode_interrupt_cb(void *ctx)\n{\n    VideoState *is = ctx;\n    return is->abort_request;\n}"}, {"function body": "static int read_thread(void *arg)\n{\n    VideoState *is = arg;\n    AVFormatContext *ic = NULL;\n    int err, i, ret;\n    int st_index[AVMEDIA_TYPE_NB];\n    AVPacket pkt1, *pkt = &pkt1;\n    int eof = 0;\n    int pkt_in_play_range = 0;\n    AVDictionaryEntry *t;\n    AVDictionary **opts;\n    int orig_nb_streams;\n    SDL_mutex *wait_mutex = SDL_CreateMutex();\n\n    memset(st_index, -1, sizeof(st_index));\n    is->last_video_stream = is->video_stream = -1;\n    is->last_audio_stream = is->audio_stream = -1;\n    is->last_subtitle_stream = is->subtitle_stream = -1;\n\n    ic = avformat_alloc_context();\n    ic->interrupt_callback.callback = decode_interrupt_cb;\n    ic->interrupt_callback.opaque = is;\n    err = avformat_open_input(&ic, is->filename, is->iformat, &format_opts);\n    if (err < 0) {\n        print_error(is->filename, err);\n        ret = -1;\n        goto fail;\n    }\n    if ((t = av_dict_get(format_opts, \"\", NULL, AV_DICT_IGNORE_SUFFIX))) {\n        av_log(NULL, AV_LOG_ERROR, \"Option %s not found.\\n\", t->key);\n        ret = AVERROR_OPTION_NOT_FOUND;\n        goto fail;\n    }\n    is->ic = ic;\n\n    if (genpts)\n        ic->flags |= AVFMT_FLAG_GENPTS;\n\n    opts = setup_find_stream_info_opts(ic, codec_opts);\n    orig_nb_streams = ic->nb_streams;\n\n    err = avformat_find_stream_info(ic, opts);\n    if (err < 0) {\n        fprintf(stderr, \"%s: could not find codec parameters\\n\", is->filename);\n        ret = -1;\n        goto fail;\n    }\n    for (i = 0; i < orig_nb_streams; i++)\n        av_dict_free(&opts[i]);\n    av_freep(&opts);\n\n    if (ic->pb)\n        ic->pb->eof_reached = 0; // FIXME hack, ffplay maybe should not use url_feof() to test for the end\n\n    if (seek_by_bytes < 0)\n        seek_by_bytes = !!(ic->iformat->flags & AVFMT_TS_DISCONT);\n\n    /* if seeking requested, we execute it */\n    if (start_time != AV_NOPTS_VALUE) {\n        int64_t timestamp;\n\n        timestamp = start_time;\n        /* add the stream start time */\n        if (ic->start_time != AV_NOPTS_VALUE)\n            timestamp += ic->start_time;\n        ret = avformat_seek_file(ic, -1, INT64_MIN, timestamp, INT64_MAX, 0);\n        if (ret < 0) {\n            fprintf(stderr, \"%s: could not seek to position %0.3f\\n\",\n                    is->filename, (double)timestamp / AV_TIME_BASE);\n        }\n    }\n\n    for (i = 0; i < ic->nb_streams; i++)\n        ic->streams[i]->discard = AVDISCARD_ALL;\n    if (!video_disable)\n        st_index[AVMEDIA_TYPE_VIDEO] =\n            av_find_best_stream(ic, AVMEDIA_TYPE_VIDEO,\n                                wanted_stream[AVMEDIA_TYPE_VIDEO], -1, NULL, 0);\n    if (!audio_disable)\n        st_index[AVMEDIA_TYPE_AUDIO] =\n            av_find_best_stream(ic, AVMEDIA_TYPE_AUDIO,\n                                wanted_stream[AVMEDIA_TYPE_AUDIO],\n                                st_index[AVMEDIA_TYPE_VIDEO],\n                                NULL, 0);\n    if (!video_disable)\n        st_index[AVMEDIA_TYPE_SUBTITLE] =\n            av_find_best_stream(ic, AVMEDIA_TYPE_SUBTITLE,\n                                wanted_stream[AVMEDIA_TYPE_SUBTITLE],\n                                (st_index[AVMEDIA_TYPE_AUDIO] >= 0 ?\n                                 st_index[AVMEDIA_TYPE_AUDIO] :\n                                 st_index[AVMEDIA_TYPE_VIDEO]),\n                                NULL, 0);\n    if (show_status) {\n        av_dump_format(ic, 0, is->filename, 0);\n    }\n\n    is->show_mode = show_mode;\n\n    /* open the streams */\n    if (st_index[AVMEDIA_TYPE_AUDIO] >= 0) {\n        stream_component_open(is, st_index[AVMEDIA_TYPE_AUDIO]);\n    }\n\n    ret = -1;\n    if (st_index[AVMEDIA_TYPE_VIDEO] >= 0) {\n        ret = stream_component_open(is, st_index[AVMEDIA_TYPE_VIDEO]);\n    }\n    is->refresh_tid = SDL_CreateThread(refresh_thread, is);\n    if (is->show_mode == SHOW_MODE_NONE)\n        is->show_mode = ret >= 0 ? SHOW_MODE_VIDEO : SHOW_MODE_RDFT;\n\n    if (st_index[AVMEDIA_TYPE_SUBTITLE] >= 0) {\n        stream_component_open(is, st_index[AVMEDIA_TYPE_SUBTITLE]);\n    }\n\n    if (is->video_stream < 0 && is->audio_stream < 0) {\n        fprintf(stderr, \"%s: could not open codecs\\n\", is->filename);\n        ret = -1;\n        goto fail;\n    }\n\n    for (;;) {\n        if (is->abort_request)\n            break;\n        if (is->paused != is->last_paused) {\n            is->last_paused = is->paused;\n            if (is->paused)\n                is->read_pause_return = av_read_pause(ic);\n            else\n                av_read_play(ic);\n        }\n#if CONFIG_RTSP_DEMUXER || CONFIG_MMSH_PROTOCOL\n        if (is->paused &&\n                (!strcmp(ic->iformat->name, \"rtsp\") ||\n                 (ic->pb && !strncmp(input_filename, \"mmsh:\", 5)))) {\n            /* wait 10 ms to avoid trying to get another packet */\n            /* XXX: horrible */\n            SDL_Delay(10);\n            continue;\n        }\n#endif\n        if (is->seek_req) {\n            int64_t seek_target = is->seek_pos;\n            int64_t seek_min    = is->seek_rel > 0 ? seek_target - is->seek_rel + 2: INT64_MIN;\n            int64_t seek_max    = is->seek_rel < 0 ? seek_target - is->seek_rel - 2: INT64_MAX;\n// FIXME the +-2 is due to rounding being not done in the correct direction in generation\n//      of the seek_pos/seek_rel variables\n\n            ret = avformat_seek_file(is->ic, -1, seek_min, seek_target, seek_max, is->seek_flags);\n            if (ret < 0) {\n                fprintf(stderr, \"%s: error while seeking\\n\", is->ic->filename);\n            } else {\n                if (is->audio_stream >= 0) {\n                    packet_queue_flush(&is->audioq);\n                    packet_queue_put(&is->audioq, &flush_pkt);\n                }\n                if (is->subtitle_stream >= 0) {\n                    packet_queue_flush(&is->subtitleq);\n                    packet_queue_put(&is->subtitleq, &flush_pkt);\n                }\n                if (is->video_stream >= 0) {\n                    packet_queue_flush(&is->videoq);\n                    packet_queue_put(&is->videoq, &flush_pkt);\n                }\n            }\n            is->seek_req = 0;\n            eof = 0;\n        }\n        if (is->que_attachments_req) {\n            avformat_queue_attached_pictures(ic);\n            is->que_attachments_req = 0;\n        }\n\n        /* if the queue are full, no need to read more */\n        if (!infinite_buffer &&\n              (is->audioq.size + is->videoq.size + is->subtitleq.size > MAX_QUEUE_SIZE\n            || (   (is->audioq   .nb_packets > MIN_FRAMES || is->audio_stream < 0 || is->audioq.abort_request)\n                && (is->videoq   .nb_packets > MIN_FRAMES || is->video_stream < 0 || is->videoq.abort_request)\n                && (is->subtitleq.nb_packets > MIN_FRAMES || is->subtitle_stream < 0 || is->subtitleq.abort_request)))) {\n            /* wait 10 ms */\n            SDL_LockMutex(wait_mutex);\n            SDL_CondWaitTimeout(is->continue_read_thread, wait_mutex, 10);\n            SDL_UnlockMutex(wait_mutex);\n            continue;\n        }\n        if (eof) {\n            if (is->video_stream >= 0) {\n                av_init_packet(pkt);\n                pkt->data = NULL;\n                pkt->size = 0;\n                pkt->stream_index = is->video_stream;\n                packet_queue_put(&is->videoq, pkt);\n            }\n            if (is->audio_stream >= 0 &&\n                is->audio_st->codec->codec->capabilities & CODEC_CAP_DELAY) {\n                av_init_packet(pkt);\n                pkt->data = NULL;\n                pkt->size = 0;\n                pkt->stream_index = is->audio_stream;\n                packet_queue_put(&is->audioq, pkt);\n            }\n            SDL_Delay(10);\n            if (is->audioq.size + is->videoq.size + is->subtitleq.size == 0) {\n                if (loop != 1 && (!loop || --loop)) {\n                    stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0);\n                } else if (autoexit) {\n                    ret = AVERROR_EOF;\n                    goto fail;\n                }\n            }\n            eof=0;\n            continue;\n        }\n        ret = av_read_frame(ic, pkt);\n        if (ret < 0) {\n            if (ret == AVERROR_EOF || url_feof(ic->pb))\n                eof = 1;\n            if (ic->pb && ic->pb->error)\n                break;\n            SDL_LockMutex(wait_mutex);\n            SDL_CondWaitTimeout(is->continue_read_thread, wait_mutex, 10);\n            SDL_UnlockMutex(wait_mutex);\n            continue;\n        }\n        /* check if packet is in play range specified by user, then queue, otherwise discard */\n        pkt_in_play_range = duration == AV_NOPTS_VALUE ||\n                (pkt->pts - ic->streams[pkt->stream_index]->start_time) *\n                av_q2d(ic->streams[pkt->stream_index]->time_base) -\n                (double)(start_time != AV_NOPTS_VALUE ? start_time : 0) / 1000000\n                <= ((double)duration / 1000000);\n        if (pkt->stream_index == is->audio_stream && pkt_in_play_range) {\n            packet_queue_put(&is->audioq, pkt);\n        } else if (pkt->stream_index == is->video_stream && pkt_in_play_range) {\n            packet_queue_put(&is->videoq, pkt);\n        } else if (pkt->stream_index == is->subtitle_stream && pkt_in_play_range) {\n            packet_queue_put(&is->subtitleq, pkt);\n        } else {\n            av_free_packet(pkt);\n        }\n    }\n    /* wait until the end */\n    while (!is->abort_request) {\n        SDL_Delay(100);\n    }\n\n    ret = 0;\n fail:\n    /* close each stream */\n    if (is->audio_stream >= 0)\n        stream_component_close(is, is->audio_stream);\n    if (is->video_stream >= 0)\n        stream_component_close(is, is->video_stream);\n    if (is->subtitle_stream >= 0)\n        stream_component_close(is, is->subtitle_stream);\n    if (is->ic) {\n        avformat_close_input(&is->ic);\n    }\n\n    if (ret != 0) {\n        SDL_Event event;\n\n        event.type = FF_QUIT_EVENT;\n        event.user.data1 = is;\n        SDL_PushEvent(&event);\n    }\n    SDL_DestroyMutex(wait_mutex);\n    return 0;\n}"}, {"function body": "static VideoState *stream_open(const char *filename, AVInputFormat *iformat)\n{\n    VideoState *is;\n\n    is = av_mallocz(sizeof(VideoState));\n    if (!is)\n        return NULL;\n    av_strlcpy(is->filename, filename, sizeof(is->filename));\n    is->iformat = iformat;\n    is->ytop    = 0;\n    is->xleft   = 0;\n\n    /* start video display */\n    is->pictq_mutex = SDL_CreateMutex();\n    is->pictq_cond  = SDL_CreateCond();\n\n    is->subpq_mutex = SDL_CreateMutex();\n    is->subpq_cond  = SDL_CreateCond();\n\n    packet_queue_init(&is->videoq);\n    packet_queue_init(&is->audioq);\n    packet_queue_init(&is->subtitleq);\n\n    is->continue_read_thread = SDL_CreateCond();\n\n    is->av_sync_type = av_sync_type;\n    is->read_tid     = SDL_CreateThread(read_thread, is);\n    if (!is->read_tid) {\n        av_free(is);\n        return NULL;\n    }\n    return is;\n}"}, {"function body": "static void stream_cycle_channel(VideoState *is, int codec_type)\n{\n    AVFormatContext *ic = is->ic;\n    int start_index, stream_index;\n    int old_index;\n    AVStream *st;\n\n    if (codec_type == AVMEDIA_TYPE_VIDEO) {\n        start_index = is->last_video_stream;\n        old_index = is->video_stream;\n    } else if (codec_type == AVMEDIA_TYPE_AUDIO) {\n        start_index = is->last_audio_stream;\n        old_index = is->audio_stream;\n    } else {\n        start_index = is->last_subtitle_stream;\n        old_index = is->subtitle_stream;\n    }\n    stream_index = start_index;\n    for (;;) {\n        if (++stream_index >= is->ic->nb_streams)\n        {\n            if (codec_type == AVMEDIA_TYPE_SUBTITLE)\n            {\n                stream_index = -1;\n                is->last_subtitle_stream = -1;\n                goto the_end;\n            }\n            if (start_index == -1)\n                return;\n            stream_index = 0;\n        }\n        if (stream_index == start_index)\n            return;\n        st = ic->streams[stream_index];\n        if (st->codec->codec_type == codec_type) {\n            /* check that parameters are OK */\n            switch (codec_type) {\n            case AVMEDIA_TYPE_AUDIO:\n                if (st->codec->sample_rate != 0 &&\n                    st->codec->channels != 0)\n                    goto the_end;\n                break;\n            case AVMEDIA_TYPE_VIDEO:\n            case AVMEDIA_TYPE_SUBTITLE:\n                goto the_end;\n            default:\n                break;\n            }\n        }\n    }\n the_end:\n    stream_component_close(is, old_index);\n    stream_component_open(is, stream_index);\n    if (codec_type == AVMEDIA_TYPE_VIDEO)\n        is->que_attachments_req = 1;\n}"}, {"function body": "static void toggle_full_screen(VideoState *is)\n{\n#if defined(__APPLE__) && SDL_VERSION_ATLEAST(1, 2, 14)\n    /* OS X needs to reallocate the SDL overlays */\n    int i;\n    for (i = 0; i < VIDEO_PICTURE_QUEUE_SIZE; i++)\n        is->pictq[i].reallocate = 1;\n#endif\n    is_full_screen = !is_full_screen;\n    video_open(is, 1);\n}"}, {"function body": "static void toggle_pause(VideoState *is)\n{\n    stream_toggle_pause(is);\n    is->step = 0;\n}"}, {"function body": "static void step_to_next_frame(VideoState *is)\n{\n    /* if the stream is paused unpause it, then step */\n    if (is->paused)\n        stream_toggle_pause(is);\n    is->step = 1;\n}"}, {"function body": "static void toggle_audio_display(VideoState *is)\n{\n    int bgcolor = SDL_MapRGB(screen->format, 0x00, 0x00, 0x00);\n    is->show_mode = (is->show_mode + 1) % SHOW_MODE_NB;\n    fill_rectangle(screen,\n                is->xleft, is->ytop, is->width, is->height,\n                bgcolor);\n    SDL_UpdateRect(screen, is->xleft, is->ytop, is->width, is->height);\n}"}, {"function body": "static void event_loop(VideoState *cur_stream)\n{\n    SDL_Event event;\n    double incr, pos, frac;\n\n    for (;;) {\n        double x;\n        SDL_WaitEvent(&event);\n        switch (event.type) {\n        case SDL_KEYDOWN:\n            if (exit_on_keydown) {\n                do_exit(cur_stream);\n                break;\n            }\n            switch (event.key.keysym.sym) {\n            case SDLK_ESCAPE:\n            case SDLK_q:\n                do_exit(cur_stream);\n                break;\n            case SDLK_f:\n                toggle_full_screen(cur_stream);\n                cur_stream->force_refresh = 1;\n                break;\n            case SDLK_p:\n            case SDLK_SPACE:\n                toggle_pause(cur_stream);\n                break;\n            case SDLK_s: // S: Step to next frame\n                step_to_next_frame(cur_stream);\n                break;\n            case SDLK_a:\n                stream_cycle_channel(cur_stream, AVMEDIA_TYPE_AUDIO);\n                break;\n            case SDLK_v:\n                stream_cycle_channel(cur_stream, AVMEDIA_TYPE_VIDEO);\n                break;\n            case SDLK_t:\n                stream_cycle_channel(cur_stream, AVMEDIA_TYPE_SUBTITLE);\n                break;\n            case SDLK_w:\n                toggle_audio_display(cur_stream);\n                cur_stream->force_refresh = 1;\n                break;\n            case SDLK_PAGEUP:\n                incr = 600.0;\n                goto do_seek;\n            case SDLK_PAGEDOWN:\n                incr = -600.0;\n                goto do_seek;\n            case SDLK_LEFT:\n                incr = -10.0;\n                goto do_seek;\n            case SDLK_RIGHT:\n                incr = 10.0;\n                goto do_seek;\n            case SDLK_UP:\n                incr = 60.0;\n                goto do_seek;\n            case SDLK_DOWN:\n                incr = -60.0;\n            do_seek:\n                    if (seek_by_bytes) {\n                        if (cur_stream->video_stream >= 0 && cur_stream->video_current_pos >= 0) {\n                            pos = cur_stream->video_current_pos;\n                        } else if (cur_stream->audio_stream >= 0 && cur_stream->audio_pkt.pos >= 0) {\n                            pos = cur_stream->audio_pkt.pos;\n                        } else\n                            pos = avio_tell(cur_stream->ic->pb);\n                        if (cur_stream->ic->bit_rate)\n                            incr *= cur_stream->ic->bit_rate / 8.0;\n                        else\n                            incr *= 180000.0;\n                        pos += incr;\n                        stream_seek(cur_stream, pos, incr, 1);\n                    } else {\n                        pos = get_master_clock(cur_stream);\n                        pos += incr;\n                        stream_seek(cur_stream, (int64_t)(pos * AV_TIME_BASE), (int64_t)(incr * AV_TIME_BASE), 0);\n                    }\n                break;\n            default:\n                break;\n            }\n            break;\n        case SDL_VIDEOEXPOSE:\n            cur_stream->force_refresh = 1;\n            break;\n        case SDL_MOUSEBUTTONDOWN:\n            if (exit_on_mousedown) {\n                do_exit(cur_stream);\n                break;\n            }\n        case SDL_MOUSEMOTION:\n            if (event.type == SDL_MOUSEBUTTONDOWN) {\n                x = event.button.x;\n            } else {\n                if (event.motion.state != SDL_PRESSED)\n                    break;\n                x = event.motion.x;\n            }\n                if (seek_by_bytes || cur_stream->ic->duration <= 0) {\n                    uint64_t size =  avio_size(cur_stream->ic->pb);\n                    stream_seek(cur_stream, size*x/cur_stream->width, 0, 1);\n                } else {\n                    int64_t ts;\n                    int ns, hh, mm, ss;\n                    int tns, thh, tmm, tss;\n                    tns  = cur_stream->ic->duration / 1000000LL;\n                    thh  = tns / 3600;\n                    tmm  = (tns % 3600) / 60;\n                    tss  = (tns % 60);\n                    frac = x / cur_stream->width;\n                    ns   = frac * tns;\n                    hh   = ns / 3600;\n                    mm   = (ns % 3600) / 60;\n                    ss   = (ns % 60);\n                    fprintf(stderr, \"Seek to %2.0f%% (%2d:%02d:%02d) of total duration (%2d:%02d:%02d)       \\n\", frac*100,\n                            hh, mm, ss, thh, tmm, tss);\n                    ts = frac * cur_stream->ic->duration;\n                    if (cur_stream->ic->start_time != AV_NOPTS_VALUE)\n                        ts += cur_stream->ic->start_time;\n                    stream_seek(cur_stream, ts, 0, 0);\n                }\n            break;\n        case SDL_VIDEORESIZE:\n                screen = SDL_SetVideoMode(event.resize.w, event.resize.h, 0,\n                                          SDL_HWSURFACE|SDL_RESIZABLE|SDL_ASYNCBLIT|SDL_HWACCEL);\n                screen_width  = cur_stream->width  = event.resize.w;\n                screen_height = cur_stream->height = event.resize.h;\n                cur_stream->force_refresh = 1;\n            break;\n        case SDL_QUIT:\n        case FF_QUIT_EVENT:\n            do_exit(cur_stream);\n            break;\n        case FF_ALLOC_EVENT:\n            alloc_picture(event.user.data1);\n            break;\n        case FF_REFRESH_EVENT:\n            video_refresh(event.user.data1);\n            cur_stream->refresh = 0;\n            break;\n        default:\n            break;\n        }\n    }\n}"}, {"function body": "static int opt_frame_size(void *optctx, const char *opt, const char *arg)\n{\n    av_log(NULL, AV_LOG_WARNING, \"Option -s is deprecated, use -video_size.\\n\");\n    return opt_default(NULL, \"video_size\", arg);\n}"}, {"function body": "static int opt_width(void *optctx, const char *opt, const char *arg)\n{\n    screen_width = parse_number_or_die(opt, arg, OPT_INT64, 1, INT_MAX);\n    return 0;\n}"}, {"function body": "static int opt_height(void *optctx, const char *opt, const char *arg)\n{\n    screen_height = parse_number_or_die(opt, arg, OPT_INT64, 1, INT_MAX);\n    return 0;\n}"}, {"function body": "static int opt_format(void *optctx, const char *opt, const char *arg)\n{\n    file_iformat = av_find_input_format(arg);\n    if (!file_iformat) {\n        fprintf(stderr, \"Unknown input format: %s\\n\", arg);\n        return AVERROR(EINVAL);\n    }\n    return 0;\n}"}, {"function body": "static int opt_frame_pix_fmt(void *optctx, const char *opt, const char *arg)\n{\n    av_log(NULL, AV_LOG_WARNING, \"Option -pix_fmt is deprecated, use -pixel_format.\\n\");\n    return opt_default(NULL, \"pixel_format\", arg);\n}"}, {"function body": "static int opt_sync(void *optctx, const char *opt, const char *arg)\n{\n    if (!strcmp(arg, \"audio\"))\n        av_sync_type = AV_SYNC_AUDIO_MASTER;\n    else if (!strcmp(arg, \"video\"))\n        av_sync_type = AV_SYNC_VIDEO_MASTER;\n    else if (!strcmp(arg, \"ext\"))\n        av_sync_type = AV_SYNC_EXTERNAL_CLOCK;\n    else {\n        fprintf(stderr, \"Unknown value for %s: %s\\n\", opt, arg);\n        exit(1);\n    }\n    return 0;\n}"}, {"function body": "static int opt_seek(void *optctx, const char *opt, const char *arg)\n{\n    start_time = parse_time_or_die(opt, arg, 1);\n    return 0;\n}"}, {"function body": "static int opt_duration(void *optctx, const char *opt, const char *arg)\n{\n    duration = parse_time_or_die(opt, arg, 1);\n    return 0;\n}"}, {"function body": "static int opt_show_mode(void *optctx, const char *opt, const char *arg)\n{\n    show_mode = !strcmp(arg, \"video\") ? SHOW_MODE_VIDEO :\n                !strcmp(arg, \"waves\") ? SHOW_MODE_WAVES :\n                !strcmp(arg, \"rdft\" ) ? SHOW_MODE_RDFT  :\n                parse_number_or_die(opt, arg, OPT_INT, 0, SHOW_MODE_NB-1);\n    return 0;\n}"}, {"function body": "static void opt_input_file(void *optctx, const char *filename)\n{\n    if (input_filename) {\n        fprintf(stderr, \"Argument '%s' provided as input filename, but '%s' was already specified.\\n\",\n                filename, input_filename);\n        exit_program(1);\n    }\n    if (!strcmp(filename, \"-\"))\n        filename = \"pipe:\";\n    input_filename = filename;\n}"}, {"function body": "static int opt_codec(void *o, const char *opt, const char *arg)\n{\n    switch(opt[strlen(opt)-1]){\n    case 'a' :    audio_codec_name = arg; break;\n    case 's' : subtitle_codec_name = arg; break;\n    case 'v' :    video_codec_name = arg; break;\n    }\n    return 0;\n}"}, {"function body": "static void show_usage(void)\n{\n    av_log(NULL, AV_LOG_INFO, \"Simple media player\\n\");\n    av_log(NULL, AV_LOG_INFO, \"usage: %s [options] input_file\\n\", program_name);\n    av_log(NULL, AV_LOG_INFO, \"\\n\");\n}"}, {"function body": "void show_help_default(const char *opt, const char *arg)\n{\n    av_log_set_callback(log_callback_help);\n    show_usage();\n    show_help_options(options, \"Main options:\", 0, OPT_EXPERT, 0);\n    show_help_options(options, \"Advanced options:\", OPT_EXPERT, 0, 0);\n    printf(\"\\n\");\n    show_help_children(avcodec_get_class(), AV_OPT_FLAG_DECODING_PARAM);\n    show_help_children(avformat_get_class(), AV_OPT_FLAG_DECODING_PARAM);\n#if !CONFIG_AVFILTER\n    show_help_children(sws_get_class(), AV_OPT_FLAG_ENCODING_PARAM);\n#else\n    show_help_children(avfilter_get_class(), AV_OPT_FLAG_FILTERING_PARAM);\n#endif\n    printf(\"\\nWhile playing:\\n\"\n           \"q, ESC              quit\\n\"\n           \"f                   toggle full screen\\n\"\n           \"p, SPC              pause\\n\"\n           \"a                   cycle audio channel\\n\"\n           \"v                   cycle video channel\\n\"\n           \"t                   cycle subtitle channel\\n\"\n           \"w                   show audio waves\\n\"\n           \"s                   activate frame-step mode\\n\"\n           \"left/right          seek backward/forward 10 seconds\\n\"\n           \"down/up             seek backward/forward 1 minute\\n\"\n           \"page down/page up   seek backward/forward 10 minutes\\n\"\n           \"mouse click         seek to percentage in file corresponding to fraction of width\\n\"\n           );\n}"}, {"function body": "static int lockmgr(void **mtx, enum AVLockOp op)\n{\n   switch(op) {\n      case AV_LOCK_CREATE:\n          *mtx = SDL_CreateMutex();\n          if(!*mtx)\n              return 1;\n          return 0;\n      case AV_LOCK_OBTAIN:\n          return !!SDL_LockMutex(*mtx);\n      case AV_LOCK_RELEASE:\n          return !!SDL_UnlockMutex(*mtx);\n      case AV_LOCK_DESTROY:\n          SDL_DestroyMutex(*mtx);\n          return 0;\n   }\n   return 1;\n}"}, {"function body": "int main(int argc, char **argv)\n{\n    int flags;\n    VideoState *is;\n    char dummy_videodriver[] = \"SDL_VIDEODRIVER=dummy\";\n\n    av_log_set_flags(AV_LOG_SKIP_REPEATED);\n    parse_loglevel(argc, argv, options);\n\n    /* register all codecs, demux and protocols */\n    avcodec_register_all();\n#if CONFIG_AVDEVICE\n    avdevice_register_all();\n#endif\n#if CONFIG_AVFILTER\n    avfilter_register_all();\n#endif\n    av_register_all();\n    avformat_network_init();\n\n    init_opts();\n\n    signal(SIGINT , sigterm_handler); /* Interrupt (ANSI).    */\n    signal(SIGTERM, sigterm_handler); /* Termination (ANSI).  */\n\n    show_banner(argc, argv, options);\n\n    parse_options(NULL, argc, argv, options, opt_input_file);\n\n    if (!input_filename) {\n        show_usage();\n        fprintf(stderr, \"An input file must be specified\\n\");\n        fprintf(stderr, \"Use -h to get full help or, even better, run 'man %s'\\n\", program_name);\n        exit(1);\n    }\n\n    if (display_disable) {\n        video_disable = 1;\n    }\n    flags = SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER;\n    if (audio_disable)\n        flags &= ~SDL_INIT_AUDIO;\n    if (display_disable)\n        SDL_putenv(dummy_videodriver); /* For the event queue, we always need a video driver. */\n#if !defined(__MINGW32__) && !defined(__APPLE__)\n    flags |= SDL_INIT_EVENTTHREAD; /* Not supported on Windows or Mac OS X */\n#endif\n    if (SDL_Init (flags)) {\n        fprintf(stderr, \"Could not initialize SDL - %s\\n\", SDL_GetError());\n        fprintf(stderr, \"(Did you set the DISPLAY variable?)\\n\");\n        exit(1);\n    }\n\n    if (!display_disable) {\n#if HAVE_SDL_VIDEO_SIZE\n        const SDL_VideoInfo *vi = SDL_GetVideoInfo();\n        fs_screen_width = vi->current_w;\n        fs_screen_height = vi->current_h;\n#endif\n    }\n\n    SDL_EventState(SDL_ACTIVEEVENT, SDL_IGNORE);\n    SDL_EventState(SDL_SYSWMEVENT, SDL_IGNORE);\n    SDL_EventState(SDL_USEREVENT, SDL_IGNORE);\n\n    if (av_lockmgr_register(lockmgr)) {\n        fprintf(stderr, \"Could not initialize lock manager!\\n\");\n        do_exit(NULL);\n    }\n\n    av_init_packet(&flush_pkt);\n    flush_pkt.data = (char *)(intptr_t)\"FLUSH\";\n\n    is = stream_open(input_filename, file_iformat);\n    if (!is) {\n        fprintf(stderr, \"Failed to initialize VideoState!\\n\");\n        do_exit(NULL);\n    }\n\n    event_loop(is);\n\n    /* never returns */\n\n    return 0;\n}"}]}]}